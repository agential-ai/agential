{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agential.cog.agent.reflexion import ReflexionCoTAgent, ReflexionReActAgent\n",
    "from agential.cog.prompts.agent.reflexion import (\n",
    "    REFLEXION_COT_INSTRUCTION_HOTPOTQA,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    REFLEXION_REACT_INSTRUCTION_HOTPOTQA,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "\n",
    "    FEVER_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    FEVER_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_FEVER,\n",
    "    REFLEXION_REACT_INSTRUCTION_FEVER,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_FEVER,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_FEVER,\n",
    "\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_AMBIGNQ,\n",
    "    REFLEXION_REACT_INSTRUCTION_AMBIGNQ,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_TRIVIAQA,\n",
    "    REFLEXION_REACT_INSTRUCTION_TRIVIAQA,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "\n",
    "    GSM8K_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    GSM8K_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_GSM8K,\n",
    "    REFLEXION_REACT_INSTRUCTION_GSM8K,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_GSM8K,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_GSM8K,\n",
    "\n",
    "    SVAMP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    SVAMP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_SVAMP,\n",
    "    REFLEXION_REACT_INSTRUCTION_SVAMP,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_SVAMP,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_SVAMP,\n",
    "\n",
    "    TABMWP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    TABMWP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_TABMWP,\n",
    "    REFLEXION_REACT_INSTRUCTION_TABMWP,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_TABMWP,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_TABMWP,\n",
    "\n",
    "    MBPP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    MBPP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_MBPP,\n",
    "    REFLEXION_REACT_INSTRUCTION_MBPP,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_MBPP,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_MBPP,\n",
    "\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_HUMANEVAL,\n",
    "    REFLEXION_REACT_INSTRUCTION_HUMANEVAL,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    ")\n",
    "from agential.cog.prompts.benchmark.hotpotqa import (\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_COT,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.prompts.benchmark.fever import (\n",
    "    FEVER_FEWSHOT_EXAMPLES_COT,\n",
    "    FEVER_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.prompts.benchmark.triviaqa import (\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_COT,\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.prompts.benchmark.ambignq import (\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_COT,\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.prompts.benchmark.gsm8k import (\n",
    "    GSM8K_FEWSHOT_EXAMPLES_COT,\n",
    "    GSM8K_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.prompts.benchmark.svamp import (\n",
    "    SVAMP_FEWSHOT_EXAMPLES_COT,\n",
    "    SVAMP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.prompts.benchmark.tabmwp import (\n",
    "    TABMWP_FEWSHOT_EXAMPLES_COT,\n",
    "    TABMWP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.prompts.benchmark.mbpp import (\n",
    "    MBPP_FEWSHOT_EXAMPLES_COT,\n",
    "    MBPP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.prompts.benchmark.humaneval import (\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_COT,\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.modules.reflect.reflexion import (\n",
    "    ReflexionCoTReflector,\n",
    "    ReflexionReActReflector,\n",
    ")\n",
    "import tiktoken\n",
    "from langchain_community.docstore.wikipedia import Wikipedia\n",
    "from agential.utils.docstore import DocstoreExplorer\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PROMPT AGENT===============================================================>\n",
      "Solve a coding question task by having a Thought, then Finish with your answer. Thought can reason about the current situation. Finish[answer] returns the answer and finishes the task.\n",
      "Here are some examples:\n",
      "You are an expert Python programmer, and here is your task: Write a function to find the shared elements from the given two lists.\n",
      "Your code should pass these tests:\n",
      "\n",
      "assert set(similar_elements((3, 4, 5, 6), (5, 7, 4, 10))) == set((4, 5))\n",
      "assert set(similar_elements((1, 2, 3, 4), (5, 4, 3, 7))) == set((3, 4))\n",
      "assert set(similar_elements((11, 12, 14, 13), (17, 15, 14, 13))) == set((13, 14))\n",
      "\n",
      "Thought: Let's think step by step. We need to find the common elements between the two lists and return them as a tuple.\n",
      "Action: Finish[\n",
      "```python\n",
      "def similar_elements(test_tup1, test_tup2):\n",
      "    res = tuple(set(test_tup1) & set(test_tup2))\n",
      "    return res\n",
      "```\n",
      "]\n",
      "\n",
      "---\n",
      "\n",
      "You are an expert Python programmer, and here is your task: Write a python function to identify non-prime numbers.\n",
      "Your code should pass these tests:\n",
      "\n",
      "assert is_not_prime(2) == False\n",
      "assert is_not_prime(10) == True\n",
      "assert is_not_prime(35) == True\n",
      "assert is_not_prime(37) == False\n",
      "\n",
      "Thought: Let's think step by step. We need to check if a number is not a prime by testing if it is divisible by any number from 2 to the square root of the number.\n",
      "Action: Finish[\n",
      "```python\n",
      "import math\n",
      "\n",
      "def is_not_prime(n):\n",
      "    result = False\n",
      "    for i in range(2, int(math.sqrt(n)) + 1):\n",
      "        if n % i == 0:\n",
      "            result = True\n",
      "            break\n",
      "    return result\n",
      "```\n",
      "]\n",
      "\n",
      "---\n",
      "\n",
      "You are an expert Python programmer, and here is your task: Write a function to find the n largest integers from a given list of numbers, returned in descending order.\n",
      "Your code should pass these tests:\n",
      "\n",
      "assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58], 3) == [85, 75, 65]\n",
      "assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58], 2) == [85, 75]\n",
      "assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58], 5) == [85, 75, 65, 58, 35]\n",
      "\n",
      "Thought: Let's think step by step. We need to find the n largest numbers in the list using the heapq.nlargest function.\n",
      "Action: Finish[\n",
      "```python\n",
      "import heapq as hq\n",
      "\n",
      "def heap_queue_largest(nums, n):\n",
      "    largest_nums = hq.nlargest(n, nums)\n",
      "    return largest_nums\n",
      "```\n",
      "]\n",
      "(END OF EXAMPLES)\n",
      "\n",
      "\n",
      "\n",
      "You are an expert Python programmer, and here is your task: Write a python function to find the first repeated character in a given string..\n",
      "Your code should pass these tests:\n",
      "\n",
      "assert first_repeated_char(\"abcabc\") == \"a\"\n",
      "assert first_repeated_char(\"abc\") == None\n",
      "assert first_repeated_char(\"123123\") == \"1\"\n",
      "\n",
      "\n",
      "Thought:\n",
      "<PROMPT AGENT===============================================================>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tuvin\\anaconda3\\envs\\agential\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OUT AGENT===============================================================>\n",
      "\"Let's think step by step. We need to iterate through the string and keep track of characters we have seen so far to identify the first repeated character.\\nAction: Finish[\\n```python\\ndef first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None\\n```\\n]\"\n",
      "<OUT AGENT===============================================================>\n"
     ]
    }
   ],
   "source": [
    "from agential.cog.strategies.reflexion.code import (\n",
    "    ReflexionCoTCodeStrategy,\n",
    ")\n",
    "\n",
    "question = \"Write a python function to find the first repeated character in a given string.\"\n",
    "key = \"\"\"assert first_repeated_char(\"abcabc\") == \"a\"\n",
    "assert first_repeated_char(\"abc\") == None\n",
    "assert first_repeated_char(\"123123\") == \"1\\\"\"\"\"\n",
    "\n",
    "strategy = ReflexionCoTCodeStrategy(llm=llm)\n",
    "out = strategy.generate(\n",
    "    question=question,\n",
    "    examples=MBPP_FEWSHOT_EXAMPLES_COT,\n",
    "    reflections=\"\",\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_MBPP,\n",
    "    additional_keys={\"tests\": key},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PROMPT AGENT===============================================================>\n",
      "Solve a coding question task by having a Thought, then Finish with your answer. Thought can reason about the current situation. Finish[answer] returns the answer and finishes the task.\n",
      "Here are some examples:\n",
      "You are an expert Python programmer, and here is your task: Write a function to find the shared elements from the given two lists.\n",
      "Your code should pass these tests:\n",
      "\n",
      "assert set(similar_elements((3, 4, 5, 6), (5, 7, 4, 10))) == set((4, 5))\n",
      "assert set(similar_elements((1, 2, 3, 4), (5, 4, 3, 7))) == set((3, 4))\n",
      "assert set(similar_elements((11, 12, 14, 13), (17, 15, 14, 13))) == set((13, 14))\n",
      "\n",
      "Thought: Let's think step by step. We need to find the common elements between the two lists and return them as a tuple.\n",
      "Action: Finish[\n",
      "```python\n",
      "def similar_elements(test_tup1, test_tup2):\n",
      "    res = tuple(set(test_tup1) & set(test_tup2))\n",
      "    return res\n",
      "```\n",
      "]\n",
      "\n",
      "---\n",
      "\n",
      "You are an expert Python programmer, and here is your task: Write a python function to identify non-prime numbers.\n",
      "Your code should pass these tests:\n",
      "\n",
      "assert is_not_prime(2) == False\n",
      "assert is_not_prime(10) == True\n",
      "assert is_not_prime(35) == True\n",
      "assert is_not_prime(37) == False\n",
      "\n",
      "Thought: Let's think step by step. We need to check if a number is not a prime by testing if it is divisible by any number from 2 to the square root of the number.\n",
      "Action: Finish[\n",
      "```python\n",
      "import math\n",
      "\n",
      "def is_not_prime(n):\n",
      "    result = False\n",
      "    for i in range(2, int(math.sqrt(n)) + 1):\n",
      "        if n % i == 0:\n",
      "            result = True\n",
      "            break\n",
      "    return result\n",
      "```\n",
      "]\n",
      "\n",
      "---\n",
      "\n",
      "You are an expert Python programmer, and here is your task: Write a function to find the n largest integers from a given list of numbers, returned in descending order.\n",
      "Your code should pass these tests:\n",
      "\n",
      "assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58], 3) == [85, 75, 65]\n",
      "assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58], 2) == [85, 75]\n",
      "assert heap_queue_largest([25, 35, 22, 85, 14, 65, 75, 22, 58], 5) == [85, 75, 65, 58, 35]\n",
      "\n",
      "Thought: Let's think step by step. We need to find the n largest numbers in the list using the heapq.nlargest function.\n",
      "Action: Finish[\n",
      "```python\n",
      "import heapq as hq\n",
      "\n",
      "def heap_queue_largest(nums, n):\n",
      "    largest_nums = hq.nlargest(n, nums)\n",
      "    return largest_nums\n",
      "```\n",
      "]\n",
      "(END OF EXAMPLES)\n",
      "\n",
      "\n",
      "\n",
      "You are an expert Python programmer, and here is your task: Write a python function to find the first repeated character in a given string..\n",
      "Your code should pass these tests:\n",
      "\n",
      "assert first_repeated_char(\"abcabc\") == \"a\"\n",
      "assert first_repeated_char(\"abc\") == None\n",
      "assert first_repeated_char(\"123123\") == \"1\"\n",
      "\n",
      "\n",
      "Thought: Let's think step by step. We need to iterate through the string and keep track of characters we have seen so far to identify the first repeated character.\n",
      "Action:\n",
      "<PROMPT AGENT===============================================================>\n",
      "<OUT AGENT===============================================================>\n",
      "'Finish[\\n```python\\ndef first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None\\n```\\n]'\n",
      "<OUT AGENT===============================================================>\n"
     ]
    }
   ],
   "source": [
    "action_type, query = strategy.generate_action(\n",
    "    question=question,\n",
    "    examples=MBPP_FEWSHOT_EXAMPLES_COT,\n",
    "    reflections=\"\",\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_MBPP,\n",
    "    additional_keys={\"tests\": key},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HotpotQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"VIVA Media AG changed it's name in 2004. What does their new acronym stand for?\"\n",
    "key = \"Gesellschaft mit beschränkter Haftung\"\n",
    "\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"hotpotqa\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=HOTPOTQA_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_HOTPOTQA, \n",
    "    reflect_examples=HOTPOTQA_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"VIVA Media AG changed it's name in 2004. What does their new acronym stand for?\"\n",
    "key = \"Gesellschaft mit beschränkter Haftung\"\n",
    "\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"hotpotqa\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=HOTPOTQA_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_HOTPOTQA, \n",
    "    reflect_examples=HOTPOTQA_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\"\n",
    "key = \"REFUTES\"\n",
    "\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"fever\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=FEVER_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_FEVER, \n",
    "    reflect_examples=FEVER_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_FEVER,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\"\n",
    "key = \"REFUTES\"\n",
    "\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"fever\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=FEVER_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_FEVER, \n",
    "    reflect_examples=FEVER_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_FEVER,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AmbigNQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did the simpsons first air on television?\"\n",
    "key = \"1989\"\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"ambignq\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=AMBIGNQ_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_AMBIGNQ, \n",
    "    reflect_examples=AMBIGNQ_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did the simpsons first air on television?\"\n",
    "key = \"1989\"\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"ambignq\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=AMBIGNQ_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_AMBIGNQ, \n",
    "    reflect_examples=AMBIGNQ_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriviaQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which American-born Sinclair won the Nobel Prize for Literature in 1930?\"\n",
    "key = \"Sinclair Lewis\"\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"triviaqa\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=TRIVIAQA_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_TRIVIAQA, \n",
    "    reflect_examples=TRIVIAQA_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which American-born Sinclair won the Nobel Prize for Literature in 1930?\"\n",
    "key = \"Sinclair Lewis\"\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"triviaqa\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=TRIVIAQA_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_TRIVIAQA, \n",
    "    reflect_examples=TRIVIAQA_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with 4933828. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\n",
    "key = -9867630\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm, \n",
    "    mode={\"math\": \"gsm8k\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1\n",
    ")\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=GSM8K_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_GSM8K,\n",
    "    reflect_examples=GSM8K_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_GSM8K,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with 4933828. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\n",
    "key = -9867630\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"math\": \"gsm8k\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=GSM8K_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_GSM8K, \n",
    "    reflect_examples=GSM8K_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_GSM8K,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"There are 87 oranges and 290 bananas in Philip's collection. If the bananas are organized into 2 groups and oranges are organized into 93 groups. How big is each group of bananas?\"\n",
    "key = 145\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm, \n",
    "    mode={\"math\": \"svamp\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=SVAMP_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_SVAMP,\n",
    "    reflect_examples=SVAMP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_SVAMP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"There are 87 oranges and 290 bananas in Philip's collection. If the bananas are organized into 2 groups and oranges are organized into 93 groups. How big is each group of bananas?\"\n",
    "key = 145\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"math\": \"svamp\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=SVAMP_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_SVAMP, \n",
    "    reflect_examples=SVAMP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_SVAMP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabMWP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Read the following table regarding \"Bowling Scores\" and then write Python code to answer a question:\n",
    "\n",
    "Name | Score\n",
    "Amanda | 117\n",
    "Sam | 236\n",
    "Irma | 144\n",
    "Mike | 164\n",
    "\n",
    "Question: Some friends went bowling and kept track of their scores. How many more points did Mike score than Irma?\"\"\"\n",
    "key = 20\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm, \n",
    "    mode={\"math\": \"tabmwp\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=TABMWP_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_TABMWP,\n",
    "    reflect_examples=TABMWP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_TABMWP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Read the following table regarding \"Bowling Scores\" and then write Python code to answer a question:\n",
    "\n",
    "Name | Score\n",
    "Amanda | 117\n",
    "Sam | 236\n",
    "Irma | 144\n",
    "Mike | 164\n",
    "\n",
    "Question: Some friends went bowling and kept track of their scores. How many more points did Mike score than Irma?\"\"\"\n",
    "key = 20\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"math\": \"tabmwp\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=TABMWP_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_TABMWP, \n",
    "    reflect_examples=TABMWP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_TABMWP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HumanEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = {\"task_id\": \"HumanEval/0\", \"prompt\": \"from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \\\"\\\"\\\"\\n\", \"entry_point\": \"has_close_elements\", \"canonical_solution\": \"    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n\", \"test\": \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\\n\\n\"}\n",
    "question = inst['prompt']\n",
    "key = f\"{inst['test']}\\ncheck({inst['entry_point']})\"\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm, \n",
    "    mode={\"code\": \"humaneval\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=HUMANEVAL_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_HUMANEVAL,\n",
    "    reflect_examples=HUMANEVAL_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = {\"task_id\": \"HumanEval/0\", \"prompt\": \"from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \\\"\\\"\\\"\\n\", \"entry_point\": \"has_close_elements\", \"canonical_solution\": \"    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n\", \"test\": \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\\n\\n\"}\n",
    "question = inst['prompt']\n",
    "key = f\"{inst['test']}\\ncheck({inst['entry_point']})\"\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"code\": \"humaneval\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=HUMANEVAL_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_HUMANEVAL,\n",
    "    reflect_examples=HUMANEVAL_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MBPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Write a python function to find the first repeated character in a given string.\"\n",
    "key = \"\"\"assert first_repeated_char(\"abcabc\") == \"a\"\n",
    "assert first_repeated_char(\"abc\") == None\n",
    "assert first_repeated_char(\"123123\") == \"1\\\"\"\"\"\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm, \n",
    "    mode={\"code\": \"mbpp\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=MBPP_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_MBPP,\n",
    "    reflect_examples=MBPP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_MBPP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={\"tests\": key},\n",
    "    reflect_additional_keys={\"tests\": key},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Write a python function to find the first repeated character in a given string.\"\n",
    "key = \"\"\"assert first_repeated_char(\"abcabc\") == \"a\"\n",
    "assert first_repeated_char(\"abc\") == None\n",
    "assert first_repeated_char(\"123123\") == \"1\\\"\"\"\"\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"code\": \"mbpp\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=MBPP_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_MBPP,\n",
    "    reflect_examples=MBPP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_MBPP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={\"tests\": key},\n",
    "    reflect_additional_keys={\"tests\": key},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
