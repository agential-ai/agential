{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agential.cog.reflexion.agent import ReflexionCoTAgent, ReflexionReActAgent\n",
    "from agential.cog.reflexion.prompts import (\n",
    "    REFLEXION_COT_INSTRUCTION_HOTPOTQA,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    REFLEXION_REACT_INSTRUCTION_HOTPOTQA,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "\n",
    "    FEVER_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    FEVER_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_FEVER,\n",
    "    REFLEXION_REACT_INSTRUCTION_FEVER,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_FEVER,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_FEVER,\n",
    "\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_AMBIGNQ,\n",
    "    REFLEXION_REACT_INSTRUCTION_AMBIGNQ,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_TRIVIAQA,\n",
    "    REFLEXION_REACT_INSTRUCTION_TRIVIAQA,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "\n",
    "    GSM8K_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    GSM8K_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_GSM8K,\n",
    "    REFLEXION_REACT_INSTRUCTION_GSM8K,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_GSM8K,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_GSM8K,\n",
    "\n",
    "    SVAMP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    SVAMP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_SVAMP,\n",
    "    REFLEXION_REACT_INSTRUCTION_SVAMP,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_SVAMP,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_SVAMP,\n",
    "\n",
    "    TABMWP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    TABMWP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_TABMWP,\n",
    "    REFLEXION_REACT_INSTRUCTION_TABMWP,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_TABMWP,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_TABMWP,\n",
    "\n",
    "    MBPP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    MBPP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_MBPP,\n",
    "    REFLEXION_REACT_INSTRUCTION_MBPP,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_MBPP,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_MBPP,\n",
    "\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_HUMANEVAL,\n",
    "    REFLEXION_REACT_INSTRUCTION_HUMANEVAL,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    ")\n",
    "from agential.cog.fewshots.hotpotqa import (\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_COT,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.fewshots.fever import (\n",
    "    FEVER_FEWSHOT_EXAMPLES_COT,\n",
    "    FEVER_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.fewshots.triviaqa import (\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_COT,\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.fewshots.ambignq import (\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_COT,\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.fewshots.gsm8k import (\n",
    "    GSM8K_FEWSHOT_EXAMPLES_COT,\n",
    "    GSM8K_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.fewshots.svamp import (\n",
    "    SVAMP_FEWSHOT_EXAMPLES_COT,\n",
    "    SVAMP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.fewshots.tabmwp import (\n",
    "    TABMWP_FEWSHOT_EXAMPLES_COT,\n",
    "    TABMWP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.fewshots.mbpp import (\n",
    "    MBPP_FEWSHOT_EXAMPLES_COT,\n",
    "    MBPP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.fewshots.humaneval import (\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_COT,\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.reflexion.reflect import (\n",
    "    ReflexionCoTReflector,\n",
    "    ReflexionReActReflector,\n",
    ")\n",
    "import tiktoken\n",
    "from langchain_community.docstore.wikipedia import Wikipedia\n",
    "from agential.utils.docstore import DocstoreExplorer\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HotpotQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"VIVA Media AG changed it's name in 2004. What does their new acronym stand for?\"\n",
    "key = \"Gesellschaft mit beschränkter Haftung\"\n",
    "\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm,\n",
    "    benchmark=\"hotpotqa\",\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=HOTPOTQA_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_HOTPOTQA, \n",
    "    reflect_examples=HOTPOTQA_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"VIVA Media AG changed it's name in 2004. What does their new acronym stand for?\"\n",
    "key = \"Gesellschaft mit beschränkter Haftung\"\n",
    "\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    benchmark=\"hotpotqa\",\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=HOTPOTQA_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_HOTPOTQA, \n",
    "    reflect_examples=HOTPOTQA_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\"\n",
    "key = \"REFUTES\"\n",
    "\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm,\n",
    "    benchmark=\"fever\",\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=FEVER_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_FEVER, \n",
    "    reflect_examples=FEVER_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_FEVER,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\"\n",
    "key = \"REFUTES\"\n",
    "\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    benchmark=\"fever\",\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=FEVER_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_FEVER, \n",
    "    reflect_examples=FEVER_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_FEVER,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AmbigNQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did the simpsons first air on television?\"\n",
    "key = \"1989\"\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm,\n",
    "    benchmark=\"ambignq\",\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=AMBIGNQ_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_AMBIGNQ, \n",
    "    reflect_examples=AMBIGNQ_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did the simpsons first air on television?\"\n",
    "key = \"1989\"\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    benchmark=\"ambignq\",\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=AMBIGNQ_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_AMBIGNQ, \n",
    "    reflect_examples=AMBIGNQ_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriviaQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which American-born Sinclair won the Nobel Prize for Literature in 1930?\"\n",
    "key = \"Sinclair Lewis\"\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm,\n",
    "    benchmark=\"triviaqa\",\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=TRIVIAQA_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_TRIVIAQA, \n",
    "    reflect_examples=TRIVIAQA_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which American-born Sinclair won the Nobel Prize for Literature in 1930?\"\n",
    "key = \"Sinclair Lewis\"\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    benchmark=\"triviaqa\",\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=TRIVIAQA_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_TRIVIAQA, \n",
    "    reflect_examples=TRIVIAQA_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with 4933828. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\n",
    "key = -9867630\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"gsm8k\",\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1\n",
    ")\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=GSM8K_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_GSM8K,\n",
    "    reflect_examples=GSM8K_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_GSM8K,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with 4933828. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\n",
    "key = -9867630\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    benchmark=\"gsm8k\",\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=GSM8K_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_GSM8K, \n",
    "    reflect_examples=GSM8K_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_GSM8K,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"There are 87 oranges and 290 bananas in Philip's collection. If the bananas are organized into 2 groups and oranges are organized into 93 groups. How big is each group of bananas?\"\n",
    "key = 145\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"svamp\",\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=SVAMP_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_SVAMP,\n",
    "    reflect_examples=SVAMP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_SVAMP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"There are 87 oranges and 290 bananas in Philip's collection. If the bananas are organized into 2 groups and oranges are organized into 93 groups. How big is each group of bananas?\"\n",
    "key = 145\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    benchmark=\"svamp\",\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=SVAMP_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_SVAMP, \n",
    "    reflect_examples=SVAMP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_SVAMP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabMWP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Read the following table regarding \"Bowling Scores\" and then write Python code to answer a question:\n",
    "\n",
    "Name | Score\n",
    "Amanda | 117\n",
    "Sam | 236\n",
    "Irma | 144\n",
    "Mike | 164\n",
    "\n",
    "Question: Some friends went bowling and kept track of their scores. How many more points did Mike score than Irma?\"\"\"\n",
    "key = 20\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"tabmwp\",\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=TABMWP_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_TABMWP,\n",
    "    reflect_examples=TABMWP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_TABMWP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Read the following table regarding \"Bowling Scores\" and then write Python code to answer a question:\n",
    "\n",
    "Name | Score\n",
    "Amanda | 117\n",
    "Sam | 236\n",
    "Irma | 144\n",
    "Mike | 164\n",
    "\n",
    "Question: Some friends went bowling and kept track of their scores. How many more points did Mike score than Irma?\"\"\"\n",
    "key = 20\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    benchmark=\"tabmwp\",\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=TABMWP_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_TABMWP, \n",
    "    reflect_examples=TABMWP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_TABMWP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HumanEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = {\"task_id\": \"HumanEval/0\", \"prompt\": \"from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \\\"\\\"\\\"\\n\", \"entry_point\": \"has_close_elements\", \"canonical_solution\": \"    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n\", \"test\": \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\\n\\n\"}\n",
    "question = inst['prompt']\n",
    "key = f\"{inst['test']}\\ncheck({inst['entry_point']})\"\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"humaneval\",\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=HUMANEVAL_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_HUMANEVAL,\n",
    "    reflect_examples=HUMANEVAL_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = {\"task_id\": \"HumanEval/0\", \"prompt\": \"from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \\\"\\\"\\\"\\n\", \"entry_point\": \"has_close_elements\", \"canonical_solution\": \"    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n\", \"test\": \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\\n\\n\"}\n",
    "question = inst['prompt']\n",
    "key = f\"{inst['test']}\\ncheck({inst['entry_point']})\"\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    benchmark=\"humaneval\",\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=HUMANEVAL_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_HUMANEVAL,\n",
    "    reflect_examples=HUMANEVAL_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MBPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Write a python function to find the first repeated character in a given string.\"\n",
    "key = \"\"\"assert first_repeated_char(\"abcabc\") == \"a\"\n",
    "assert first_repeated_char(\"abc\") == None\n",
    "assert first_repeated_char(\"123123\") == \"1\\\"\"\"\"\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"mbpp\",\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=MBPP_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_MBPP,\n",
    "    reflect_examples=MBPP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_MBPP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={\"tests\": key},\n",
    "    reflect_additional_keys={\"tests\": key},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Write a python function to find the first repeated character in a given string.\"\n",
    "key = \"\"\"assert first_repeated_char(\"abcabc\") == \"a\"\n",
    "assert first_repeated_char(\"abc\") == None\n",
    "assert first_repeated_char(\"123123\") == \"1\\\"\"\"\"\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    benchmark=\"mbpp\",\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    # kwargs.\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=MBPP_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_MBPP,\n",
    "    reflect_examples=MBPP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_MBPP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={\"tests\": key},\n",
    "    reflect_additional_keys={\"tests\": key},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    "    # kwargs.\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
