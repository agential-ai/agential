{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agential.cog.agent.reflexion import ReflexionCoTAgent, ReflexionReActAgent\n",
    "from agential.cog.prompts.agent.reflexion import (\n",
    "    REFLEXION_COT_INSTRUCTION_HOTPOTQA,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    REFLEXION_REACT_INSTRUCTION_HOTPOTQA,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "\n",
    "    FEVER_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    FEVER_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_FEVER,\n",
    "    REFLEXION_REACT_INSTRUCTION_FEVER,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_FEVER,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_FEVER,\n",
    "\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_AMBIGNQ,\n",
    "    REFLEXION_REACT_INSTRUCTION_AMBIGNQ,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_TRIVIAQA,\n",
    "    REFLEXION_REACT_INSTRUCTION_TRIVIAQA,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "\n",
    "    GSM8K_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    GSM8K_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_GSM8K,\n",
    "    REFLEXION_REACT_INSTRUCTION_GSM8K,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_GSM8K,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_GSM8K,\n",
    "\n",
    "    SVAMP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    SVAMP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_SVAMP,\n",
    "    REFLEXION_REACT_INSTRUCTION_SVAMP,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_SVAMP,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_SVAMP,\n",
    "\n",
    "    TABMWP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    TABMWP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_TABMWP,\n",
    "    REFLEXION_REACT_INSTRUCTION_TABMWP,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_TABMWP,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_TABMWP,\n",
    "\n",
    "    MBPP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    MBPP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    REFLEXION_COT_INSTRUCTION_MBPP,\n",
    "    REFLEXION_REACT_INSTRUCTION_MBPP,\n",
    "    REFLEXION_COT_REFLECT_INSTRUCTION_MBPP,\n",
    "    REFLEXION_REACT_REFLECT_INSTRUCTION_MBPP\n",
    ")\n",
    "from agential.cog.prompts.benchmark.hotpotqa import (\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_COT,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.prompts.benchmark.fever import (\n",
    "    FEVER_FEWSHOT_EXAMPLES_COT,\n",
    "    FEVER_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.prompts.benchmark.triviaqa import (\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_COT,\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.prompts.benchmark.ambignq import (\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_COT,\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.prompts.benchmark.gsm8k import (\n",
    "    GSM8K_FEWSHOT_EXAMPLES_COT,\n",
    "    GSM8K_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.prompts.benchmark.svamp import (\n",
    "    SVAMP_FEWSHOT_EXAMPLES_COT,\n",
    "    SVAMP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.prompts.benchmark.tabmwp import (\n",
    "    TABMWP_FEWSHOT_EXAMPLES_COT,\n",
    "    TABMWP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.prompts.benchmark.mbpp import (\n",
    "    MBPP_FEWSHOT_EXAMPLES_COT,\n",
    "    MBPP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.modules.reflect.reflexion import (\n",
    "    ReflexionCoTReflector,\n",
    "    ReflexionReActReflector,\n",
    ")\n",
    "import tiktoken\n",
    "from langchain_community.docstore.wikipedia import Wikipedia\n",
    "from agential.utils.docstore import DocstoreExplorer\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HotpotQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"VIVA Media AG changed it's name in 2004. What does their new acronym stand for?\"\n",
    "key = \"Gesellschaft mit beschränkter Haftung\"\n",
    "\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"hotpotqa\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=HOTPOTQA_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_HOTPOTQA, \n",
    "    reflect_examples=HOTPOTQA_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"VIVA Media AG changed it's name in 2004. What does their new acronym stand for?\"\n",
    "key = \"Gesellschaft mit beschränkter Haftung\"\n",
    "\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"hotpotqa\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=HOTPOTQA_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_HOTPOTQA, \n",
    "    reflect_examples=HOTPOTQA_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\"\n",
    "key = \"REFUTES\"\n",
    "\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"fever\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=FEVER_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_FEVER, \n",
    "    reflect_examples=FEVER_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_FEVER,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\"\n",
    "key = \"REFUTES\"\n",
    "\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"fever\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=FEVER_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_FEVER, \n",
    "    reflect_examples=FEVER_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_FEVER,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AmbigNQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did the simpsons first air on television?\"\n",
    "key = \"1989\"\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"ambignq\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=AMBIGNQ_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_AMBIGNQ, \n",
    "    reflect_examples=AMBIGNQ_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did the simpsons first air on television?\"\n",
    "key = \"1989\"\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"ambignq\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=AMBIGNQ_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_AMBIGNQ, \n",
    "    reflect_examples=AMBIGNQ_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriviaQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which American-born Sinclair won the Nobel Prize for Literature in 1930?\"\n",
    "key = \"Sinclair Lewis\"\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"triviaqa\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=TRIVIAQA_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_TRIVIAQA, \n",
    "    reflect_examples=TRIVIAQA_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which American-born Sinclair won the Nobel Prize for Literature in 1930?\"\n",
    "key = \"Sinclair Lewis\"\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"qa\": \"triviaqa\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=TRIVIAQA_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_TRIVIAQA, \n",
    "    reflect_examples=TRIVIAQA_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with 4933828. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\n",
    "key = -9867630\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm, \n",
    "    mode={\"math\": \"gsm8k\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1\n",
    ")\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=GSM8K_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_GSM8K,\n",
    "    reflect_examples=GSM8K_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_GSM8K,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with 4933828. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\n",
    "key = -9867630\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"math\": \"gsm8k\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=GSM8K_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_GSM8K, \n",
    "    reflect_examples=GSM8K_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_GSM8K,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"There are 87 oranges and 290 bananas in Philip's collection. If the bananas are organized into 2 groups and oranges are organized into 93 groups. How big is each group of bananas?\"\n",
    "key = 145\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm, \n",
    "    mode={\"math\": \"svamp\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=SVAMP_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_SVAMP,\n",
    "    reflect_examples=SVAMP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_SVAMP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"There are 87 oranges and 290 bananas in Philip's collection. If the bananas are organized into 2 groups and oranges are organized into 93 groups. How big is each group of bananas?\"\n",
    "key = 145\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"math\": \"svamp\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=SVAMP_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_SVAMP, \n",
    "    reflect_examples=SVAMP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_SVAMP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabMWP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Read the following table regarding \"Bowling Scores\" and then write Python code to answer a question:\n",
    "\n",
    "Name | Score\n",
    "Amanda | 117\n",
    "Sam | 236\n",
    "Irma | 144\n",
    "Mike | 164\n",
    "\n",
    "Question: Some friends went bowling and kept track of their scores. How many more points did Mike score than Irma?\"\"\"\n",
    "key = 20\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm, \n",
    "    mode={\"math\": \"tabmwp\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=TABMWP_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_TABMWP,\n",
    "    reflect_examples=TABMWP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_TABMWP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Read the following table regarding \"Bowling Scores\" and then write Python code to answer a question:\n",
    "\n",
    "Name | Score\n",
    "Amanda | 117\n",
    "Sam | 236\n",
    "Irma | 144\n",
    "Mike | 164\n",
    "\n",
    "Question: Some friends went bowling and kept track of their scores. How many more points did Mike score than Irma?\"\"\"\n",
    "key = 20\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"math\": \"tabmwp\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=TABMWP_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_TABMWP, \n",
    "    reflect_examples=TABMWP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_TABMWP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    max_steps=6,\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HumanEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MBPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Write a python function to find the first repeated character in a given string.\"\n",
    "key = \"\"\"assert first_repeated_char(\"abcabc\") == \"a\"\n",
    "assert first_repeated_char(\"abc\") == None\n",
    "assert first_repeated_char(\"123123\") == \"1\\\"\"\"\"\n",
    "\n",
    "agent = ReflexionCoTAgent(\n",
    "    llm=llm, \n",
    "    mode={\"code\": \"mbpp\"},\n",
    "    reflector=ReflexionCoTReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=MBPP_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_MBPP,\n",
    "    reflect_examples=MBPP_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_MBPP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={\"tests\": key},\n",
    "    reflect_additional_keys={\"tests\": key},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Write a python function to find the first repeated character in a given string.\"\n",
    "key = \"\"\"assert first_repeated_char(\"abcabc\") == \"a\"\n",
    "assert first_repeated_char(\"abc\") == None\n",
    "assert first_repeated_char(\"123123\") == \"1\\\"\"\"\"\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    llm=llm,\n",
    "    mode={\"code\": \"mbpp\"},\n",
    "    reflector=ReflexionReActReflector(llm=llm),\n",
    "    max_reflections=3,\n",
    "    max_trials=1,\n",
    "    max_steps=6,\n",
    "    max_tokens=5000,\n",
    "    enc=tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=MBPP_FEWSHOT_EXAMPLES_REACT,\n",
    "    prompt=REFLEXION_REACT_INSTRUCTION_MBPP,\n",
    "    reflect_examples=MBPP_FEWSHOT_EXAMPLES_REFLEXION_REACT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_REACT_REFLECT_INSTRUCTION_MBPP,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={\"tests\": key},\n",
    "    reflect_additional_keys={\"tests\": key},\n",
    "    max_trials=3,\n",
    "    patience=3,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
