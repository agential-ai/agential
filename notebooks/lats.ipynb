{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agential.cog.lats.agent import LATSAgent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from agential.utils.docstore import DocstoreExplorer\n",
    "\n",
    "from langchain_community.docstore.wikipedia import Wikipedia\n",
    "\n",
    "from agential.cog.fewshots.hotpotqa import (\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.fewshots.fever import (\n",
    "    FEVER_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.fewshots.triviaqa import (\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.fewshots.ambignq import (\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.fewshots.gsm8k import (\n",
    "    GSM8K_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.fewshots.svamp import (\n",
    "    SVAMP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.fewshots.tabmwp import (\n",
    "    TABMWP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.fewshots.humaneval import (\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.fewshots.mbpp import (\n",
    "    MBPP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.lats.prompts import (\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_HOTPOTQA,\n",
    "    LATS_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_LATS_VALUE, \n",
    "    LATS_VALUE_INSTRUCTION_HOTPOTQA,\n",
    "\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_AMBIGNQ,\n",
    "    LATS_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_LATS_VALUE, \n",
    "    LATS_VALUE_INSTRUCTION_AMBIGNQ,\n",
    "\n",
    "    FEVER_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_FEVER,\n",
    "    LATS_REFLECT_INSTRUCTION_FEVER,\n",
    "    FEVER_FEWSHOT_EXAMPLES_LATS_VALUE, \n",
    "    LATS_VALUE_INSTRUCTION_FEVER,\n",
    "\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_TRIVIAQA,\n",
    "    LATS_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_LATS_VALUE, \n",
    "    LATS_VALUE_INSTRUCTION_TRIVIAQA,\n",
    "\n",
    "    GSM8K_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_GSM8K,\n",
    "    LATS_REFLECT_INSTRUCTION_GSM8K,\n",
    "    GSM8K_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    LATS_VALUE_INSTRUCTION_GSM8K,\n",
    "\n",
    "    SVAMP_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_SVAMP,\n",
    "    LATS_REFLECT_INSTRUCTION_SVAMP,\n",
    "    SVAMP_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    LATS_VALUE_INSTRUCTION_SVAMP,\n",
    "\n",
    "    TABMWP_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_TABMWP,\n",
    "    LATS_REFLECT_INSTRUCTION_TABMWP,\n",
    "    TABMWP_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    LATS_VALUE_INSTRUCTION_TABMWP,\n",
    "\n",
    "    MBPP_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_MBPP,\n",
    "    LATS_REFLECT_INSTRUCTION_MBPP,\n",
    "    LATS_REFLECT_INSTRUCTION_MBPP,\n",
    "    LATS_VALUE_INSTRUCTION_MBPP,\n",
    "\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_HUMANEVAL,\n",
    "    LATS_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    "    LATS_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    "    LATS_VALUE_INSTRUCTION_HUMANEVAL,\n",
    ")\n",
    "\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HotpotQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"VIVA Media AG changed it's name in 2004. What does their new acronym stand for?\"\n",
    "key = \"Gesellschaft mit beschr√§nkter Haftung\"\n",
    "\n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"hotpotqa\", \n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "best_node, out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=HOTPOTQA_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=HOTPOTQA_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=HOTPOTQA_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_HOTPOTQA,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_HOTPOTQA,\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\"\n",
    "key = \"REFUTES\"\n",
    "\n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"fever\", \n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "best_node, out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=FEVER_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=FEVER_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=FEVER_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_FEVER,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_FEVER,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_FEVER,    \n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AmbigNQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did the simpsons first air on television?\"\n",
    "key = \"1989\"\n",
    "\n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"ambignq\", \n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "best_node, out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=AMBIGNQ_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=AMBIGNQ_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=AMBIGNQ_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_AMBIGNQ,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_AMBIGNQ,        \n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriviaQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which American-born Sinclair won the Nobel Prize for Literature in 1930?\"\n",
    "key = \"Sinclair Lewis\"\n",
    "\n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"triviaqa\", \n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "    \n",
    "best_node, out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=TRIVIAQA_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=TRIVIAQA_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=TRIVIAQA_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_TRIVIAQA,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_TRIVIAQA,            \n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with 4933828. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\n",
    "key = -9867630\n",
    "\n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"gsm8k\",\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "best_node, out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=GSM8K_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=GSM8K_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=GSM8K_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_GSM8K,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_GSM8K,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_GSM8K,            \n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"There are 87 oranges and 290 bananas in Philip's collection. If the bananas are organized into 2 groups and oranges are organized into 93 groups. How big is each group of bananas?\"\n",
    "key = 145\n",
    "    \n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"svamp\",\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "best_node, out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=SVAMP_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=SVAMP_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=SVAMP_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_SVAMP,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_SVAMP,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_SVAMP,            \n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabMWP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Read the following table regarding \"Bowling Scores\" and then write Python code to answer a question:\n",
    "\n",
    "Name | Score\n",
    "Amanda | 117\n",
    "Sam | 236\n",
    "Irma | 144\n",
    "Mike | 164\n",
    "\n",
    "Question: Some friends went bowling and kept track of their scores. How many more points did Mike score than Irma?\"\"\"\n",
    "key = 20\n",
    "\n",
    "\n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"tabmwp\",\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "best_node, out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=TABMWP_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=TABMWP_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=TABMWP_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_TABMWP,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_TABMWP,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_TABMWP,            \n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
