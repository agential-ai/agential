{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agential.cog.lats.agent import LATSAgent\n",
    "from agential.utils.docstore import DocstoreExplorer\n",
    "from agential.llm.llm import LLM\n",
    "\n",
    "from langchain_community.docstore.wikipedia import Wikipedia\n",
    "\n",
    "from agential.cog.fewshots.hotpotqa import (\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.fewshots.fever import (\n",
    "    FEVER_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.fewshots.triviaqa import (\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_REACT,\n",
    ") \n",
    "from agential.cog.fewshots.ambignq import (\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.fewshots.gsm8k import (\n",
    "    GSM8K_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.fewshots.svamp import (\n",
    "    SVAMP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.fewshots.tabmwp import (\n",
    "    TABMWP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.fewshots.humaneval import (\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.fewshots.mbpp import (\n",
    "    MBPP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.lats.prompts import (\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_HOTPOTQA,\n",
    "    LATS_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_LATS_VALUE, \n",
    "    LATS_VALUE_INSTRUCTION_HOTPOTQA,\n",
    "\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_AMBIGNQ,\n",
    "    LATS_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_LATS_VALUE, \n",
    "    LATS_VALUE_INSTRUCTION_AMBIGNQ,\n",
    "\n",
    "    FEVER_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_FEVER,\n",
    "    LATS_REFLECT_INSTRUCTION_FEVER,\n",
    "    FEVER_FEWSHOT_EXAMPLES_LATS_VALUE, \n",
    "    LATS_VALUE_INSTRUCTION_FEVER,\n",
    "\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_TRIVIAQA,\n",
    "    LATS_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_LATS_VALUE, \n",
    "    LATS_VALUE_INSTRUCTION_TRIVIAQA,\n",
    "\n",
    "    GSM8K_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_GSM8K,\n",
    "    LATS_REFLECT_INSTRUCTION_GSM8K,\n",
    "    GSM8K_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    LATS_VALUE_INSTRUCTION_GSM8K,\n",
    "\n",
    "    SVAMP_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_SVAMP,\n",
    "    LATS_REFLECT_INSTRUCTION_SVAMP,\n",
    "    SVAMP_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    LATS_VALUE_INSTRUCTION_SVAMP,\n",
    "\n",
    "    TABMWP_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_TABMWP,\n",
    "    LATS_REFLECT_INSTRUCTION_TABMWP,\n",
    "    TABMWP_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    LATS_VALUE_INSTRUCTION_TABMWP,\n",
    "\n",
    "    MBPP_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_MBPP,\n",
    "    LATS_REFLECT_INSTRUCTION_MBPP,\n",
    "    MBPP_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    LATS_VALUE_INSTRUCTION_MBPP,\n",
    "\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_HUMANEVAL,\n",
    "    LATS_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    LATS_VALUE_INSTRUCTION_HUMANEVAL,\n",
    ")\n",
    "\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "llm = LLM(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HotpotQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"VIVA Media AG changed it's name in 2004. What does their new acronym stand for?\"\n",
    "key = \"Gesellschaft mit beschr√§nkter Haftung\"\n",
    "\n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"hotpotqa\", \n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=HOTPOTQA_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=HOTPOTQA_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=HOTPOTQA_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_HOTPOTQA,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_HOTPOTQA,\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\"\n",
    "key = \"REFUTES\"\n",
    "\n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"fever\", \n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=FEVER_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=FEVER_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=FEVER_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_FEVER,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_FEVER,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_FEVER,    \n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AmbigNQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"When did the simpsons first air on television?\"\n",
    "key = \"1989\"\n",
    "\n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"ambignq\", \n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=AMBIGNQ_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=AMBIGNQ_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=AMBIGNQ_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_AMBIGNQ,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_AMBIGNQ,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_AMBIGNQ,        \n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TriviaQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which American-born Sinclair won the Nobel Prize for Literature in 1930?\"\n",
    "key = \"Sinclair Lewis\"\n",
    "\n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"triviaqa\", \n",
    "    docstore=DocstoreExplorer(Wikipedia()),\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "    \n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=TRIVIAQA_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=TRIVIAQA_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=TRIVIAQA_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_TRIVIAQA,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_TRIVIAQA,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_TRIVIAQA,            \n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with 4933828. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\n",
    "key = -9867630\n",
    "\n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"gsm8k\",\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=GSM8K_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=GSM8K_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=GSM8K_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_GSM8K,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_GSM8K,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_GSM8K,            \n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"There are 87 oranges and 290 bananas in Philip's collection. If the bananas are organized into 2 groups and oranges are organized into 93 groups. How big is each group of bananas?\"\n",
    "key = 145\n",
    "    \n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"svamp\",\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=SVAMP_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=SVAMP_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=SVAMP_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_SVAMP,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_SVAMP,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_SVAMP,            \n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabMWP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Read the following table regarding \"Bowling Scores\" and then write Python code to answer a question:\n",
    "\n",
    "Name | Score\n",
    "Amanda | 117\n",
    "Sam | 236\n",
    "Irma | 144\n",
    "Mike | 164\n",
    "\n",
    "Question: Some friends went bowling and kept track of their scores. How many more points did Mike score than Irma?\"\"\"\n",
    "key = 20\n",
    "\n",
    "\n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"tabmwp\",\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=TABMWP_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=TABMWP_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=TABMWP_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_TABMWP,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_TABMWP,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_TABMWP,            \n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HumanEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = {\"task_id\": \"HumanEval/0\", \"prompt\": \"from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \\\"\\\"\\\"\\n\", \"entry_point\": \"has_close_elements\", \"canonical_solution\": \"    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n\", \"test\": \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\\n\\n\"}\n",
    "question = inst['prompt']\n",
    "key = f\"{inst['test']}\\ncheck({inst['entry_point']})\"\n",
    "\n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"humaneval\",\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=HUMANEVAL_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=HUMANEVAL_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=HUMANEVAL_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_HUMANEVAL,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_HUMANEVAL,            \n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MBPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Write a python function to find the first repeated character in a given string.\"\n",
    "key = \"\"\"assert first_repeated_char(\"abcabc\") == \"a\"\n",
    "assert first_repeated_char(\"abc\") == None\n",
    "assert first_repeated_char(\"123123\") == \"1\\\"\"\"\"\n",
    "\n",
    "agent = LATSAgent(\n",
    "    llm=llm, \n",
    "    benchmark=\"mbpp\",\n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=MBPP_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=MBPP_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=MBPP_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_MBPP,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_MBPP,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_MBPP,            \n",
    "    additional_keys={\"tests\": key},\n",
    "    reflect_additional_keys={\"tests\": key},\n",
    "    value_additional_keys={\"tests\": key},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
