{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”Š Extract ðŸ”Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will focus on extracting audio (or transcript) along with any other useful metadata from the video. I'll mainly be using notebooks for experimentation and quick testing.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<ul>\n",
    "    <li>1. <a href=\"#setup\">Setup</a></li>\n",
    "    <li>\n",
    "        2. <a href=\"#extraction\">Extraction</a>\n",
    "        <ul>\n",
    "            <li>2.1. <a href=\"#extract-youtube-audio\">Extract YouTube Audio</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytube\n",
    "from pathlib import Path\n",
    "from pytube import YouTube\n",
    "\n",
    "import openai\n",
    "import langchain\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "from langchain.document_loaders.youtube import YoutubeLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Extract YouTube Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first extract the youtube audio.\n",
    "def to_snake_case(name):\n",
    "    return name.lower().replace(\" \", \"_\").replace(\":\", \"_\").replace(\"__\", \"_\")\n",
    "\n",
    "def download_youtube_audio(url, file_name=None, out_dir=\".\"):\n",
    "    \"Download the audio from a YouTube video\"\n",
    "    yt = YouTube(url)\n",
    "    if file_name is None:\n",
    "        file_name = Path(out_dir, to_snake_case(yt.title)).with_suffix(\".mp4\")\n",
    "    yt_stream = (yt.streams\n",
    "            .filter(only_audio=True, file_extension=\"mp4\")\n",
    "            .order_by(\"abr\")\n",
    "            .desc())\n",
    "    return yt_stream.first().download(filename=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://youtu.be/8ESJRRrVllI\"\n",
    "root = \"..\"\n",
    "out_dir = os.path.join(root, \"data\", \"external\", \"audio\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "audio = download_youtube_audio(url=url, out_dir=out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a different way to do the same thing. This time using LangChain.\n",
    "url = \"https://youtu.be/8ESJRRrVllI\"\n",
    "root = \"..\"\n",
    "out_dir = os.path.join(root, \"data\", \"external\", \"audio\")\n",
    "\n",
    "loader = GenericLoader(YoutubeAudioLoader(urls=[url], save_dir=out_dir), OpenAIWhisperParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://youtu.be/8ESJRRrVllI\n",
      "[youtube] 8ESJRRrVllI: Downloading webpage\n",
      "[youtube] 8ESJRRrVllI: Downloading ios player API JSON\n",
      "[youtube] 8ESJRRrVllI: Downloading android player API JSON\n",
      "[youtube] 8ESJRRrVllI: Downloading m3u8 information\n",
      "[info] 8ESJRRrVllI: Downloading 1 format(s): 140\n",
      "[download] ..\\data\\external\\audio\\Peggy Hillï¼š I forgot to add the meat.m4a has already been downloaded\n",
      "[download] 100% of  282.55KiB\n",
      "[ExtractAudio] Not converting audio ..\\data\\external\\audio\\Peggy Hillï¼š I forgot to add the meat.m4a; file is already in target format m4a\n",
      "Transcribing part 1!\n"
     ]
    }
   ],
   "source": [
    "a = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='My Sloppy Joe is all sloppy and no joke. I forgot to add the meat. How could I be so freaking stupid?', metadata={'source': '..\\\\data\\\\external\\\\audio\\\\Peggy Hillï¼š I forgot to add the meat.m4a', 'chunk': 0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=QsYGlZkevEg\", add_video_info=True\n",
    ")\n",
    "b = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_content': 'LADIES AND GENTLEMEN, PEDRO PASCAL! [ CHEERS AND APPLAUSE ] >> THANK YOU, THANK YOU. THANK YOU VERY MUCH. I\\'M SO EXCITED TO BE HERE. THANK YOU. I SPENT THE LAST YEAR SHOOTING A SHOW CALLED \"THE LAST OF US\" ON HBO. FOR SOME HBO SHOES, YOU GET TO SHOOT IN A FIVE STAR ITALIAN RESORT SURROUNDED BY BEAUTIFUL PEOPLE, BUT I SAID, NO, THAT\\'S TOO EASY. I WANT TO SHOOT IN A FREEZING CANADIAN FOREST WHILE BEING CHASED AROUND BY A GUY WHOSE HEAD LOOKS LIKE A GENITAL WART. IT IS AN HONOR BEING A PART OF THESE HUGE FRANCHISEs LIKE \"GAME OF THRONES\" AND \"STAR WARS,\" BUT I\\'M STILL GETTING USED TO PEOPLE RECOGNIZING ME. THE OTHER DAY, A GUY STOPPED ME ON THE STREET AND SAYS, MY SON LOVES \"THE MANDALORIAN\" AND THE NEXT THING I KNOW, I\\'M FACE TIMING WITH A 6-YEAR-OLD WHO HAS NO IDEA WHO I AM BECAUSE MY CHARACTER WEARS A MASK THE ENTIRE SHOW. THE GUY IS LIKE, DO THE MANDO VOICE, BUT IT\\'S LIKE A BEDROOM VOICE. WITHOUT THE MASK, IT JUST SOUNDS PORNY. PEOPLE WALKING BY ON THE STREET SEE ME WHISPERING TO A 6-YEAR-OLD KID. I CAN BRING YOU IN WARM, OR I CAN BRING YOU IN COLD. EVEN THOUGH I CAME TO THE U.S. WHEN I WAS LITTLE, I WAS BORN IN CHILE, AND I HAVE 34 FIRST COUSINS WHO ARE STILL THERE. THEY\\'RE VERY PROUD OF ME. I KNOW THEY\\'RE PROUD BECAUSE THEY GIVE MY PHONE NUMBER TO EVERY PERSON THEY MEET, WHICH MEANS EVERY DAY, SOMEONE IN SANTIAGO WILL TEXT ME STUFF LIKE, CAN YOU COME TO MY WEDDING, OR CAN YOU SING MY PRIEST HAPPY BIRTHDAY, OR IS BABY YODA MEAN IN REAL LIFE. SO I HAVE TO BE LIKE NO, NO, AND HIS NAME IS GROGU. BUT MY COUSINS WEREN\\'T ALWAYS SO PROUD. EARLY IN MY CAREER, I PLAYED SMALL PARTS IN EVERY CRIME SHOW. I EVEN PLAYED TWO DIFFERENT CHARACTERS ON \"LAW AND ORDER.\" TITO CABASSA WHO LOOKED LIKE THIS. AND ONE YEAR LATER, I PLAYED REGGIE LUCKMAN WHO LOOKS LIKE THIS. AND THAT, MY FRIENDS, IS CALLED RANGE. BUT IT IS AMAZING TO BE HERE, LIKE I SAID. I WAS BORN IN CHILE, AND NINE MONTHS LATER, MY PARENTS FLED AND BROUGHT ME AND MY SISTER TO THE U.S. THEY WERE SO BRAVE, AND WITHOUT THEM, I WOULDN\\'T BE HERE IN THIS WONDERFUL COUNTRY, AND I CERTAINLY WOULDN\\'T BE STANDING HERE WITH YOU ALL TONIGHT. SO TO ALL MY FAMILY WATCHING IN CHILE, I WANT TO SAY [ SPEAKING NON-ENGLISH ] WHICH MEANS, I LOVE YOU, I MISS YOU, AND STOP GIVING OUT MY PHONE NUMBER. WE\\'VE GOT AN AMAZING SHOW FOR YOU TONIGHT. COLDPLAY IS HERE, SO STICK',\n",
       " 'metadata': {'source': 'QsYGlZkevEg',\n",
       "  'title': 'Pedro Pascal Monologue - SNL',\n",
       "  'description': 'Unknown',\n",
       "  'view_count': 1756695,\n",
       "  'thumbnail_url': 'https://i.ytimg.com/vi/QsYGlZkevEg/hq720.jpg',\n",
       "  'publish_date': '2023-02-04 00:00:00',\n",
       "  'length': 224,\n",
       "  'author': 'Saturday Night Live'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Extract Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] 8ESJRRrVllI: Downloading webpage\n",
      "Obtaining frames\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from multiprocessing.pool import Pool\n",
    "\n",
    "import cv2\n",
    "import youtube_dl\n",
    "\n",
    "def process_video_parallel(url, skip_frames, process_number):\n",
    "    cap = cv2.VideoCapture(url)\n",
    "    num_processes = os.cpu_count()\n",
    "    frames_per_process = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) // num_processes\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frames_per_process * process_number)\n",
    "    x = 0\n",
    "    count = 0\n",
    "    while x < 10 and count < frames_per_process:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        filename =r\"PATH\\shot\"+str(x)+\".png\"\n",
    "        x += 1\n",
    "        cv2.imwrite(filename.format(count), frame)\n",
    "        count += skip_frames  # Skip 300 frames i.e. 10 seconds for 30 fps\n",
    "        cap.set(1, count)\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "\n",
    "video_url = \"https://youtu.be/8ESJRRrVllI\"  # The Youtube URL\n",
    "ydl_opts = {}\n",
    "ydl = youtube_dl.YoutubeDL(ydl_opts)\n",
    "info_dict = ydl.extract_info(video_url, download=False)\n",
    "\n",
    "formats = info_dict.get('formats', None)\n",
    "\n",
    "print(\"Obtaining frames\")\n",
    "for f in formats:\n",
    "    if f.get('format_note', None) == '144p':\n",
    "        url = f.get('url', None)\n",
    "        cpu_count = os.cpu_count()\n",
    "        with Pool(cpu_count) as pool:\n",
    "            pool.map(partial(process_video_parallel, url, 300), range(cpu_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'average_rating'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Testing getting stream.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFFXD417ugHM\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m video \u001b[39m=\u001b[39m pafy\u001b[39m.\u001b[39;49mnew(url)\n\u001b[0;32m      6\u001b[0m best \u001b[39m=\u001b[39m video\u001b[39m.\u001b[39mgetbest(preftype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmp4\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m capture \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(best\u001b[39m.\u001b[39murl)\n",
      "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\discussion-agents\\lib\\site-packages\\pafy\\pafy.py:124\u001b[0m, in \u001b[0;36mnew\u001b[1;34m(url, basic, gdata, size, callback, ydl_opts)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m        \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackend_youtube_dl\u001b[39;00m \u001b[39mimport\u001b[39;00m YtdlPafy \u001b[39mas\u001b[39;00m Pafy\n\u001b[1;32m--> 124\u001b[0m \u001b[39mreturn\u001b[39;00m Pafy(url, basic, gdata, size, callback, ydl_opts\u001b[39m=\u001b[39;49mydl_opts)\n",
      "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\discussion-agents\\lib\\site-packages\\pafy\\backend_youtube_dl.py:31\u001b[0m, in \u001b[0;36mYtdlPafy.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m ydl_opts:\n\u001b[0;32m     30\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ydl_opts\u001b[39m.\u001b[39mupdate(ydl_opts)\n\u001b[1;32m---> 31\u001b[0m \u001b[39msuper\u001b[39m(YtdlPafy, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\discussion-agents\\lib\\site-packages\\pafy\\backend_shared.py:97\u001b[0m, in \u001b[0;36mBasePafy.__init__\u001b[1;34m(self, video_url, basic, gdata, size, callback, ydl_opts)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpiry \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[39mif\u001b[39;00m basic:\n\u001b[1;32m---> 97\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_basic()\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m gdata:\n\u001b[0;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetch_gdata()\n",
      "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\discussion-agents\\lib\\site-packages\\pafy\\backend_youtube_dl.py:50\u001b[0m, in \u001b[0;36mYtdlPafy._fetch_basic\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_title \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ydl_info[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_author \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ydl_info[\u001b[39m'\u001b[39m\u001b[39muploader\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ydl_info[\u001b[39m'\u001b[39;49m\u001b[39maverage_rating\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_length \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ydl_info[\u001b[39m'\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_viewcount \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ydl_info[\u001b[39m'\u001b[39m\u001b[39mview_count\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'average_rating'"
     ]
    }
   ],
   "source": [
    "import pafy\n",
    "\n",
    "# Testing getting stream.\n",
    "url = \"FFXD417ugHM\"\n",
    "video = pafy.new(url)\n",
    "best = video.getbest(preftype=\"mp4\")\n",
    "\n",
    "capture = cv2.VideoCapture(best.url)\n",
    "while True:\n",
    "    grabbed, frame = capture.read()\n",
    "    print(\"a \", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discussion-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
