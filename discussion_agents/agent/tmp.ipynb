{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'update_broad_plan' from 'discussion_agents.planning.generative_agents' (C:\\Users\\tuvin\\OneDrive\\Desktop\\discussion-agents\\discussion_agents\\planning\\generative_agents.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tuvin\\OneDrive\\Desktop\\discussion-agents\\discussion_agents\\agent\\tmp.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tuvin/OneDrive/Desktop/discussion-agents/discussion_agents/agent/tmp.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchat_models\u001b[39;00m \u001b[39mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tuvin/OneDrive/Desktop/discussion-agents/discussion_agents/agent/tmp.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiscussion_agents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmemory\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgenerative_agents\u001b[39;00m \u001b[39mimport\u001b[39;00m GenerativeAgentMemory\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tuvin/OneDrive/Desktop/discussion-agents/discussion_agents/agent/tmp.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiscussion_agents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magent\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_agent\u001b[39;00m \u001b[39mimport\u001b[39;00m GenerativeAgent\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\discussion-agents\\discussion_agents\\agent\\base_agent.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain_experimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpydantic_v1\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel, Field\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiscussion_agents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmemory\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgenerative_agents\u001b[39;00m \u001b[39mimport\u001b[39;00m GenerativeAgentMemory\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiscussion_agents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplanning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgenerative_agents\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     generate_broad_plan,\n\u001b[0;32m     24\u001b[0m     generate_refined_plan,\n\u001b[0;32m     25\u001b[0m     update_broad_plan,\n\u001b[0;32m     26\u001b[0m     update_status,\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiscussion_agents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparse\u001b[39;00m \u001b[39mimport\u001b[39;00m remove_name\n\u001b[0;32m     31\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mGenerativeAgent\u001b[39;00m(BaseModel):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'update_broad_plan' from 'discussion_agents.planning.generative_agents' (C:\\Users\\tuvin\\OneDrive\\Desktop\\discussion-agents\\discussion_agents\\planning\\generative_agents.py)"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import faiss\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from discussion_agents.memory.generative_agents import GenerativeAgentMemory\n",
    "from discussion_agents.agent.base_agent import GenerativeAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevance_score_fn(score: float) -> float:\n",
    "    return 1.0 - score / math.sqrt(2)\n",
    "\n",
    "def create_new_memory_retriever():\n",
    "    embeddings_model = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "    embedding_size = 1536\n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    vectorstore = FAISS(\n",
    "        embeddings_model.embed_query,\n",
    "        index,\n",
    "        InMemoryDocstore({}),\n",
    "        {},\n",
    "        relevance_score_fn=relevance_score_fn,\n",
    "    )\n",
    "    return TimeWeightedVectorStoreRetriever(\n",
    "        vectorstore=vectorstore, other_score_keys=[\"importance\"], k=15\n",
    "    )\n",
    "\n",
    "\n",
    "LLM = ChatOpenAI(openai_api_key=openai_api_key, max_tokens=1500)\n",
    "\n",
    "memory = GenerativeAgentMemory(\n",
    "    llm=LLM,\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    verbose=False,\n",
    "    reflection_threshold=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeAgentMemory(llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.7, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=1500, tiktoken_model_name=None), memory_retriever=TimeWeightedVectorStoreRetriever(tags=None, metadata=None, vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x000001CDFED219C0>, search_kwargs={'k': 100}, memory_stream=[], decay_rate=0.01, k=15, other_score_keys=['importance'], default_salience=None), reflection_threshold=8.0, importance_weight=0.15, aggregate_importance=0.0, max_tokens_limit=1200, queries_key='queries', most_recent_memories_token_key='recent_memories_token', add_memory_key='add_memory', relevant_memories_key='relevant_memories', relevant_memories_simple_key='relevant_memories_simple', most_recent_memories_key='most_recent_memories', now_key='now', reflecting=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = [\n",
    "    \"Tommie remembers his dog, Bruno, from when he was a kid\",\n",
    "    \"Tommie feels tired from driving so far\",\n",
    "    \"Tommie sees the new home\",\n",
    "    \"The new neighbors have a cat\",\n",
    "    \"The road is noisy at night\",\n",
    "    \"Tommie is hungry\",\n",
    "    \"Tommie tries to get some rest.\",\n",
    "]\n",
    "for ob in obs:\n",
    "    memory.add_memories(ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Tommie remembers his dog, Bruno, from when he was a kid', metadata={'importance': 0.12, 'last_accessed_at': datetime.datetime(2023, 10, 16, 3, 7, 39, 533702), 'created_at': datetime.datetime(2023, 10, 16, 3, 7, 26, 736692), 'buffer_idx': 0}),\n",
       " Document(page_content='Tommie feels tired from driving so far', metadata={'importance': 0.03, 'last_accessed_at': datetime.datetime(2023, 10, 16, 3, 7, 39, 533702), 'created_at': datetime.datetime(2023, 10, 16, 3, 7, 28, 664805), 'buffer_idx': 1}),\n",
       " Document(page_content='Tommie sees the new home', metadata={'importance': 0.075, 'last_accessed_at': datetime.datetime(2023, 10, 16, 3, 7, 39, 533702), 'created_at': datetime.datetime(2023, 10, 16, 3, 7, 30, 135762), 'buffer_idx': 2}),\n",
       " Document(page_content='The new neighbors have a cat', metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2023, 10, 16, 3, 7, 39, 533702), 'created_at': datetime.datetime(2023, 10, 16, 3, 7, 36, 214066), 'buffer_idx': 3}),\n",
       " Document(page_content='The road is noisy at night', metadata={'importance': 0.06, 'last_accessed_at': datetime.datetime(2023, 10, 16, 3, 7, 39, 533702), 'created_at': datetime.datetime(2023, 10, 16, 3, 7, 37, 528309), 'buffer_idx': 4}),\n",
       " Document(page_content='Tommie is hungry', metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2023, 10, 16, 3, 7, 39, 533702), 'created_at': datetime.datetime(2023, 10, 16, 3, 7, 38, 851758), 'buffer_idx': 5}),\n",
       " Document(page_content='Tommie tries to get some rest.', metadata={'importance': 0.09, 'last_accessed_at': datetime.datetime(2023, 10, 16, 3, 7, 40, 675731), 'created_at': datetime.datetime(2023, 10, 16, 3, 7, 40, 675731), 'buffer_idx': 6})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.memory_retriever.memory_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = GenerativeAgent(\n",
    "    name=\"Tommie\",\n",
    "    age=25,\n",
    "    traits=\"anxious, likes design, talkative\",\n",
    "    lifestyle=\"\",\n",
    "    status=\"looking for a job\",\n",
    "    memory_retriever=create_new_memory_retriever(),\n",
    "    llm=LLM,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeAgent(name='Tommie', age=25, traits='anxious, likes design, talkative', lifestyle='', status='looking for a job', memory=GenerativeAgentMemory(llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.7, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=1500, tiktoken_model_name=None), memory_retriever=TimeWeightedVectorStoreRetriever(tags=None, metadata=None, vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x000001CDFED219C0>, search_kwargs={'k': 100}, memory_stream=[Document(page_content='Tommie remembers his dog, Bruno, from when he was a kid', metadata={'importance': 0.12, 'last_accessed_at': datetime.datetime(2023, 10, 16, 3, 7, 39, 533702), 'created_at': datetime.datetime(2023, 10, 16, 3, 7, 26, 736692), 'buffer_idx': 0}), Document(page_content='Tommie feels tired from driving so far', metadata={'importance': 0.03, 'last_accessed_at': datetime.datetime(2023, 10, 16, 3, 7, 39, 533702), 'created_at': datetime.datetime(2023, 10, 16, 3, 7, 28, 664805), 'buffer_idx': 1}), Document(page_content='Tommie sees the new home', metadata={'importance': 0.075, 'last_accessed_at': datetime.datetime(2023, 10, 16, 3, 7, 39, 533702), 'created_at': datetime.datetime(2023, 10, 16, 3, 7, 30, 135762), 'buffer_idx': 2}), Document(page_content='The new neighbors have a cat', metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2023, 10, 16, 3, 7, 39, 533702), 'created_at': datetime.datetime(2023, 10, 16, 3, 7, 36, 214066), 'buffer_idx': 3}), Document(page_content='The road is noisy at night', metadata={'importance': 0.06, 'last_accessed_at': datetime.datetime(2023, 10, 16, 3, 7, 39, 533702), 'created_at': datetime.datetime(2023, 10, 16, 3, 7, 37, 528309), 'buffer_idx': 4}), Document(page_content='Tommie is hungry', metadata={'importance': 0.045, 'last_accessed_at': datetime.datetime(2023, 10, 16, 3, 7, 39, 533702), 'created_at': datetime.datetime(2023, 10, 16, 3, 7, 38, 851758), 'buffer_idx': 5}), Document(page_content='Tommie tries to get some rest.', metadata={'importance': 0.09, 'last_accessed_at': datetime.datetime(2023, 10, 16, 3, 7, 40, 675731), 'created_at': datetime.datetime(2023, 10, 16, 3, 7, 40, 675731), 'buffer_idx': 6})], decay_rate=0.01, k=15, other_score_keys=['importance'], default_salience=None), reflection_threshold=8.0, importance_weight=0.15, aggregate_importance=0.46499999999999997, max_tokens_limit=1200, queries_key='queries', most_recent_memories_token_key='recent_memories_token', add_memory_key='add_memory', relevant_memories_key='relevant_memories', relevant_memories_simple_key='relevant_memories_simple', most_recent_memories_key='most_recent_memories', now_key='now', reflecting=False), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.7, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=1500, tiktoken_model_name=None), summary='', summary_refresh_seconds=3600, last_refreshed=datetime.datetime(2023, 10, 16, 3, 7, 41, 333684), plan_req={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discussion_agents.planning.generative_agents import (\n",
    "    generate_broad_plan,\n",
    "    update_status,\n",
    "    update_broad_plan,\n",
    "    generate_refined_plan,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"A table is considered reliable when it consistently provides accurate and relevant information. It should be able to withstand regular use and not break or collapse easily. The following steps outline Bob's plan in broad-strokes:\",\n",
       " 'Choose a sturdy table made of high-quality materials such as solid wood or metal',\n",
       " 'Ensure that the table is properly assembled and all joints and connections are secure',\n",
       " 'Check that the table has a flat and level surface, without any noticeable wobbling or unevenness',\n",
       " 'Verify that the table is of an appropriate size and shape to accommodate the intended use and the number of people or items it will hold',\n",
       " \"Test the table's weight capacity by placing heavy objects on it and ensuring it remains stable\",\n",
       " \"Consider the table's design and functionality, ensuring it meets Bob's specific needs and preferences\",\n",
       " 'Regularly clean and maintain the table to prevent damage or deterioration',\n",
       " 'Avoid placing excessive weight or overloading the table beyond its intended capacity',\n",
       " 'Handle the table with care and avoid any rough or careless use that may cause damage',\n",
       " 'Finally, periodically inspect the table for any signs of wear or damage and address them promptly to ensure its long-term reliability']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction = \"Describe what makes a table reliable.\"\n",
    "lifestyle = \"lazy, likes to sleep late\"\n",
    "name = \"Bob\"\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key)\n",
    "llm_kwargs = {}\n",
    "\n",
    "broad_plan = generate_broad_plan(\n",
    "    instruction=instruction,\n",
    "    lifestyle=lifestyle,\n",
    "    name=name,\n",
    "    llm=llm,\n",
    "    llm_kwargs=llm_kwargs,\n",
    "    memory=memory\n",
    ")\n",
    "broad_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Status: Bob is determined to choose a sturdy and durable table that is properly constructed and assembled with strong joints and secure fastenings. He understands the importance of selecting a table made from solid wood or metal to withstand potential misuse or negligence. Bob also recognizes the need to check the weight capacity and ensure the table can support the intended load without wobbling or collapsing. He plans to look for adjustable legs or supports for stability and will regularly inspect and maintain the table to address any loose or damaged parts promptly. Considering the table's design for his specific needs and preferences is also a priority for Bob. He intends to test the table's reliability by placing heavy objects on it and assess its stability. Choosing a reputable brand or manufacturer with positive customer reviews is essential to Bob's plan. Overall, he believes this comprehensive approach will help him find a reliable table that meets his requirements.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status = update_status(\n",
    "    previous_steps=broad_plan,\n",
    "    plan_step=broad_plan[1],\n",
    "    name=\"Bob\",\n",
    "    status=\"Sturdy and durable tables are reliable.\",\n",
    "    llm=llm,\n",
    "    llm_kwargs={},\n",
    "    memory=memory,\n",
    ")\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Choose a sturdy table made of high-quality materials such as solid wood, metal, or composite materials that are known for their durability and strength',\n",
       " 'Ensure that the table is properly assembled, with all joints and connections securely fastened. Avoid tables with loose or wobbly parts as they can compromise stability and reliability',\n",
       " 'Check that the table has a flat and level surface, free from any noticeable wobbling or unevenness. Uneven surfaces can lead to instability and make the table unreliable',\n",
       " 'Verify that the table is of an appropriate size and shape to accommodate the intended use and the number of people or items it will hold. Overcrowding the table can cause it to become unstable and prone to damage',\n",
       " \"Test the table's weight capacity by placing heavy objects on it and ensuring it remains stable. It should be able to support the expected load without sagging or showing signs of stress\",\n",
       " \"Consider the table's design and functionality, ensuring it meets specific needs and preferences. For example, if the table will be used for outdoor activities, it should be weather-resistant and able to withstand exposure to the elements\",\n",
       " \"Regularly clean and maintain the table to prevent damage or deterioration. Follow the manufacturer's recommendations for cleaning and care, and promptly address any spills, stains, or scratches\",\n",
       " 'Avoid placing excessive weight or overloading the table beyond its intended capacity. This can cause structural damage and compromise its reliability',\n",
       " 'Handle the table with care and avoid any rough or careless use that may cause damage. Use coasters or placemats to protect the surface from hot or sharp objects, and avoid dragging heavy items across the table',\n",
       " 'Periodically inspect the table for any signs of wear or damage and address them promptly to ensure its long-term reliability. This includes checking for loose screws, cracks, or any other issues that may compromise stability or functionality']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_broad_plan = update_broad_plan(\n",
    "    instruction=\"Describe what makes a table reliable.\", \n",
    "    name=\"Bob\",\n",
    "    plan=broad_plan,\n",
    "    llm=llm,\n",
    "    llm_kwargs={},\n",
    "    memory=memory,\n",
    ")\n",
    "updated_broad_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1) Choose a sturdy table made of high-quality materials such as solid wood or metal\\n1.1) Research and compare different types of materials used for tables\\n1.2) Look for tables that are known for their durability and strength\\n\\n2) Ensure that the table is properly assembled and all joints and connections are secure\\n2.1) Follow the manufacturer's instructions for assembly\\n2.2) Double-check all screws, bolts, and connections to ensure they are tightened properly\\n\\n3) Check that the table has a flat and level surface, without any noticeable wobbling or unevenness\\n3.1) Use a level to check if the table is flat\\n3.2) Place the table on a level surface and test for any wobbling or instability\\n\\n4) Verify that the table is of an appropriate size and shape to accommodate the intended use and the number of people or items it will hold\\n4.1) Determine the purpose of the table (e.g., dining, work, etc.) and the number of people it needs to accommodate\\n4.2) Measure the available space to ensure the table fits properly without overcrowding the area\\n\\n5) Test the table's weight capacity by placing heavy objects on it and ensuring it remains stable\\n5.1) Gradually add weight to the table, starting with lighter objects and gradually increasing the weight\\n5.2) Observe the table for any signs of instability or sagging under the weight\\n\\n6) Consider the table's design and functionality, ensuring it meets Bob's specific needs and preferences\\n6.1) Identify the specific features or functionalities Bob requires from the table (e.g., storage, adjustable height, etc.)\\n6.2) Compare different table designs and choose one that aligns with Bob's preferences and requirements\\n\\n7) Regularly clean and maintain the table to prevent damage or deterioration\\n7.1) Follow the manufacturer's instructions for cleaning and maintenance\\n7.2) Use appropriate cleaning products and techniques to keep the table in good condition\\n\\n8) Avoid placing excessive weight or overloading the table beyond its intended capacity\\n\\n9) Handle the table with care and avoid any rough or careless use that may cause damage\\n\\n10) Finally, periodically inspect the table for any signs of wear or damage and address them promptly to ensure its long-term reliability\\n10.1) Regularly inspect the table for any cracks, scratches, or other signs of damage\\n10.2) Fix any issues promptly by repairing or replacing damaged parts to maintain the table's reliability.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_plan = generate_refined_plan(\n",
    "    instruction=\"Describe what makes a table reliable.\",\n",
    "    plan=broad_plan,\n",
    "    name=\"Bob\",\n",
    "    llm=llm,\n",
    "    llm_kwargs={},\n",
    "    memory=memory\n",
    ")\n",
    "refined_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMChain\nprompt\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tuvin\\OneDrive\\Desktop\\discussion-agents\\discussion_agents\\agent\\tmp.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tuvin/OneDrive/Desktop/discussion-agents/discussion_agents/agent/tmp.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchat_models\u001b[39;00m \u001b[39mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tuvin/OneDrive/Desktop/discussion-agents/discussion_agents/agent/tmp.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m LLMChain(llm \u001b[39m=\u001b[39;49m ChatOpenAI(openai_api_key\u001b[39m=\u001b[39;49mopenai_api_key, max_tokens\u001b[39m=\u001b[39;49m\u001b[39m1500\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tuvin/OneDrive/Desktop/discussion-agents/discussion_agents/agent/tmp.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\discussion-agents\\lib\\site-packages\\langchain\\load\\serializable.py:75\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     76\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\discussion-agents\\lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for LLMChain\nprompt\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "LLMChain(llm = ChatOpenAI(openai_api_key=openai_api_key, max_tokens=1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Something:\n",
    "\n",
    "    name: str\n",
    "    age: int = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discussion-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
