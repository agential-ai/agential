{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import dotenv\n",
    "import os\n",
    "import joblib\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from typing import Dict, List\n",
    "\n",
    "from discussion_agents.cog.train.expel import (\n",
    "    # Experience Gathering.\n",
    "    gather_experience,\n",
    "    categorize_experiences,\n",
    "    get_folds,\n",
    "    # Insight Extraction.\n",
    "    _build_compare_prompt,\n",
    "    collapse_prompts,\n",
    "    _prompt_compare_critique,\n",
    "    parse_rules,\n",
    "    retrieve_rule_index,\n",
    "    is_existing_rule,\n",
    "    remove_err_operations,\n",
    "    update_rules,\n",
    ")\n",
    "from discussion_agents.utils.general import random_divide_list\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_rules = 20\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_key=openai_api_key)\n",
    "experiences = joblib.load(\"exp_15_compare_fake.joblib\")\n",
    "categories = categorize_experiences(experiences)\n",
    "folds = get_folds(categories, len(experiences['idxs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def create_rules(\n",
    "    llm: BaseChatModel,\n",
    "    experiences: Dict[str, List], \n",
    "    categories: Dict[str, int], \n",
    "    train_idxs: List[int], \n",
    "    rules: List[str], \n",
    "    rules_with_count: List[Tuple[str, int]],\n",
    "    max_num_rules: int,\n",
    ") -> Tuple[List[str], List[Tuple[str, int]]]:\n",
    "    # Intersect between train_idxs and each category (compare, success, fail).\n",
    "    train_category_idxs = {\n",
    "        category: list(set(train_idxs).intersection(set(category_idxs))) \\\n",
    "            for category, category_idxs in categories.items()\n",
    "    }\n",
    "\n",
    "    # Compare.\n",
    "    for train_idx in train_category_idxs[\"compare\"]:\n",
    "        question = experiences[\"questions\"][train_idx]\n",
    "        trajectory = experiences[\"trajectories\"][train_idx]\n",
    "\n",
    "        # Compare the successful trial with all previous failed trials.\n",
    "        success_trial = trajectory[-1][-1]\n",
    "        for failed_trial in trajectory[:-1]:\n",
    "            out = _prompt_compare_critique(\n",
    "                rules, \n",
    "                question, \n",
    "                success_trial, \n",
    "                failed_trial, \n",
    "                max_num_rules < len(rules_with_count),\n",
    "                llm\n",
    "            )\n",
    "            operations = parse_rules(out)\n",
    "            operations = remove_err_operations(rules_with_count, operations)\n",
    "\n",
    "            # Update rules_with_count and rules with comparison insights.\n",
    "            rules_with_count = update_rules(rules_with_count, operations, is_full=max_num_rules+5 <= len(rules_with_count))\n",
    "            rules = [rule[0] for rule in rules_with_count]\n",
    "\n",
    "    # Success.\n",
    "    for train_idx in train_category_idxs[\"success\"]:\n",
    "        question = experiences[\"questions\"][train_idx]\n",
    "        trajectory = experiences[\"trajectories\"][train_idx]\n",
    "\n",
    "    return rules, rules_with_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1, 2, 6, 9, 12, 14]\n"
     ]
    }
   ],
   "source": [
    "rules, rules_with_count = [], []\n",
    "for fold, train_idxs in folds.items():\n",
    "    print(fold, train_idxs)\n",
    "    rules, rules_with_count = create_rules(llm, experiences, categories, train_idxs, rules, rules_with_count, max_num_rules)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compare': [12, 14], 'success': [1, 6], 'fail': [9, 2]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_category_idxs = {\n",
    "    category: list(set(train_idxs).intersection(set(category_idxs))) \\\n",
    "        for category, category_idxs in categories.items()\n",
    "}\n",
    "train_category_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 6]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from discussion_agents.utils.general import random_divide_list\n",
    "\n",
    "success_critique_num = 8\n",
    "batched_success_trajs_idxs = random_divide_list(train_category_idxs['success'], success_critique_num)\n",
    "batched_success_trajs_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 6]\n",
      "it works\n"
     ]
    }
   ],
   "source": [
    "for success_idxs in batched_success_trajs_idxs:\n",
    "    print(success_idxs)\n",
    "\n",
    "    concat_success_trajs = [\n",
    "        f\"{experiences['questions'][idx]}\\n{experiences['trajectories'][idx][0][-1]}\"\n",
    "        for idx in success_idxs\n",
    "    ]\n",
    "    success_trajs_str = \"\\n\\n\".join(concat_success_trajs)\n",
    "    print(\"it works\")\n",
    "\n",
    "    concat_success_trajs = []\n",
    "    for idx in success_idxs:\n",
    "        question = experiences[\"questions\"][idx]\n",
    "        trajectory = experiences['trajectories'][idx]\n",
    "        out = question + \"\\n\" + trajectory[0][-1]  # Get this successful trajectory's zero-th trial output.\n",
    "        concat_success_trajs.append(out)\n",
    "    _success_trajs_str = \"\\n\\n\".join(concat_success_trajs)\n",
    "\n",
    "    # success_trials = '\\n\\n'.join([self.remove_task_suffix(task) + '\\n' + trajectory for task, trajectory in success_chunk])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idx in train_category_idxs[\"success\"]:\n",
    "    question = experiences[\"questions\"][train_idx]\n",
    "    trajectory = experiences[\"trajectories\"][train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_critique_num = 8\n",
    "\n",
    "\n",
    "all_success = random_divide_list(all_success, self.success_critique_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discussion-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
