{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discussion_agents.cog.agent.reflexion import ReflexionReActAgent\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_key=openai_api_key)\n",
    "\n",
    "question = \"VIVA Media AG changed it's name in 2004. What does their new acronym stand for?\"\n",
    "key = \"Gesellschaft mit beschränkter Haftung\"\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    self_reflect_llm=llm,\n",
    "    action_llm=llm,\n",
    "    max_steps=7,\n",
    "    max_trials=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>type</th>\n",
       "      <th>level</th>\n",
       "      <th>supporting_facts</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a7613c15542994ccc9186bf</td>\n",
       "      <td>VIVA Media AG changed it's name in 2004. What ...</td>\n",
       "      <td>Gesellschaft mit beschränkter Haftung</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'title': ['VIVA Media', 'Gesellschaft mit bes...</td>\n",
       "      <td>{'title': ['Constantin Medien', 'VIVA Poland',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5adf2fa35542993344016c11</td>\n",
       "      <td>Which of Jonny Craig and Pete Doherty has been...</td>\n",
       "      <td>Jonny\" Craig</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'title': ['Jonny Craig', 'Jonny Craig', 'Pete...</td>\n",
       "      <td>{'title': ['Pete Doherty', 'Relativity (Emaros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5adfdef9554299025d62a36b</td>\n",
       "      <td>Where was the first governor after the The Mis...</td>\n",
       "      <td>Bath, Maine</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'title': ['Maine gubernatorial election, 1820...</td>\n",
       "      <td>{'title': ['Compromise of 1790', 'Anti-Nebrask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5a7180205542994082a3e856</td>\n",
       "      <td>The creator of \"Wallace and Gromit\" also creat...</td>\n",
       "      <td>Creature Comforts</td>\n",
       "      <td>bridge</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'title': ['Creature Comforts', 'Creature Comf...</td>\n",
       "      <td>{'title': ['Creature Comforts', 'Tata Steel Zo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a78bc6b554299148911f979</td>\n",
       "      <td>Woman's Era and Naj are what kind of magazines?</td>\n",
       "      <td>fortnightly women interest magazine</td>\n",
       "      <td>comparison</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'title': ['Woman's Era', 'Naj'], 'sent_id': [...</td>\n",
       "      <td>{'title': ['Lifestyle trends and media', 'Chin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  5a7613c15542994ccc9186bf   \n",
       "1  5adf2fa35542993344016c11   \n",
       "2  5adfdef9554299025d62a36b   \n",
       "3  5a7180205542994082a3e856   \n",
       "4  5a78bc6b554299148911f979   \n",
       "\n",
       "                                            question  \\\n",
       "0  VIVA Media AG changed it's name in 2004. What ...   \n",
       "1  Which of Jonny Craig and Pete Doherty has been...   \n",
       "2  Where was the first governor after the The Mis...   \n",
       "3  The creator of \"Wallace and Gromit\" also creat...   \n",
       "4    Woman's Era and Naj are what kind of magazines?   \n",
       "\n",
       "                                  answer        type level  \\\n",
       "0  Gesellschaft mit beschränkter Haftung      bridge  hard   \n",
       "1                           Jonny\" Craig  comparison  hard   \n",
       "2                            Bath, Maine      bridge  hard   \n",
       "3                      Creature Comforts      bridge  hard   \n",
       "4    fortnightly women interest magazine  comparison  hard   \n",
       "\n",
       "                                    supporting_facts  \\\n",
       "0  {'title': ['VIVA Media', 'Gesellschaft mit bes...   \n",
       "1  {'title': ['Jonny Craig', 'Jonny Craig', 'Pete...   \n",
       "2  {'title': ['Maine gubernatorial election, 1820...   \n",
       "3  {'title': ['Creature Comforts', 'Creature Comf...   \n",
       "4  {'title': ['Woman's Era', 'Naj'], 'sent_id': [...   \n",
       "\n",
       "                                             context  \n",
       "0  {'title': ['Constantin Medien', 'VIVA Poland',...  \n",
       "1  {'title': ['Pete Doherty', 'Relativity (Emaros...  \n",
       "2  {'title': ['Compromise of 1790', 'Anti-Nebrask...  \n",
       "3  {'title': ['Creature Comforts', 'Tata Steel Zo...  \n",
       "4  {'title': ['Lifestyle trends and media', 'Chin...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "hotpot = joblib.load('../agent/hotpot-qa-distractor-sample.joblib').reset_index(drop=True)\n",
    "hotpot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "\n",
    "def gather_experience(\n",
    "    reflexion_react_agent: ReflexionReActAgent,\n",
    "    questions: List[str],\n",
    "    keys: List[str],\n",
    "    strategy: Optional[str] = \"reflexion\",\n",
    ") -> Dict[str, List]:\n",
    "    experiences = {\n",
    "        \"idxs\": [],\n",
    "        \"questions\": [],\n",
    "        \"keys\": [],\n",
    "        \"trajectories\": [],\n",
    "        \"reflections\": []\n",
    "    }\n",
    "    for idx, (question, key) in enumerate(zip(questions, keys)):\n",
    "        trajectory = reflexion_react_agent.generate(\n",
    "            question=question, key=key, strategy=strategy, reset=True\n",
    "        )\n",
    "\n",
    "        experiences[\"idxs\"].append(idx)\n",
    "        experiences[\"questions\"].append(question)\n",
    "        experiences[\"keys\"].append(key)\n",
    "        experiences[\"trajectories\"].append(trajectory)\n",
    "        experiences[\"reflections\"].append(agent.reflector.reflections)\n",
    "        \n",
    "    return experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tuvin\\anaconda3\\envs\\discussion-agents\\lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\tuvin\\anaconda3\\envs\\discussion-agents\\lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "agent = ReflexionReActAgent(\n",
    "    self_reflect_llm=llm,\n",
    "    action_llm=llm,\n",
    "    max_steps=7,\n",
    "    max_trials=3,\n",
    ")\n",
    "\n",
    "experiences = gather_experience(agent, questions=hotpot.question.values.tolist()[:k], keys=hotpot.answer.values.tolist()[:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_eval_idx_list(agent_dict, n_folds: int):\n",
    "    \"\"\"\n",
    "    Gets the split evaluation index list.\n",
    "    \n",
    "    Args:\n",
    "        agent_dict: The agent dictionary.\n",
    "        n_folds: The number of folds.\n",
    "    \n",
    "    Returns:\n",
    "        The split evaluation index list.\n",
    "    \"\"\"\n",
    "    eval_idx_list = [[] for _ in range(n_folds)]\n",
    "    env_names = set(x['env_name'] for x in agent_dict['tasks'])\n",
    "    print(env_names)\n",
    "    task2idx = agent_dict['task2idx']\n",
    "    print(task2idx)\n",
    "\n",
    "    # Compare, Success, Fail.\n",
    "    compare_dict = {env_name: [] for env_name in env_names}\n",
    "    success_dict = {env_name: [] for env_name in env_names}\n",
    "    fail_dict = {env_name: [] for env_name in env_names}\n",
    "    for task, trials in agent_dict['succeeded_trial_history'].items():\n",
    "        if len(trials) > 0:\n",
    "            if len(agent_dict['failed_trial_history'][task]) > 0:\n",
    "                compare_dict[get_env_name_from_task(task, agent_dict['benchmark_name'])].append(task2idx[task])\n",
    "            else:\n",
    "                success_dict[get_env_name_from_task(task, agent_dict['benchmark_name'])].append(task2idx[task])\n",
    "        else:\n",
    "            assert len(agent_dict['failed_trial_history'][task]) > 0\n",
    "            fail_dict[get_env_name_from_task(task, agent_dict['benchmark_name'])].append(task2idx[task])\n",
    "\n",
    "    # split into n_folds\n",
    "    j = 0\n",
    "    a = list(compare_dict.values()) + list(success_dict.values()) + list(fail_dict.values())\n",
    "    print(a)\n",
    "    for idx_list in a:\n",
    "        random.shuffle(idx_list)\n",
    "        for idx in idx_list:\n",
    "            eval_idx_list[j % n_folds].append(idx)\n",
    "            j += 1\n",
    "    \n",
    "    assert set.intersection(*[set(x) for x in eval_idx_list]) == set()\n",
    "    \n",
    "    return eval_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = joblib.load(\"experiences_5.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compare': [], 'success': [3], 'fail': [0, 1, 2, 4]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_experiences(experiences: Dict[str, List]) -> Dict[str, List]:\n",
    "    count_dict = {\n",
    "        \"compare\": [],\n",
    "        \"success\": [],\n",
    "        \"fail\": []\n",
    "    }\n",
    "\n",
    "    for idx in experiences[\"idxs\"]:  # Index for a particular task.\n",
    "        trajectory = experiences[\"trajectories\"][idx]\n",
    "        trials_are_correct = [trial[0] for trial in trajectory]  # (is_correct, answer, output)[0]\n",
    "\n",
    "        # Success.\n",
    "        if all(trials_are_correct) and len(trials_are_correct) == 1:  # If success @ first trial, then stop generation.\n",
    "            count_dict[\"success\"].append(idx)\n",
    "        # Compare.\n",
    "        elif trials_are_correct[-1]:  # If fail(s), then succeeds, then only last trial is True.\n",
    "            count_dict[\"compare\"].append(idx)\n",
    "        # Fail.\n",
    "        elif not all(trials_are_correct):  # All trials failed, then fail case.\n",
    "            count_dict[\"fail\"].append(idx)\n",
    "        else:\n",
    "            raise ValueError(f\"Unhandled scenario for trajectory at index {idx}.\")\n",
    "\n",
    "    return count_dict\n",
    "\n",
    "groups = group_experiences(experiences)\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [3, 0, 2], 1: [1, 4]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_folds = 2\n",
    "\n",
    "X = range(len(experiences['idxs']))\n",
    "y = [0] * len(experiences['idxs'])\n",
    "\n",
    "group_labels = dict(zip(groups.keys(), range(len(groups))))\n",
    "\n",
    "folds = {fold: [] for fold in range(n_folds)}\n",
    "\n",
    "# Assign labels for 'compare', 'success', and  'fail'.\n",
    "for group_name, indices in groups.items():\n",
    "    for count, idx in enumerate(indices):\n",
    "        folds[count % n_folds].append(idx)\n",
    "\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StratifiedShuffleSplit\n\u001b[0;32m      3\u001b[0m sss \u001b[38;5;241m=\u001b[39m StratifiedShuffleSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train_index, test_index) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sss\u001b[38;5;241m.\u001b[39msplit(X, y)):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Train: index=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\discussion-agents\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1746\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1716\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1745\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1746\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32mc:\\Users\\tuvin\\anaconda3\\envs\\discussion-agents\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2147\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2145\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y_indices)\n\u001b[0;32m   2146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(class_counts) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 2147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m member, which is too few. The minimum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of groups for any class cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be less than 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2152\u001b[0m     )\n\u001b[0;32m   2154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[0;32m   2155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   2158\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=2, test_size=0.5, random_state=42)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discussion-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
