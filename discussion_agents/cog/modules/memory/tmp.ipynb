{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import dotenv\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from discussion_agents.cog.functional.expel import (\n",
    "    categorize_experiences,\n",
    "    get_folds,\n",
    "    create_rules,\n",
    ")\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = joblib.load(\"../../../../tests/assets/expel/expel_experiences_10_fake.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Tuple, Optional, Union\n",
    "from discussion_agents.cog.modules.memory.base import BaseMemory\n",
    "\n",
    "class ExpeLExperienceMemory(BaseMemory):\n",
    "    def __init__(\n",
    "        self,\n",
    "        questions: Optional[List[str]] = [],\n",
    "        keys: Optional[List[str]] = [],\n",
    "        trajectories: Optional[List[List[Tuple[bool, str, List[Tuple[str, str, str]]]]]] = [],\n",
    "        reflections: Optional[List[List[str]]] = []\n",
    "    ) -> None:\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(questions) == len(keys) == len(trajectories)\n",
    "\n",
    "        if reflections:\n",
    "            assert len(reflections) == len(questions)\n",
    "        else:\n",
    "            reflections = [[] for _ in range(len(questions))]\n",
    "\n",
    "        self.experiences = {\n",
    "            \"idxs\": list(range(len(questions))),\n",
    "            \"questions\": questions,\n",
    "            \"keys\": keys,\n",
    "            \"trajectories\": trajectories,\n",
    "            \"reflections\": reflections\n",
    "        }\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.experiences = {\n",
    "            \"idxs\": [],\n",
    "            \"questions\": [],\n",
    "            \"keys\": [],\n",
    "            \"trajectories\": [],\n",
    "            \"reflections\": []\n",
    "        }\n",
    "\n",
    "    def add_memories(\n",
    "        self, \n",
    "        questions: List[str], \n",
    "        keys: List[str], \n",
    "        trajectories: List[List[Tuple[bool, str, List[Tuple[str, str, str]]]]],\n",
    "        reflections: Optional[List[List[str]]] = []\n",
    "    ) -> None:\n",
    "        assert len(questions) == len(keys) == len(trajectories)\n",
    "\n",
    "        self.experiences['idxs'].extend(\n",
    "            list(\n",
    "                range(\n",
    "                    len(self.experiences['idxs']),\n",
    "                    len(self.experiences['idxs']) + len(questions)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        self.experiences[\"questions\"].extend(questions)\n",
    "        self.experiences[\"keys\"].extend(keys)\n",
    "        self.experiences[\"trajectories\"].extend(trajectories)\n",
    "        \n",
    "        if reflections:\n",
    "            assert len(reflections) == len(questions)\n",
    "        else:\n",
    "            reflections = [[] for _ in range(len(questions))]\n",
    "        self.experiences[\"reflections\"].extend(reflections)\n",
    "\n",
    "    def load_memories(self, idxs: Union[List[int], int]) -> Dict[str, Any]:\n",
    "        if isinstance(idxs, int): \n",
    "            idxs = [idxs]            \n",
    "\n",
    "        return {\n",
    "            'questions': [self.experiences['questions'][idx] for idx in idxs],\n",
    "            'keys': [self.experiences['keys'][idx] for idx in idxs],\n",
    "            'trajectories': [self.experiences['trajectories'][idx] for idx in idxs],\n",
    "            'reflections': [self.experiences['reflections'][idx] for idx in idxs],\n",
    "        }\n",
    "\n",
    "    def show_memories(self) -> Dict[str, Any]:\n",
    "        return self.experiences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "a.extend([\"k\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflections = [[] for _ in range(len(a))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reflections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discussion-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
