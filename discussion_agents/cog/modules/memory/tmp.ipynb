{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tuvin\\anaconda3\\envs\\discussion-agents\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import dotenv\n",
    "import os\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "from discussion_agents.cog.modules.memory.expel import ExpeLExperienceMemory\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = joblib.load(\"../../../../tests/assets/expel/expel_experiences_10_fake.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discussion_agents.cog.prompts.react import REACT_WEBTHINK_SIMPLE6_FEWSHOT_EXAMPLES\n",
    "\n",
    "fewshot_questions = re.findall(r'Question: (.+?)\\n', REACT_WEBTHINK_SIMPLE6_FEWSHOT_EXAMPLES)\n",
    "fewshot_keys = re.findall(r'Action \\d+: Finish\\[(.+?)\\]', REACT_WEBTHINK_SIMPLE6_FEWSHOT_EXAMPLES)\n",
    "blocks = re.split(r'(?=Question: )', REACT_WEBTHINK_SIMPLE6_FEWSHOT_EXAMPLES)[1:]  # Split and ignore the first empty result\n",
    "\n",
    "fewshot_examples = []\n",
    "for block in blocks:\n",
    "    # Extract all thoughts, actions, and observations within each block\n",
    "    thoughts = re.findall(r'(Thought \\d+: .+?)\\n', block)\n",
    "    actions = re.findall(r'(Action \\d+: .+?)\\n', block)\n",
    "    observations = re.findall(r'(Observation \\d+: .+)', block)\n",
    "    \n",
    "    # Combine them into tuples and add to the examples list\n",
    "    fewshot_examples.append(list(zip(thoughts, actions, observations)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ExpeLExperienceMemory(experiences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n",
      "1245\n"
     ]
    }
   ],
   "source": [
    "for i in range(38):\n",
    "    a = memory._fewshot_doc_token_count(memory.success_traj_docs[i])\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {\n",
    "    \"task\": 'The creator of \"Wallace and Gromit\" also created what animation comedy that matched animated zoo animals with a soundtrack of people talking about their homes? ',\n",
    "    \"thought\": 'Thought: I should try a different approach. Let me search for press releases, industry news sources, or announcements specifically related to the name change and new acronym for VIVA Media AG in 2004. By focusing on more specialized sources, I may be able to find the accurate information needed to answer the question correctly. '\n",
    "}\n",
    "docs = memory.load_memories(queries=queries, query_type=\"task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discussion-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
