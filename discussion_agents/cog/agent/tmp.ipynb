{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import dotenv\n",
    "import os\n",
    "from discussion_agents.cog.agent.reflexion import ReflexionReActAgent\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_key=openai_api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given we change the examples/prompts for agent/reflect, what changes must be made?\n",
    "- the states of the agent\n",
    "\n",
    "The states of the reflexion react agent are: reflector and memory\n",
    "- memory stores scratchpad info only\n",
    "- reflector stores reflections only\n",
    "\n",
    "Given the above context, if we modify the examples, prompt, reflect_examples, and reflect_prompt, what happens to the agent states?\n",
    "- if we modify both/either examples or prompt, the input to the llm for prompting the agent is diff but\n",
    "the outputs won't differ; memory stores scratchpad (output) only so no change here; reflector does not change in this case\n",
    "- if we modify both/either examples or prompt, the input to the llm reflect is diff but \n",
    "the outputs won't differ; reflector stores reflections (output) only so no change here; memory does not store reflections\n",
    "\n",
    "So memory and reflection don't bleed into each other. They are mutually exclusive? Yes.\n",
    "\n",
    "If I make changes in the prompt for the agent (examples/prompt), should these changes be reflected in the prompt for reflection?\n",
    "For example, if I include \"insights\" or fewshot examples in the prompt for the agent, shouldn't these also be present in the \n",
    "prompt input during reflection?\n",
    "\n",
    "Reflection takes in \"question\", \"examples\", \"reflections\". In this case, examples refers to fewshot reflection examples not the ones used \n",
    "in the prompting for the agent. I notice in original react and reflexion, they don't include these fewshot examples in reflection and it\n",
    "wouldn't make much sense to anyways. It's not relevant context for the sake of reflection.\n",
    "\n",
    "What about insights? That's slightly different from reflections, shouldn't that be included in the prompts for reflection (since it's\n",
    "used for prompting the agent). This does make slight sense, except these insights are meant to be fixed and not updated (unless it's done by\n",
    "the expel insight extraction stage 2 process) by the llm during reflection. So if it were to be included during reflexion, it would be static/fixed.\n",
    "\n",
    "Ok, but then if it's static/fixed in the reflection prompt, don't you think it'll help out the reflection process? \n",
    "\n",
    "The ExpeL paper uses basic ReAct during stage 3 evaluation. I have no idea how they would go about it with reflexion + react. That being said,\n",
    "generally, nothing in the input to the prompt agent is used as input to the reflect component of reflexion. This is true for CoT and react.\n",
    "\n",
    "Hmmmmmm, then what's stopping you from incorporating these insights into the prompt? Well, first off, we know that these insights shouldn't be \n",
    "part of the reflection output/reflector class state. But now it begs the question: should it be part of the input to the reflection component?\n",
    "\n",
    "My answer is a bit mixed on this. It makes sense to include it, but generally you don't include input to prompt agent as the input to the reflection process.\n",
    "\n",
    "It kinda makes sense that the insights would aid in the reflection process, but then how would this even look? Well, the reflect prompt\n",
    "would probably have either a new argument (unlikely) or the insights are appended to the examples (probably the case). The problem is\n",
    "the reflector should be focused on the reflection process. These insights aid in inference not reflection. That's what they're geared for.\n",
    "\n",
    "I'm leaning towards no. if it is yes, then it would have to be appended to the examples or we could have kwargs (but this gets complicated\n",
    "very quickly; let's stay away from this).\n",
    "\n",
    "So if we do do it, it must be through appending the examples. Though I don't think this matters because we won't do this. It wouldn't make\n",
    "sense. The insights are for inference not for reflection, but then again, the insights would be partially responsible for inference output.\n",
    "\n",
    "Ok, I think I won't do it. But, to be comprehensive, is there harm in providing the option to do that? No. Let's just implement something and see where this takes us. oK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "\n",
    "hotpotqa = joblib.load('../../../tests/assets/hotpotqa/hotpot-qa-distractor-sample.joblib')\n",
    "experiences = joblib.load('../../../tests/assets/expel/expel_experiences_10_fake.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ExpeLAgent(\n",
    "    llm=llm,\n",
    "    self_reflect_llm=llm,\n",
    "    action_llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discussion_agents.cog.prompts.react import REACT_WEBTHINK_SIMPLE6_FEWSHOT_EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == REACT_WEBTHINK_SIMPLE6_FEWSHOT_EXAMPLES + \"\\n(END OF EXAMPLES)\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"\n",
    "Here are some examples:\n",
    "{examples}\n",
    "(END OF EXAMPLES)\n",
    "\"\"\"\n",
    "\n",
    "b = f\"\"\"\n",
    "Here are some examples:\n",
    "{REACT_WEBTHINK_SIMPLE6_FEWSHOT_EXAMPLES}\n",
    "\"\"\" + \\\n",
    "\"(END OF EXAMPLES)\\n\"\n",
    "\n",
    "a.format(examples=REACT_WEBTHINK_SIMPLE6_FEWSHOT_EXAMPLES) == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discussion_agents.cog.agent.reflexion import ReflexionReActAgent\n",
    "\n",
    "reflexion_agent = ReflexionReActAgent(\n",
    "    self_reflect_llm=llm,\n",
    "    action_llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflexion_agent.generate(\n",
    "    hotpotqa.iloc[0].question,\n",
    "    hotpotqa.iloc[0].answer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.insight_memory.insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.gather_experience(\n",
    "    questions=hotpotqa.question.values[:1],\n",
    "    keys=hotpotqa.answer.values[:1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.insight_memory.insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.experience_memory.experiences['trajectories'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.experience_memory.success_traj_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.experience_memory.vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.insight_memory.insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discussion-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
