{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import alfworld\n",
    "import alfworld.agents.environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Base memory interface class.\"\"\"\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, Dict\n",
    "\n",
    "\n",
    "class BaseMemory(ABC):\n",
    "    \"\"\"Base memory class providing a general interface for memory operations.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def clear(self, *args: Any, **kwargs: Any) -> None:\n",
    "        \"\"\"Clear all memories.\n",
    "\n",
    "        Implementations should override this method to provide the functionality\n",
    "        to clear memories. Specific parameters and return types depend on the implementation.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def add_memories(self, *args: Any, **kwargs: Any) -> None:\n",
    "        \"\"\"Add memories.\n",
    "\n",
    "        Implementations should override this method to provide the functionality\n",
    "        to add memories. Specific parameters and return types depend on the implementation.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_memories(self, *args: Any, **kwargs: Any) -> Dict[str, Any]:\n",
    "        \"\"\"Load memories and return a dictionary.\n",
    "\n",
    "        Implementations should override this method to provide the functionality\n",
    "        to load memories. Specific parameters and return types depend on the implementation.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def show_memories(self, *args: Any, **kwargs: Any) -> Dict[str, Any]:\n",
    "        \"\"\"Show all memories.\n",
    "\n",
    "        Implementations should override this method to provide the functionality\n",
    "        to show memories. Specific parameters and return types depend on the implementation.\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ReAct's memory implementation.\n",
    "\n",
    "Original Paper: https://arxiv.org/abs/2210.03629\n",
    "Paper Repository: https://github.com/ysymyth/ReAct\n",
    "LangChain: https://github.com/langchain-ai/langchain\n",
    "LangChain ReAct: https://python.langchain.com/docs/modules/agents/agent_types/react\n",
    "\"\"\"\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "\n",
    "\n",
    "class ReActMemory(BaseMemory):\n",
    "    \"\"\"A memory storage class for ReAct.\n",
    "\n",
    "    It stores, retrieves, and manages text-based memories (observations) in a scratchpad (str).\n",
    "\n",
    "    Attributes:\n",
    "        scratchpad (str): A string attribute that stores all the memories.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scratchpad: Optional[str] = None) -> None:\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super().__init__()\n",
    "        self.scratchpad = scratchpad if scratchpad else \"\"\n",
    "\n",
    "    def clear(\n",
    "        self,\n",
    "    ) -> None:\n",
    "        \"\"\"Clears the contents of the scratchpad.\n",
    "\n",
    "        This method resets the scratchpad to an empty string, erasing all stored memories.\n",
    "        \"\"\"\n",
    "        self.scratchpad = \"\"\n",
    "\n",
    "    def add_memories(self, observation: str) -> None:\n",
    "        \"\"\"Adds a new observation to the scratchpad.\n",
    "\n",
    "        This method appends the given observation text to the existing contents of the scratchpad.\n",
    "\n",
    "        Args:\n",
    "            observation (str): The observation text to be added to the memory.\n",
    "\n",
    "        \"\"\"\n",
    "        self.scratchpad += observation\n",
    "\n",
    "    def load_memories(self, input_key: str = \"scratchpad\") -> Dict[str, Any]:\n",
    "        \"\"\"Retrieves all stored memories.\n",
    "\n",
    "        `show_memories` and `load_memories` are identical in ReAct's case.\n",
    "\n",
    "        Args:\n",
    "            input_key (str, optional): The key used to access memories. Defaults to \"scratchpad\".\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: A dictionary containing the stored memories, accessible via the provided input key.\n",
    "        \"\"\"\n",
    "        return {input_key: self.scratchpad}\n",
    "\n",
    "    def show_memories(self, input_key: str = \"scratchpad\") -> Dict[str, Any]:\n",
    "        \"\"\"Displays all stored memories.\n",
    "\n",
    "        Args:\n",
    "            input_key (str, optional): The key used to access memories. Defaults to \"scratchpad\".\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: A dictionary containing the stored memories, accessible via the provided input key.\n",
    "        \"\"\"\n",
    "        return {input_key: self.scratchpad}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base import BaseAgent \n",
    "import tiktoken\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from typing import Any, Dict, List, Optional\n",
    "from tiktoken.core import Encoding\n",
    "\n",
    "class Alfworld(BaseAgent):\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: BaseChatModel,\n",
    "        memory: Optional[ReActMemory] = None,\n",
    "        max_tokens: int = 3896,\n",
    "        enc: Encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    "        env_config: str = 'base_config.yaml',\n",
    "        max_step: int = 50\n",
    "    ):\n",
    "\n",
    "\n",
    "        super().__init__()\n",
    "        self.llm = llm\n",
    "\n",
    "        if not memory:\n",
    "            self.memory = ReActMemory()\n",
    "        else:\n",
    "            self.memory = memory\n",
    "\n",
    "        \n",
    "        self.max_tokens = max_tokens\n",
    "        self.max_step = max_step\n",
    "        self.enc = enc\n",
    "\n",
    "        self.env_config=env_config\n",
    "\n",
    "        # Internal variables.\n",
    "        self._finished = False  #: :meta private:\n",
    "        self.prefixes = {\n",
    "            'pick_and_place': 'put',\n",
    "            'pick_clean_then_place': 'clean',\n",
    "            'pick_heat_then_place': 'heat',\n",
    "            'pick_cool_then_place': 'cool',\n",
    "            'look_at_obj': 'examine',\n",
    "            'pick_two_obj': 'puttwo'\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models.openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run = Alfworld(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_run.max_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello wolrd\n",
      "Initializing AlfredTWEnv...\n",
      "Checking for solvable games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [00:00<00:00, 2650.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall we have 134 games in split=eval_out_of_distribution\n",
      "Evaluating with 134 games\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are in the middle of a room. Looking quickly around you, you see a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a countertop 3, a countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a fridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\n",
      "Your task is to: put a cool tomato in microwave.\n"
     ]
    }
   ],
   "source": [
    "with open(test_run.env_config) as reader:\n",
    "    config = yaml.safe_load(reader)\n",
    "    \n",
    "print('hello wolrd')\n",
    "split = \"eval_out_of_distribution\"\n",
    "\n",
    "env = getattr(alfworld.agents.environment, config[\"env\"][\"type\"])(config, train_eval=split)\n",
    "env = env.init_env(batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "ob, info = env.reset()\n",
    "ob = '\\n'.join(ob[0].split('\\n\\n')[1:])\n",
    "print(ob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "REACT_ALFWORLD_INSTRUCTION = \"\"\"\n",
    "Here are some examples:\n",
    "{examples}\n",
    "(END OF EXAMPLES)\n",
    "Statement: {question}{scratchpad}\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "REACT_ALFWORLD_ACT_EXAMINE_1 = \"\"\"\n",
    "You are in the middle of a room. Looking quickly around you, you see a bed 1, a drawer 10, a drawer 9, a drawer 8, a drawer 7, a drawer 6, a drawer 5, a drawer 4, a drawer 3, a drawer 2, a drawer 1, a dresser 1, a garbagecan 1, a shelf 9, a shelf 8, a shelf 7, a shelf 6, a shelf 5, a shelf 4, a shelf 3, a shelf 2, and a shelf 1.\n",
    "Your task is to: examine the pen with the desklamp.\n",
    "Act 1: go to drawer 1\n",
    "Obs 1: The drawer 1 is closed.\n",
    "Act 2: open drawer 1\n",
    "Obs 2: You open the drawer 1. The drawer 1 is open. In it, you see nothing.\n",
    "Act 3: go to drawer 2\n",
    "Obs 3: The drawer 2 is closed.\n",
    "Act 4: open drawer 2\n",
    "Obs 4: You open the drawer 2. The drawer 2 is open. In it, you see nothing.\n",
    "Act 5: go to drawer 3\n",
    "Obs 5: The drawer 3 is closed.\n",
    "Act 6: open drawer 3\n",
    "Obs 6: You open the drawer 3. The drawer 3 is open. In it, you see nothing.\n",
    "Act 7: go to drawer 4\n",
    "Obs 7: The drawer 4 is closed.\n",
    "Act 8: open drawer 4\n",
    "Obs 8: You open the drawer 4. The drawer 4 is open. In it, you see a cd 3, a keychain 1, and a pen 2.\n",
    "Act 9: take pen 2 from drawer 4\n",
    "Obs 9: You pick up the pen 2 from the drawer 4.\n",
    "Act 10: go to dresser 1\n",
    "Obs 10: On the dresser 1, you see a alarmclock 2, a alarmclock 1, a book 1, a cd 1, a creditcard 1, a desklamp 1, a keychain 2, a pen 3, and a pen 1.\n",
    "Act 11: use desklamp 1\n",
    "Obs 11: You turn on the desklamp 1.\n",
    "Act 12: put pen 2 in/on dresser 1\n",
    "Obs 12: You turn on the desklamp 1.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from tiktoken import Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_newline(step: str) -> str:\n",
    "    \"\"\"Formats a step string by stripping leading/trailing newlines and spaces, and replacing internal newlines with empty space.\n",
    "\n",
    "    Args:\n",
    "        step (str): The step string to be formatted.\n",
    "\n",
    "    Returns:\n",
    "        str: The formatted step string.\n",
    "    \"\"\"\n",
    "    return step.strip(\"\\n\").strip().replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_alfworld_agent_prompt(question: str, scratchpad: str) -> str:\n",
    "    \"\"\"Constructs a prompt template for the agent.\n",
    "\n",
    "    This function formats a predefined prompt template (REACT_INSTRUCTION) with examples,\n",
    "    the provided question, and a scratchpad.\n",
    "\n",
    "    Args:\n",
    "        question (str): The question to be included in the prompt.\n",
    "        scratchpad (str): Additional scratchpad information to be included.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted prompt template ready for use.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate.from_template(REACT_ALFWORLD_INSTRUCTION).format(\n",
    "        examples=REACT_ALFWORLD_ACT_EXAMINE_1,\n",
    "        question=question,\n",
    "        scratchpad=scratchpad,\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def _alfworld_prompt_agent(llm: BaseChatModel, question: str, scratchpad: str) -> str:\n",
    "    \"\"\"Generates a response from the LLM based on a given question and scratchpad.\n",
    "\n",
    "    This function creates a prompt using `_build_agent_prompt` and then gets the LLM's\n",
    "    output. The newline characters in the output are removed before returning.\n",
    "\n",
    "    Args:\n",
    "        llm (BaseChatModel): The language model to be prompted.\n",
    "        question (str): The question to ask the language model.\n",
    "        scratchpad (str): Additional context or information for the language model.\n",
    "        example (str): the example used for specific benchmark\n",
    "\n",
    "    Returns:\n",
    "        str: The processed response from the language model.\n",
    "    \"\"\"\n",
    "    prompt = _build_alfworld_agent_prompt(question=question, scratchpad=scratchpad)\n",
    "    out = llm(\n",
    "        [\n",
    "            HumanMessage(\n",
    "                content=prompt,\n",
    "            )\n",
    "        ]\n",
    "    ).content\n",
    "    assert isinstance(out, str)\n",
    "    return remove_newline(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are in the middle of a room. Looking quickly around you, you see a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a countertop 3, a countertop 2, a countertop 1, a drawer 3, a drawer 2, a drawer 1, a fridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.\n",
      "Your task is to: put a clean plate in countertop.\n",
      "pick_clean_then_place_in_recep-Plate-None-CounterTop-10/trial_T20190908_213420_728917\n"
     ]
    }
   ],
   "source": [
    "ob, info = env.reset()\n",
    "ob = '\\n'.join(ob[0].split('\\n\\n')[1:])\n",
    "name = '/'.join(info['extra.gamefile'][0].split('/')[-3:-1])\n",
    "\n",
    "\n",
    "print(ob)\n",
    "print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './prompts/alfworld_3prompts.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./prompts/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m prompt_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malfworld_3prompts.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprompt_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m     d \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './prompts/alfworld_3prompts.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "folder = './prompts/'\n",
    "prompt_file = 'alfworld_3prompts.json'\n",
    "with open(folder + prompt_file, 'r') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (k, v) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_run\u001b[38;5;241m.\u001b[39mprefixes\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mstartswith(k):\n\u001b[0;32m----> 3\u001b[0m         prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInteract with a household to solve a task. Here are two examples.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43md\u001b[49m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreact_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m d[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreact_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_0\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mHere is the task.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m         instruction \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{scratchpad}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "for i, (k, v) in enumerate(test_run.prefixes.items()):\n",
    "    if name.startswith(k):\n",
    "        prompt = 'Interact with a household to solve a task. Here are two examples.\\n' + d[f'react_{v}_1'] + d[f'react_{v}_0'] + '\\nHere is the task.\\n'\n",
    "        instruction = prompt + '{scratchpad}\\n>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
