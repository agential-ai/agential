{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "import dotenv\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from discussion_agents.cog.functional.expel import (\n",
    "    categorize_experiences,\n",
    "    get_folds,\n",
    "    create_rules,\n",
    ")\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_rules = 20\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_key=openai_api_key)\n",
    "experiences = joblib.load(\"../../../tests/assets/expel/expel_experiences_10_fake.joblib\")\n",
    "categories = categorize_experiences(experiences)\n",
    "folds = get_folds(categories, len(experiences['idxs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1, 2, 5, 8, 9]\n",
      "1 [0, 3, 4, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "rules = []\n",
    "for fold, train_idxs in folds.items():\n",
    "    print(fold, train_idxs)\n",
    "    rules = create_rules(\n",
    "        llm, \n",
    "        experiences, \n",
    "        categories, \n",
    "        train_idxs, \n",
    "        rules, \n",
    "        max_num_rules=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('If the initial search does not provide information related to the specific question, try to explore different angles or sources to gather relevant information that may lead to the answer. Consider refining the search query with more specific and relevant keywords to narrow down the search results and find the desired information effectively.',\n",
       "  5),\n",
       " ('If unable to find the answer after exploring different search options, consider reaching out to additional sources or experts for assistance in obtaining the required information.',\n",
       "  2),\n",
       " ('When searching for specific information, try to include relevant keywords related to the topic to narrow down the search results and find the desired information effectively.',\n",
       "  2),\n",
       " ('When searching for specific information, consider verifying the credibility of the sources to ensure the accuracy of the information retrieved.',\n",
       "  2),\n",
       " ('When faced with a search query, consider utilizing different search engines or platforms to gather information and find the desired answer effectively.',\n",
       "  1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discussion_agents.cog.prompts.react import REACT_WEBTHINK_SIMPLE6_FEWSHOT_EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshots = fewshots[0]\n",
    "task = fewshots.split('\\n')[0]\n",
    "trajectory = '\\n'.join(fewshots.split('\\n')[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_traj = Trajectory(\n",
    "    task=self.remove_task_suffix(task),\n",
    "    trajectory=trajectory,\n",
    "    reflections=[],\n",
    "    splitter=self.message_splitter,\n",
    "    identifier=self.identifier,\n",
    "    step_splitter=partial(\n",
    "        self.message_step_splitter,\n",
    "        stripper=self.step_stripper\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for fold, eval_idxs in fold.items():\n",
    "    train_idxs = total - set(eval_idxs)\n",
    "    create_rules(...)\n",
    "\n",
    "    for idx in eval_idxs:\n",
    "        agent.run(...)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_rules = 20\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", openai_api_key=openai_api_key)\n",
    "experiences = joblib.load(\"exp_15_compare_fake.joblib\")\n",
    "categories = categorize_experiences(experiences)\n",
    "folds = get_folds(categories, len(experiences['idxs']))\n",
    "\n",
    "rules, rules_with_count = [], []\n",
    "for fold, train_idxs in folds.items():\n",
    "    rules, rules_with_count = create_rules(\n",
    "        llm, \n",
    "        experiences, \n",
    "        categories, \n",
    "        train_idxs,\n",
    "        rules, \n",
    "        rules_with_count, \n",
    "        max_num_rules\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discussion-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
