{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_num=\"4\"\n",
    "var_num=1\n",
    "env_step_limit=2\n",
    "num_episodes=1\n",
    "gpt_model=\"gpt_4_0613\"\n",
    "summarize_end_of_episode=1\n",
    "device=\"cpu\"\n",
    "temperature=0.0\n",
    "use_gold_memory_in_ep0=0\n",
    "gold_traces=\"\"\n",
    "use_last_k_memories=3\n",
    "quadrant=1\n",
    "simplifications_preset=\"easy\"\n",
    "output_path_prefix = 'logs/testrun/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jar_path = None\n",
    "task_num = \"4\"\n",
    "var_num = 1\n",
    "env_step_limit = 100\n",
    "num_episodes = 2\n",
    "gpt_model = \"gpt-4-0613\"\n",
    "summarize_end_of_episode = 1\n",
    "device = None\n",
    "temperature = 0.0\n",
    "use_gold_memory_in_ep0 = 0\n",
    "gold_traces = \"\"\n",
    "use_last_k_memories = 3\n",
    "quadrant = None\n",
    "output_path_prefix = \"save-histories\"\n",
    "simplifications_preset = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CLIN agent for taskIdx:4, varIdx:1\n"
     ]
    }
   ],
   "source": [
    "task_num = int(task_num)\n",
    "var_num = int(var_num)\n",
    "print(f\"Running CLIN agent for taskIdx:{task_num}, varIdx:{var_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/agential/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/anaconda3/envs/agential/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "exitCommands = [\"quit\", \"exit\"]\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sent_transformer_model = SentenceTransformer('bert-base-nli-mean-tokens', device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no gold path -_-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryfname = \"logs/\" + \"summary.txt\"\n",
    "summaryFile = open(summaryfname, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Names: Who was once considered the best kick boxer in the world, however he has been involved in a number of controversies relating to his \"unsportsmanlike conducts\" in the sport and crimes of violence outside of the ring\n"
     ]
    }
   ],
   "source": [
    "task = 'Who was once considered the best kick boxer in the world, however he has been involved in a number of controversies relating to his \"unsportsmanlike conducts\" in the sport and crimes of violence outside of the ring' \n",
    "print(\"Task Names: \" + str(task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CRITIC structured output module.\"\"\"\n",
    "\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from agential.agents.base.output import BaseAgentOutput\n",
    "from agential.core.llm import Response\n",
    "\n",
    "\n",
    "class ClinStepOutput(BaseModel):\n",
    "    \"\"\"Critic step Pydantic output class.\n",
    "\n",
    "    Attributes:\n",
    "        answer (str): The answer generated by the agent.\n",
    "        critique (str): The critique of the answer generated by the agent.\n",
    "        external_tool_info (Dict[str, Any]): The query requested by the agent.\n",
    "        answer_response (List[Response]): The answer responses generated by the agent.\n",
    "        critique_response (List[Response]): The critique responses generated by the agent.\n",
    "    \"\"\"\n",
    "\n",
    "    query: str = Field(..., description=\"The query requested by the agent.\")\n",
    "    answer: str = Field(..., description=\"The answer generated by the agent.\")\n",
    "    observation: str = Field(..., description=\"The answer's observation.\")\n",
    "    external_tool_info: Dict[str, Any] = Field(\n",
    "        ..., description=\"The external tool outputs.\"\n",
    "    )\n",
    "    answer_response: List[Response] = Field(\n",
    "        ..., description=\"The answer responses generated by the agent.\"\n",
    "    )\n",
    "    observation_response: List[Response] = Field(\n",
    "        ..., description=\"The observation responses generated by the agent.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ClinOutput(BaseAgentOutput):\n",
    "    \"\"\"Critic Pydantic output class.\n",
    "\n",
    "    Attributes:\n",
    "        additional_info (List[CriticStepOutput]): The additional info.\n",
    "    \"\"\"\n",
    "\n",
    "    additional_info: List[ClinStepOutput] = Field(\n",
    "        ..., description=\"The additional info.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReActQAStrategy(ReActGeneralStrategy):\n",
    "    \"\"\"A strategy class for QA benchmarks using the ReAct agent.\n",
    "\n",
    "    Attributes:\n",
    "        llm (BaseLLM): The language model used for generating answers and critiques.\n",
    "        max_steps (int): The maximum number of steps the agent can take.\n",
    "        max_tokens (int): The maximum number of tokens allowed for a response.\n",
    "        enc (Encoding): The encoding used for the language model.\n",
    "        docstore (DocstoreExplorer): The document store used for searching and looking up information.\n",
    "        testing (bool): Whether the strategy is in testing mode. Defaults to False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: BaseLLM,\n",
    "        max_steps: int = 6,\n",
    "        max_tokens: int = 5000,\n",
    "        enc: Encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\"),\n",
    "        docstore: DocstoreExplorer = DocstoreExplorer(Wikipedia()),\n",
    "        testing: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super().__init__(\n",
    "            llm=llm,\n",
    "            max_steps=max_steps,\n",
    "            max_tokens=max_tokens,\n",
    "            enc=enc,\n",
    "            testing=testing,\n",
    "        )\n",
    "        self.docstore = docstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agential.agents.base.agent import BaseAgent\n",
    "from agential.core.llm import BaseLLM\n",
    "\n",
    "class Clin(BaseAgent):\n",
    "    \"\"\"Clin Agent.\n",
    "\n",
    "    Attributes:\n",
    "        llm (BaseLLM): An instance of a language model used for generating initial answers\n",
    "            and critiques.\n",
    "        benchmark (str): The benchmark.\n",
    "        testing (bool): Whether to run in testing mode. Defaults to False.\n",
    "        **strategy_kwargs (Any): Additional strategy-specific arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: BaseLLM,\n",
    "        benchmark: str,\n",
    "        testing: bool = False,\n",
    "        **strategy_kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super().__init__(llm=llm, benchmark=benchmark, testing=testing)\n",
    "\n",
    "        self.strategy = Clin.get_strategy(\n",
    "            benchmark=self.benchmark, llm=self.llm, testing=testing, **strategy_kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_variations_to_run = 1\n",
    "for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
