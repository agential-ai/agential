{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvincenttu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "from agential.prompting.standard.prompting import Standard\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from agential.prompting.standard.prompts import (\n",
    "    STANDARD_INSTRUCTION_AMBIGNQ, \n",
    "    STANDARD_INSTRUCTION_FEVER, \n",
    "    STANDARD_INSTRUCTION_GSM8K,  \n",
    "    STANDARD_INSTRUCTION_HOTPOTQA, \n",
    "    STANDARD_INSTRUCTION_SVAMP, \n",
    "    STANDARD_INSTRUCTION_TRIVIAQA,\n",
    "    STANDARD_INSTRUCTION_TABMWP,\n",
    "    STANDARD_INSTRUCTION_HUMANEVAL,\n",
    "    STANDARD_INSTRUCTION_MBPP,\n",
    ")\n",
    "from agential.core.fewshots.ambignq import AMBIGNQ_FEWSHOT_EXAMPLES_DIRECT\n",
    "from agential.core.fewshots.fever import FEVER_FEWSHOT_EXAMPLES_DIRECT\n",
    "from agential.core.fewshots.gsm8k import GSM8K_FEWSHOT_EXAMPLES_POT\n",
    "from agential.core.fewshots.hotpotqa import HOTPOTQA_FEWSHOT_EXAMPLES_DIRECT\n",
    "from agential.core.fewshots.svamp import SVAMP_FEWSHOT_EXAMPLES_POT\n",
    "from agential.core.fewshots.triviaqa import TRIVIAQA_FEWSHOT_EXAMPLES_DIRECT\n",
    "from agential.core.fewshots.tabmwp import TABMWP_FEWSHOT_EXAMPLES_POT\n",
    "from agential.core.fewshots.humaneval import HUMANEVAL_FEWSHOT_EXAMPLES_POT\n",
    "from agential.core.fewshots.mbpp import MBPP_FEWSHOT_EXAMPLES_POT\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from agential.core.llm import LLM\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "with open('../data/hotpotqa/hotpot_dev_v1_simplified_s42_sample500.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvincenttu\u001b[0m (\u001b[33magential\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tuvin\\OneDrive\\Desktop\\agential\\experiments\\wandb\\run-20240908_150801-58nc4sa3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/agential/hotpotqa/runs/58nc4sa3' target=\"_blank\">lilac-mountain-1</a></strong> to <a href='https://wandb.ai/agential/hotpotqa' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/agential/hotpotqa' target=\"_blank\">https://wandb.ai/agential/hotpotqa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/agential/hotpotqa/runs/58nc4sa3' target=\"_blank\">https://wandb.ai/agential/hotpotqa/runs/58nc4sa3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>em</td><td>▁▁▁█▁▁█▁▁▁█▁▁▁▁█▁▁▁█▁█▁█▁██▁▁▁▁█▁▁▁▁▁█▁█</td></tr><tr><td>f1</td><td>▁▁▁█▁▁█▃▁▁█▁▁▁▁█▅▁▄█▅█▁█▂██▂▁▁▅█▁▃▁▁▁█▅█</td></tr><tr><td>precision</td><td>▁▁▁█▁▁█▃▁▁█▁▁▁▁█▅▁▅███▁█▂██▁▁▁▅█▁▂▁▁▁█▅█</td></tr><tr><td>recall</td><td>▁▁▁█▁▁█▂▁▁█▁▁▁▁█▅▁▄█▃█▁█▅██▅▁▁▅█▁▃▁▁▁█▆█</td></tr><tr><td>total_em</td><td>▁</td></tr><tr><td>total_f1</td><td>▁</td></tr><tr><td>total_precision</td><td>▁</td></tr><tr><td>total_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>em</td><td>0</td></tr><tr><td>f1</td><td>0.25</td></tr><tr><td>precision</td><td>0.25</td></tr><tr><td>recall</td><td>0.25</td></tr><tr><td>total_em</td><td>0.282</td></tr><tr><td>total_f1</td><td>0.35906</td></tr><tr><td>total_precision</td><td>0.37254</td></tr><tr><td>total_recall</td><td>0.38965</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lilac-mountain-1</strong> at: <a href='https://wandb.ai/agential/hotpotqa/runs/58nc4sa3' target=\"_blank\">https://wandb.ai/agential/hotpotqa/runs/58nc4sa3</a><br/> View project at: <a href='https://wandb.ai/agential/hotpotqa' target=\"_blank\">https://wandb.ai/agential/hotpotqa</a><br/>Synced 4 W&B file(s), 2 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240908_150801-58nc4sa3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agential.eval.metrics.classification import EM, f1, precision, recall\n",
    "\n",
    "\n",
    "seed = 42\n",
    "root_dir = \"output\"\n",
    "method_name = \"standard\"\n",
    "benchmark_name = \"hotpotqa\"\n",
    "num_retries = 1\n",
    "warming = [1.0]\n",
    "\n",
    "output_path = os.path.join(root_dir, method_name, benchmark_name)\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "llm = LLM(\"gpt-3.5-turbo\", organization=os.getenv(\"OPENAI_ORGANIZATION\"), seed=seed)\n",
    "\n",
    "method = Standard(\n",
    "    llm=llm,\n",
    "    benchmark=benchmark_name,\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    project=benchmark_name, \n",
    "    entity=\"agential\",\n",
    "    config={\n",
    "        \"seed\": seed,\n",
    "        \"num_retries\": num_retries,\n",
    "        \"warming\": warming,\n",
    "    },\n",
    "    group=method_name,\n",
    "    tags=[f\"method={method_name}\", f\"seed={seed}\", f\"num_retries={num_retries}\", f\"warming={warming}\", \"base\"],\n",
    ")\n",
    "\n",
    "eval_table_data = []\n",
    "perf_table_data = []\n",
    "em_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "outputs = []\n",
    "\n",
    "for instance in data:\n",
    "    question = instance[\"question\"]\n",
    "    answer = instance[\"answer\"]\n",
    "\n",
    "    # Inference.\n",
    "    out = method.generate(\n",
    "        question=question,\n",
    "        key=answer,\n",
    "        num_retries=num_retries,\n",
    "        warming=warming\n",
    "    )\n",
    "\n",
    "    # Calculate metrics.\n",
    "    is_correct = int(EM(out.answer, answer))\n",
    "    precision_score = precision(out.answer, answer)\n",
    "    recall_score = recall(out.answer, answer)\n",
    "    f1_score = f1(out.answer, answer)\n",
    "\n",
    "    # Update scores.\n",
    "    em_scores.append(is_correct)\n",
    "    precision_scores.append(precision_score)\n",
    "    recall_scores.append(recall_score)\n",
    "    f1_scores.append(f1_score)\n",
    "\n",
    "    # Update tables.\n",
    "    eval_table_data.append([question, answer, out.answer, is_correct, precision_score, recall_score, f1_score])\n",
    "    perf_table_data.append([\n",
    "        out.total_prompt_tokens, \n",
    "        out.total_completion_tokens, \n",
    "        out.total_tokens, \n",
    "        out.total_prompt_cost,\n",
    "        out.total_completion_cost,\n",
    "        out.total_cost,\n",
    "        out.total_prompt_time,\n",
    "        out.total_time\n",
    "    ])\n",
    "\n",
    "    # Update outputs.\n",
    "    outputs.append(out)\n",
    "\n",
    "    # Log metrics.\n",
    "    run.log({\n",
    "        \"em\": is_correct,\n",
    "        \"precision\": precision_score,\n",
    "        \"recall\": recall_score,\n",
    "        \"f1\": f1_score,\n",
    "    })\n",
    "\n",
    "total_em = sum(em_scores) / len(em_scores)\n",
    "total_precision = sum(precision_scores) / len(precision_scores)\n",
    "total_recall = sum(recall_scores) / len(recall_scores)\n",
    "total_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "eval_table = wandb.Table(data=eval_table_data, columns=[\"question\", \"answer\", \"predicted_answer\", \"EM\", \"precision\", \"recall\", \"f1\"])\n",
    "perf_table = wandb.Table(data=perf_table_data, columns=[\"total_prompt_tokens\", \"total_completion_tokens\", \"total_tokens\", \"total_prompt_cost\", \"total_completion_cost\", \"total_cost\", \"total_prompt_time\", \"total_time\"])\n",
    "\n",
    "outputs_save_path = os.path.join(output_path, f\"{run.name}.pkl\")\n",
    "with open(outputs_save_path, 'wb') as f:\n",
    "    pickle.dump(outputs, f)\n",
    "\n",
    "artifact = wandb.Artifact(name=run.name, type=\"output\")\n",
    "artifact.add_file(local_path=outputs_save_path, name=\"outputs.pkl\")\n",
    "artifact.save()\n",
    "\n",
    "run.log({\n",
    "    f\"{run.name}_eval\": eval_table,\n",
    "    f\"{run.name}_perf\": perf_table\n",
    "})\n",
    "\n",
    "run.log({\n",
    "    \"total_em\": total_em,\n",
    "    \"total_precision\": total_precision,\n",
    "    \"total_recall\": total_recall,\n",
    "    \"total_f1\": total_f1,\n",
    "})\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
