{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agential.prompting.standard.prompting import Standard\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from agential.prompting.standard.prompts import (\n",
    "    STANDARD_INSTRUCTION_AMBIGNQ, \n",
    "    STANDARD_INSTRUCTION_FEVER, \n",
    "    STANDARD_INSTRUCTION_GSM8K,  \n",
    "    STANDARD_INSTRUCTION_HOTPOTQA, \n",
    "    STANDARD_INSTRUCTION_SVAMP, \n",
    "    STANDARD_INSTRUCTION_TRIVIAQA,\n",
    "    STANDARD_INSTRUCTION_TABMWP,\n",
    "    STANDARD_INSTRUCTION_HUMANEVAL,\n",
    "    STANDARD_INSTRUCTION_MBPP,\n",
    ")\n",
    "from agential.core.fewshots.ambignq import AMBIGNQ_FEWSHOT_EXAMPLES_DIRECT\n",
    "from agential.core.fewshots.fever import FEVER_FEWSHOT_EXAMPLES_DIRECT\n",
    "from agential.core.fewshots.gsm8k import GSM8K_FEWSHOT_EXAMPLES_POT\n",
    "from agential.core.fewshots.hotpotqa import HOTPOTQA_FEWSHOT_EXAMPLES_DIRECT\n",
    "from agential.core.fewshots.svamp import SVAMP_FEWSHOT_EXAMPLES_POT\n",
    "from agential.core.fewshots.triviaqa import TRIVIAQA_FEWSHOT_EXAMPLES_DIRECT\n",
    "from agential.core.fewshots.tabmwp import TABMWP_FEWSHOT_EXAMPLES_POT\n",
    "from agential.core.fewshots.humaneval import HUMANEVAL_FEWSHOT_EXAMPLES_POT\n",
    "from agential.core.fewshots.mbpp import MBPP_FEWSHOT_EXAMPLES_POT\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from agential.core.llm import LLM\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "llm = LLM(\"gpt-3.5-turbo\", organization=os.getenv(\"OPENAI_ORGANIZATION\"))\n",
    "\n",
    "with open('../data/hotpotqa/hotpot_dev_v1_simplified_s42_sample500.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agential.eval.metrics.classification import EM, f1, precision, recall\n",
    "\n",
    "# Log numbers (EM, f1, precission, recall)\n",
    "# Log/Save artifacts to your runs\n",
    "# Optional, how to log final metrics \n",
    "\n",
    "method = Standard(\n",
    "        llm=llm,\n",
    "        benchmark=\"hotpotqa\",\n",
    "    )\n",
    "\n",
    "num_correct = 0 \n",
    "samples = 20\n",
    "\n",
    "wandb.init(\"standard_hotpotqa\")\n",
    "\n",
    "for i in data[:samples]:\n",
    "\n",
    "    question = i[\"question\"]\n",
    "    answer = i[\"answer\"]\n",
    "\n",
    "    out = method.generate(\n",
    "        question=question,\n",
    "        key=answer\n",
    "    )\n",
    "    is_correct = EM(out.answer, answer)\n",
    "    precision_out = precision(out.answer, answer)\n",
    "    recall_out = recall(out.answer, answer)\n",
    "    f1_out = f1(out.answer, answer)\n",
    "\n",
    "    num_correct += int(is_correct)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
