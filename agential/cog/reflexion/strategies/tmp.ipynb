{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agential.cog.fewshots.hotpotqa import HOTPOTQA_FEWSHOT_EXAMPLES_COT\n",
    "from agential.cog.reflexion.prompts import HOTPOTQA_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT, REFLEXION_COT_INSTRUCTION_HOTPOTQA, REFLEXION_COT_REFLECT_INSTRUCTION_HOTPOTQA\n",
    "from agential.cog.reflexion.strategies.qa import ReflexionCoTQAStrategy\n",
    "from agential.llm.llm import LLM\n",
    "\n",
    "llm = LLM(\"gpt-3.5-turbo\")\n",
    "\n",
    "question = \"VIVA Media AG changed it's name in 2004. What does their new acronym stand for?\"\n",
    "key = \"Gesellschaft mit beschrÃ¤nkter Haftung\"\n",
    "\n",
    "\n",
    "agent = ReflexionCoTQAStrategy(\n",
    "    llm=llm,\n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question, \n",
    "    key=key, \n",
    "    examples=HOTPOTQA_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_HOTPOTQA, \n",
    "    reflect_examples=HOTPOTQA_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.llm.total_completion_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.total_completion_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agential.cog.fewshots.gsm8k import GSM8K_FEWSHOT_EXAMPLES_COT\n",
    "from agential.cog.reflexion.prompts import GSM8K_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT, REFLEXION_COT_INSTRUCTION_GSM8K, REFLEXION_COT_REFLECT_INSTRUCTION_GSM8K\n",
    "from agential.cog.reflexion.strategies.math import ReflexionCoTMathStrategy\n",
    "from agential.llm.llm import LLM\n",
    "\n",
    "llm = LLM(\"gpt-3.5-turbo\")\n",
    "\n",
    "question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with 4933828. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\n",
    "key = -9867630\n",
    "\n",
    "agent = ReflexionCoTMathStrategy(\n",
    "    llm=llm, \n",
    ")\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=GSM8K_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_GSM8K,\n",
    "    reflect_examples=GSM8K_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_GSM8K,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.llm.total_completion_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.total_completion_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agential.cog.fewshots.humaneval import HUMANEVAL_FEWSHOT_EXAMPLES_COT\n",
    "from agential.cog.reflexion.prompts import HUMANEVAL_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT, REFLEXION_COT_INSTRUCTION_HUMANEVAL, REFLEXION_COT_REFLECT_INSTRUCTION_HUMANEVAL\n",
    "from agential.cog.reflexion.strategies.code import ReflexionCoTCodeStrategy, ReflexionCoTHEvalStrategy\n",
    "from agential.llm.llm import LLM\n",
    "\n",
    "inst = {\"task_id\": \"HumanEval/0\", \"prompt\": \"from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \\\"\\\"\\\"\\n\", \"entry_point\": \"has_close_elements\", \"canonical_solution\": \"    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n\", \"test\": \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\\n\\n\"}\n",
    "question = inst['prompt']\n",
    "key = f\"{inst['test']}\\ncheck({inst['entry_point']})\"\n",
    "\n",
    "\n",
    "llm = LLM(\"gpt-3.5-turbo\")\n",
    "agent = ReflexionCoTHEvalStrategy(\n",
    "    llm=llm, \n",
    ")\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=HUMANEVAL_FEWSHOT_EXAMPLES_COT,\n",
    "    prompt=REFLEXION_COT_INSTRUCTION_HUMANEVAL,\n",
    "    reflect_examples=HUMANEVAL_FEWSHOT_EXAMPLES_REFLEXION_COT_REFLECT,\n",
    "    reflect_prompt=REFLEXION_COT_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    "    reflect_strategy=\"reflexion\",\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    patience=3,\n",
    "    reset=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out.additional_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.total_completion_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.total_completion_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
