{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š **Performance of ReAct Agent Running a Sample Question from TriviaQA Benchmark**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from agential.cog.agent.react import ReActAgent\n",
    "from agential.cog.prompts.react import (\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES,\n",
    "    REACT_INSTRUCTION_TRIVIAQA,\n",
    ")\n",
    "class GPT3ChatModel:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "\n",
    "    def ask(self, prompt, max_tokens=150):\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                engine=\"text-davinci-003\",  # or choose the specific model version you want\n",
    "                prompt=prompt,\n",
    "                max_tokens=max_tokens,\n",
    "                api_key=self.api_key\n",
    "            )\n",
    "            return response.choices[0].text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key has been activated\n",
      "Initializing the agent\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'GPT3ChatModel' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m agent \u001b[38;5;241m=\u001b[39m ReActAgent(llm\u001b[38;5;241m=\u001b[39mllm)\n\u001b[1;32m      9\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmerican Callan Pinckney\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms eponymously named system became a best-selling (1980s-2000s) book/video franchise in what genre?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTRIVIAQA_FEWSHOT_EXAMPLES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mREACT_INSTRUCTION_TRIVIAQA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs:\n",
      "File \u001b[0;32m~/agential/agential/cog/agent/react.py:128\u001b[0m, in \u001b[0;36mReActAgent.generate\u001b[0;34m(self, question, reset, examples, prompt)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_halted(\n\u001b[1;32m    116\u001b[0m     finished\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finished,\n\u001b[1;32m    117\u001b[0m     step_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_n,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m ):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# Think.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39madd_memories(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThought:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m     thought \u001b[38;5;241m=\u001b[39m \u001b[43m_prompt_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscratchpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_memories\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscratchpad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39madd_memories(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m thought)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# Act.\u001b[39;00m\n",
      "File \u001b[0;32m~/agential/agential/cog/functional/react.py:78\u001b[0m, in \u001b[0;36m_prompt_agent\u001b[0;34m(llm, question, scratchpad, examples, max_steps, prompt)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates a response from the LLM based on a given question and scratchpad.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mThis function creates a prompt using `_build_agent_prompt` and then gets the LLM's\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    str: The processed response from the language model.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m prompt \u001b[38;5;241m=\u001b[39m _build_agent_prompt(\n\u001b[1;32m     72\u001b[0m     question\u001b[38;5;241m=\u001b[39mquestion,\n\u001b[1;32m     73\u001b[0m     scratchpad\u001b[38;5;241m=\u001b[39mscratchpad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     77\u001b[0m )\n\u001b[0;32m---> 78\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m remove_newline(out)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'GPT3ChatModel' object is not callable"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"API key has been activated\")\n",
    "\n",
    "\n",
    "llm = GPT3ChatModel(OPENAI_API_KEY)\n",
    "print(\"Initializing the agent\")\n",
    "agent = ReActAgent(llm=llm)\n",
    "\n",
    "question = \"American Callan Pinckney's eponymously named system became a best-selling (1980s-2000s) book/video franchise in what genre?\"\n",
    "outputs = agent.generate(question=question,examples = TRIVIAQA_FEWSHOT_EXAMPLES,\n",
    "        prompt = REACT_INSTRUCTION_TRIVIAQA)\n",
    "\n",
    "print(f\"Question: {question}\") \n",
    "\n",
    "if outputs:\n",
    "    for output in outputs:\n",
    "        print(\"Thought:\", output.thought)\n",
    "        print(\"Action:\", output.action)\n",
    "        print(\"Observation:\", output.observation)\n",
    "else:\n",
    "    print(\"No output generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
