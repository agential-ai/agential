{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agential.cog.prompts.critic import (\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_POT, \n",
    "    CRITIC_POT_INSTRUCTION_HUMANEVAL,\n",
    "    CRITIC_POT_INSTRUCTION_TEST_HUMANEVAL,\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_POT_TEST,\n",
    "    CRITIC_CRITIQUE_INSTRUCTION_HUMANEVAL,\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_CRITIC\n",
    ")\n",
    "from agential.cog.functional.critic import _prompt_agent, safe_execute, _prompt_critique\n",
    "\n",
    "import dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from langchain_community.chat_models.openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PROMPT AGENT===========================================================================>\n",
      "You are an AI that only responds with python code, NOT ENGLISH. You will be given a function signature and its docstring by the user. Write your full implementation (restate the function signature, all imports, and docstring).\n",
      "\n",
      "[function signature]:\n",
      "def has_duplicate_names(names_list: List[str]) -> bool:\n",
      "    \"\"\"Check if there is any name that appears more than once in the list.\n",
      "    >>> has_duplicate_names(['Alice', 'Bob', 'Charlie', 'Alice'])\n",
      "    True\n",
      "    >>> has_duplicate_names(['Alice', 'Bob', 'Charlie', 'Dave']) \n",
      "    False\n",
      "    \"\"\"\n",
      "    return len(names_list) != len(set(names_list))\n",
      "\n",
      "[function signature]:\n",
      "def average_positive(numbers: List[int]) -> float:\n",
      "    \"\"\"Calculate the average of positive numbers in the list.\n",
      "    >>> average_positive([1, -1, 2, -2, 3])\n",
      "    2.0\n",
      "    >>> average_positive([-5, 0, 5, 15])\n",
      "    10.0\n",
      "    >>> average_positive([100, 200, -100, 0])\n",
      "    150.0\n",
      "    >>> average_positive([-1, -2, -3])\n",
      "    0\n",
      "    \"\"\"\n",
      "    positive_numbers = [num for num in numbers if num > 0]\n",
      "    return sum(positive_numbers) / len(positive_numbers) if positive_numbers else 0\n",
      "\n",
      "[function signature]:\n",
      "def exceeds_threshold(measurements: List[float], threshold: float) -> int:\n",
      "    \"\"\"Return the count of instances where the difference between any two successive measurements exceeds the given threshold.\n",
      "    >>> exceeds_threshold([100, 102, 107, 103], 5) \n",
      "    1\n",
      "    >>> exceeds_threshold([100, 101, 102, 103], 2) \n",
      "    0\n",
      "    \"\"\"\n",
      "    count = 0\n",
      "    for i in range(1, len(measurements)):\n",
      "        if abs(measurements[i] - measurements[i - 1]) > threshold:\n",
      "            count += 1\n",
      "    return count\n",
      "\n",
      "[function signature]:\n",
      "def sum_even_indexed(numbers: List[int]) -> int:\n",
      "    \"\"\"Sum numbers that are located at even indices in the list.\n",
      "    >>> sum_even_indexed([10, 3, 5, 2, 8])\n",
      "    23\n",
      "    >>> sum_even_indexed([1, 2, 3, 4, 5, 6])\n",
      "    9\n",
      "    >>> sum_even_indexed([0, 100, 200, 300])\n",
      "    200\n",
      "    >>> sum_even_indexed([7])\n",
      "    7\n",
      "    \"\"\"\n",
      "    return sum(num for i, num in enumerate(numbers) if i % 2 == 0)\n",
      "\n",
      "[function signature]:\n",
      "from collections import Counter\n",
      "\n",
      "def are_anagrams(s1: str, s2: str) -> bool:\n",
      "    \"\"\"Check if two strings are anagrams of each other, ignoring case.\n",
      "    >>> are_anagrams('Listen', 'Silent')\n",
      "    True\n",
      "    >>> are_anagrams('Hello', 'World')\n",
      "    False\n",
      "    >>> are_anagrams('Angel', 'Glean')\n",
      "    True\n",
      "    \"\"\"\n",
      "    return Counter(s1.lower()) == Counter(s2.lower())\n",
      "\n",
      "(END OF EXAMPLES)\n",
      "\n",
      "[function signature]:\n",
      "from typing import List \n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool: \n",
      "    \"\"\"Check if in given list of numbers, are any two numbers closer to each other than given threshold. \n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5) False \n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) True\n",
      "    \"\"\"\n",
      "\n",
      "<PROMPT AGENT===========================================================================>\n",
      "<OUT AGENT===========================================================================>\n",
      "'from typing import List \\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool: \\n    \"\"\"Check if in given list of numbers, are any two numbers closer to each other than given threshold. \\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5) False \\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) True\\n    \"\"\"\\n    for i in range(len(numbers)):\\n        for j in range(i + 1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False'\n",
      "<OUT AGENT===========================================================================>\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"from typing import List \n",
    "\n",
    "def has_close_elements(numbers: List[float], threshold: float) -> bool: \n",
    "    \\\"\\\"\\\"Check if in given list of numbers, are any two numbers closer to each other than given threshold. \n",
    "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5) False \n",
    "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) True\n",
    "    \\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "code = _prompt_agent(\n",
    "    llm=llm,\n",
    "    question=question,\n",
    "    examples=HUMANEVAL_FEWSHOT_EXAMPLES_POT,\n",
    "    prompt=CRITIC_POT_INSTRUCTION_HUMANEVAL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List \n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool: \n",
      "    \"\"\"Check if in given list of numbers, are any two numbers closer to each other than given threshold. \n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5) False \n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) True\n",
      "    \"\"\"\n",
      "    for i in range(len(numbers)):\n",
      "        for j in range(i + 1, len(numbers)):\n",
      "            if abs(numbers[i] - numbers[j]) < threshold:\n",
      "                return True\n",
      "    return False\n"
     ]
    }
   ],
   "source": [
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PROMPT AGENT===========================================================================>\n",
      "You are an AI coding assistant that can write unique, diverse, and intuitive unit tests for functions given the signature and docstring.\n",
      "\n",
      "[function signature]:\n",
      "def has_duplicate_names(names_list: List[str]) -> bool:\n",
      "    \"\"\"Check if there is any name that appears more than once in the list.\n",
      "    >>> has_duplicate_names(['Alice', 'Bob', 'Charlie', 'Alice'])\n",
      "    True\n",
      "    >>> has_duplicate_names(['Alice', 'Bob', 'Charlie', 'Dave']) \n",
      "    False\n",
      "    \"\"\"\n",
      "\n",
      "[unit tests]:\n",
      "assert has_duplicate_names(['Alice', 'Bob', 'Charlie', 'Alice']) == True, \"Test failed: has_duplicate_names(['Alice', 'Bob', 'Charlie', 'Alice']) should return True\"\n",
      "assert has_duplicate_names(['Alice', 'Bob', 'Charlie', 'Dave']) == False, \"Test failed: has_duplicate_names(['Alice', 'Bob', 'Charlie', 'Dave']) should return False\"\n",
      "\n",
      "[function signature]:\n",
      "def average_positive(numbers: List[int]) -> float:\n",
      "    \"\"\"Calculate the average of positive numbers in the list.\n",
      "    >>> average_positive([1, -1, 2, -2, 3])\n",
      "    2.0\n",
      "    >>> average_positive([-5, 0, 5, 15])\n",
      "    10.0\n",
      "    >>> average_positive([100, 200, -100, 0])\n",
      "    150.0\n",
      "    >>> average_positive([-1, -2, -3])\n",
      "    0\n",
      "    \"\"\"\n",
      "\n",
      "[unit tests]:\n",
      "assert average_positive([1, -1, 2, -2, 3]) == 2.0, \"Test failed: average_positive([1, -1, 2, -2, 3]) should return 2.0\"\n",
      "assert average_positive([-5, 0, 5, 15]) == 10.0, \"Test failed: average_positive([-5, 0, 5, 15]) should return 10.0\"\n",
      "assert average_positive([100, 200, -100, 0]) == 150.0, \"Test failed: average_positive([100, 200, -100, 0]) should return 150.0\"\n",
      "assert average_positive([-1, -2, -3]) == 0, \"Test failed: average_positive([-1, -2, -3]) should return 0\"\n",
      "\n",
      "[function signature]:\n",
      "def exceeds_threshold(measurements: List[float], threshold: float) -> int:\n",
      "    \"\"\"Return the count of instances where the difference between any two successive measurements exceeds the given threshold.\n",
      "    >>> exceeds_threshold([100, 102, 107, 103], 5) \n",
      "    1\n",
      "    >>> exceeds_threshold([100, 101, 102, 103], 2) \n",
      "    0\n",
      "    \"\"\"\n",
      "\n",
      "[unit tests]:\n",
      "assert exceeds_threshold([100, 102, 107, 103], 5) == 1, \"Test failed: exceeds_threshold([100, 102, 107, 103], 5) should return 1\"\n",
      "assert exceeds_threshold([100, 101, 102, 103], 2) == 0, \"Test failed: exceeds_threshold([100, 101, 102, 103], 2) should return 0\"\n",
      "\n",
      "[function signature]:\n",
      "def sum_even_indexed(numbers: List[int]) -> int:\n",
      "    \"\"\"Sum numbers that are located at even indices in the list.\n",
      "    >>> sum_even_indexed([10, 3, 5, 2, 8])\n",
      "    23\n",
      "    >>> sum_even_indexed([1, 2, 3, 4, 5, 6])\n",
      "    9\n",
      "    >>> sum_even_indexed([0, 100, 200, 300])\n",
      "    200\n",
      "    >>> sum_even_indexed([7])\n",
      "    7\n",
      "    \"\"\"\n",
      "\n",
      "[unit tests]:\n",
      "assert sum_even_indexed([10, 3, 5, 2, 8]) == 23, \"Test failed: sum_even_indexed([10, 3, 5, 2, 8]) should return 23\"\n",
      "assert sum_even_indexed([1, 2, 3, 4, 5, 6]) == 9, \"Test failed: sum_even_indexed([1, 2, 3, 4, 5, 6]) should return 9\"\n",
      "assert sum_even_indexed([0, 100, 200, 300]) == 200, \"Test failed: sum_even_indexed([0, 100, 200, 300]) should return 200\"\n",
      "assert sum_even_indexed([7]) == 7, \"Test failed: sum_even_indexed([7]) should return 7\"\n",
      "\n",
      "[function signature]:\n",
      "from collections import Counter\n",
      "\n",
      "def are_anagrams(s1: str, s2: str) -> bool:\n",
      "    \"\"\"Check if two strings are anagrams of each other, ignoring case.\n",
      "    >>> are_anagrams('Listen', 'Silent')\n",
      "    True\n",
      "    >>> are_anagrams('Hello', 'World')\n",
      "    False\n",
      "    >>> are_anagrams('Angel', 'Glean')\n",
      "    True\n",
      "    \"\"\"\n",
      "\n",
      "[unit tests]:\n",
      "assert are_anagrams('Listen', 'Silent') == True, \"Test failed: are_anagrams('Listen', 'Silent') should return True\"\n",
      "assert are_anagrams('Hello', 'World') == False, \"Test failed: are_anagrams('Hello', 'World') should return False\"\n",
      "assert are_anagrams('Angel', 'Glean') == True, \"Test failed: are_anagrams('Angel', 'Glean') should return True\"\n",
      "\n",
      "(END OF EXAMPLES)\n",
      "\n",
      "[function signature]:\n",
      "from typing import List \n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool: \n",
      "    \"\"\"Check if in given list of numbers, are any two numbers closer to each other than given threshold. \n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5) False \n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) True\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "[unit tests]:\n",
      "<PROMPT AGENT===========================================================================>\n",
      "<OUT AGENT===========================================================================>\n",
      "'assert has_close_elements([1.0, 2.0, 3.0], 0.5) == False, \"Test failed: has_close_elements([1.0, 2.0, 3.0], 0.5) should return False\"\\nassert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True, \"Test failed: has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) should return True\"'\n",
      "<OUT AGENT===========================================================================>\n"
     ]
    }
   ],
   "source": [
    "tests = _prompt_agent(\n",
    "    llm=llm,\n",
    "    question=question,\n",
    "    examples=HUMANEVAL_FEWSHOT_EXAMPLES_POT_TEST,\n",
    "    prompt=CRITIC_POT_INSTRUCTION_TEST_HUMANEVAL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assert has_close_elements([1.0, 2.0, 3.0], 0.5) == False, \"Test failed: has_close_elements([1.0, 2.0, 3.0], 0.5) should return False\"\n",
      "assert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True, \"Test failed: has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) should return True\"\n"
     ]
    }
   ],
   "source": [
    "print(tests) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_answer, execution_status = safe_execute(\n",
    "    code + \"\\n\\n\" + tests #+ \"assert False\" + \"\\n\\n\"\n",
    ")  # Can be None, \"Exception\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " \"AssertionError('Test failed: exceeds_threshold([100, 102, 107, 103], 5) should return 1')\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"\"\"def exceeds_threshold(measurements: List[float], threshold: float) -> int:\n",
    "    count = 0\n",
    "    for i in range(1, len(measurements)):\n",
    "        if abs(measurements[i] - measurements[i - 1]) > (threshold + 1):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "assert exceeds_threshold([100, 102, 107, 103], 5) == 1, \"Test failed: exceeds_threshold([100, 102, 107, 103], 5) should return 1\"\n",
    "assert exceeds_threshold([100, 101, 102, 103], 2) == 0, \"Test failed: exceeds_threshold([100, 101, 102, 103], 2) should return 0\"\n",
    "\"\"\"\n",
    "\n",
    "safe_execute(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critique_additional_keys = {\n",
    "    \"execution_status\": execution_status,\n",
    "    \"code_answer\": code_answer,\n",
    "}\n",
    "\n",
    "critique = _prompt_critique(\n",
    "    llm=llm,\n",
    "    question=code,\n",
    "    examples=critique_examples,\n",
    "    answer=tests,\n",
    "    critique=\"\",\n",
    "    additional_keys=critique_additional_keys,\n",
    "    prompt=critique_prompt\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
