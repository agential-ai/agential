{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agential.cog.agent.critic import CriticAgent\n",
    "# from agential.cog.agent.critic_old import CriticAgent as OldCriticAgent\n",
    "from langchain_community.utilities.google_search import GoogleSearchAPIWrapper\n",
    "\n",
    "from langchain_community.chat_models.openai import ChatOpenAI\n",
    "from agential.cog.prompts.critic import (\n",
    "    # QA.\n",
    "    CRITIC_INSTRUCTION_HOTPOTQA,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_COT,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_DIRECT,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_REACT,\n",
    "    CRITIC_CRITIQUE_INSTRUCTION_HOTPOTQA,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_CRITIC,\n",
    "\n",
    "    CRITIC_INSTRUCTION_FEVER,\n",
    "    FEVER_FEWSHOT_EXAMPLES_COT,\n",
    "    FEVER_FEWSHOT_EXAMPLES_DIRECT,\n",
    "    FEVER_FEWSHOT_EXAMPLES_REACT,\n",
    "    CRITIC_CRITIQUE_INSTRUCTION_FEVER,\n",
    "    FEVER_FEWSHOT_EXAMPLES_CRITIC,\n",
    "\n",
    "    CRITIC_INSTRUCTION_AMBIGNQ,\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_COT,\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_DIRECT,\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_REACT,\n",
    "    CRITIC_CRITIQUE_INSTRUCTION_AMBIGNQ,\n",
    "    AMBIGNQ_FEWSHOT_EXAMPLES_CRITIC,\n",
    "\n",
    "    CRITIC_INSTRUCTION_TRIVIAQA,\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_COT,\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_DIRECT,\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_REACT,\n",
    "    CRITIC_CRITIQUE_INSTRUCTION_TRIVIAQA,\n",
    "    TRIVIAQA_FEWSHOT_EXAMPLES_CRITIC,\n",
    "\n",
    "    # Math.\n",
    "    CRITIC_POT_INSTRUCTION_GSM8K,\n",
    "    GSM8K_FEWSHOT_EXAMPLES_POT,\n",
    "    CRITIC_CRITIQUE_INSTRUCTION_GSM8K,\n",
    "    GSM8K_FEWSHOT_EXAMPLES_CRITIC,\n",
    "    CRITIC_CRITIQUE_NO_TOOL_INSTRUCTION_GSM8K,\n",
    "    GSM8K_FEWSHOT_EXAMPLES_CRITIC_NO_TOOL,\n",
    "\n",
    "    CRITIC_POT_INSTRUCTION_SVAMP,\n",
    "    SVAMP_FEWSHOT_EXAMPLES_POT,\n",
    "    CRITIC_CRITIQUE_INSTRUCTION_SVAMP,\n",
    "    SVAMP_FEWSHOT_EXAMPLES_CRITIC,\n",
    "    CRITIC_CRITIQUE_NO_TOOL_INSTRUCTION_SVAMP,\n",
    "    SVAMP_FEWSHOT_EXAMPLES_CRITIC_NO_TOOL,\n",
    "\n",
    "    CRITIC_POT_INSTRUCTION_TABMWP,\n",
    "    TABMWP_FEWSHOT_EXAMPLES_POT,\n",
    "    CRITIC_CRITIQUE_INSTRUCTION_TABMWP,\n",
    "    TABMWP_FEWSHOT_EXAMPLES_CRITIC,\n",
    "    CRITIC_CRITIQUE_NO_TOOL_INSTRUCTION_TABMWP,\n",
    "    TABMWP_FEWSHOT_EXAMPLES_CRITIC_NO_TOOL,\n",
    "\n",
    "    # Code.\n",
    "    CRITIC_POT_INSTRUCTION_HUMANEVAL,\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_POT,\n",
    "    CRITIC_CRITIQUE_INSTRUCTION_HUMANEVAL,\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_CRITIC,\n",
    "    CRITIC_CRITIQUE_NO_TOOL_INSTRUCTION_HUMANEVAL,\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_CRITIC_NO_TOOL,\n",
    "\n",
    "    CRITIC_POT_INSTRUCTION_MBPP,\n",
    "    MBPP_FEWSHOT_EXAMPLES_POT,\n",
    "    CRITIC_CRITIQUE_INSTRUCTION_MBPP,\n",
    "    MBPP_FEWSHOT_EXAMPLES_CRITIC,\n",
    "    CRITIC_CRITIQUE_NO_TOOL_INSTRUCTION_MBPP,\n",
    "    MBPP_FEWSHOT_EXAMPLES_CRITIC_NO_TOOL,\n",
    ")\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "search = GoogleSearchAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "D\n",
      "E\n",
      "\"1. The revenue from selling eggs should be a positive number, -9867630 < 0, which is not reasonable.\\n\\n2. Let's check the code:\\n\\n- `total_eggs = 16` - This defines the total number of eggs laid by Janet's ducks per day.\\n- `eaten_eggs = 3` - This represents the number of eggs Janet eats for breakfast.\\n- `baked_eggs = 4933828` - This represents the number of eggs Janet uses to bake muffins for her friends daily.\\n- `sold_eggs = total_eggs - eaten_eggs - baked_eggs` - This calculates the number of eggs Janet has left to sell at the farmers' market.\\n- `dollars_per_egg = 2` - This represents the selling price of each fresh duck egg.\\n- `answer = sold_eggs * dollars_per_egg` - This calculates the total revenue from selling eggs at the farmers' market.\\n\\nThe issue with the code is that the calculation for `sold_eggs` is incorrect. Janet should only sell the eggs that are left after she eats some for breakfast and uses some for baking. \\n\\nHere's a corrected solution:\\n\\n```python\\ntotal_eggs = 16\\neaten_eggs = 3\\nbaked_eggs = 4933828\\n\\n# Calculate the number of eggs left to sell\\nremaining_eggs = total_eggs - eaten_eggs - baked_eggs\\n\\ndollars_per_egg = 2\\n\\n# Calculate the revenue from selling eggs\\ntotal_revenue = remaining_eggs * dollars_per_egg\\n\\nanswer = total_revenue\\n```\"\n"
     ]
    }
   ],
   "source": [
    "from agential.cog.strategies.critic.math_strategy import (\n",
    "    CritGSM8KStrategy,\n",
    "    CritSVAMPStrategy,\n",
    "    CritTabMWPStrategy,\n",
    "    MathStrategy,\n",
    ")\n",
    "strategy = MathStrategy(llm=llm)\n",
    "\n",
    "question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with 4933828. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\n",
    "answer = 'total_eggs = 16\\neaten_eggs = 3\\nbaked_eggs = 4933828\\nsold_eggs = total_eggs - eaten_eggs - baked_eggs\\ndollars_per_egg = 2\\nanswer = sold_eggs * dollars_per_egg'\n",
    "\n",
    "result, external_tool_info = strategy.generate_critique(\n",
    "    idx=0,\n",
    "    question=question,\n",
    "    examples=GSM8K_FEWSHOT_EXAMPLES_CRITIC,\n",
    "    answer=answer,\n",
    "    critique=\"\",\n",
    "    prompt=CRITIC_CRITIQUE_INSTRUCTION_GSM8K,\n",
    "    additional_keys={},\n",
    "    use_tool=True,\n",
    "    max_interactions=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'execution_status': 'Done', 'code_answer': -9867630}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_tool_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CriticAgent(\n",
    "    llm=llm, mode={\"qa\": \"hotpotqa\"}, search=search\n",
    ")\n",
    "use_tool = False\n",
    "\n",
    "# HotpotQA\n",
    "question = 'Who was once considered the best kick boxer in the world, however he has been involved in a number of controversies relating to his \"unsportsmanlike conducts\" in the sport and crimes of violence outside of the ring'\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    examples=HOTPOTQA_FEWSHOT_EXAMPLES_COT,  # HOTPOTQA_FEWSHOT_EXAMPLES_DIRECT, HOTPOTQA_FEWSHOT_EXAMPLES_REACT\n",
    "    prompt=CRITIC_INSTRUCTION_HOTPOTQA,\n",
    "    critique_examples=HOTPOTQA_FEWSHOT_EXAMPLES_CRITIC,\n",
    "    critique_prompt=CRITIC_CRITIQUE_INSTRUCTION_HOTPOTQA,\n",
    "    max_interactions=3,\n",
    "    use_tool=use_tool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CriticAgent(\n",
    "    llm=llm, mode={\"qa\": \"fever\"}, search=search\n",
    ")\n",
    "use_tool = False\n",
    "\n",
    "# FEVER\n",
    "question = \"Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.\"\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    examples=FEVER_FEWSHOT_EXAMPLES_COT,  # FEVER_FEWSHOT_EXAMPLES_DIRECT, FEVER_FEWSHOT_EXAMPLES_REACT\n",
    "    prompt=CRITIC_INSTRUCTION_FEVER,\n",
    "    critique_examples=FEVER_FEWSHOT_EXAMPLES_CRITIC,\n",
    "    critique_prompt=CRITIC_CRITIQUE_INSTRUCTION_FEVER,\n",
    "    max_interactions=3,\n",
    "    use_tool=use_tool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CriticAgent(\n",
    "    llm=llm, mode={\"qa\": \"ambignq\"}, search=search\n",
    ")\n",
    "use_tool = False\n",
    "\n",
    "# AmbigNQ\n",
    "question = \"When did the simpsons first air on television?\"\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    examples=AMBIGNQ_FEWSHOT_EXAMPLES_COT,  # AMBIGNQ_FEWSHOT_EXAMPLES_DIRECT, AMBIGNQ_FEWSHOT_EXAMPLES_REACT\n",
    "    prompt=CRITIC_INSTRUCTION_AMBIGNQ,\n",
    "    critique_examples=AMBIGNQ_FEWSHOT_EXAMPLES_CRITIC,\n",
    "    critique_prompt=CRITIC_CRITIQUE_INSTRUCTION_AMBIGNQ,\n",
    "    max_interactions=3,\n",
    "    use_tool=use_tool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CriticAgent(\n",
    "    llm=llm, mode={\"qa\": \"triviaqa\"}, search=search\n",
    ")\n",
    "use_tool = False\n",
    "\n",
    "# TriviaQA\n",
    "question = \"Which American-born Sinclair won the Nobel Prize for Literature in 1930?\"\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    examples=TRIVIAQA_FEWSHOT_EXAMPLES_COT,  # TRIVIAQA_FEWSHOT_EXAMPLES_DIRECT, TRIVIAQA_FEWSHOT_EXAMPLES_REACT\n",
    "    prompt=CRITIC_INSTRUCTION_TRIVIAQA,\n",
    "    critique_examples=TRIVIAQA_FEWSHOT_EXAMPLES_CRITIC,\n",
    "    critique_prompt=CRITIC_CRITIQUE_INSTRUCTION_TRIVIAQA,\n",
    "    max_interactions=3,\n",
    "    use_tool=use_tool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CriticAgent(\n",
    "    llm=llm, mode={\"math\": \"gsm8k\"}\n",
    ")\n",
    "\n",
    "use_tool = True\n",
    "\n",
    "# GSM8k\n",
    "question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with 4933828. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    examples=GSM8K_FEWSHOT_EXAMPLES_POT,\n",
    "    prompt=CRITIC_POT_INSTRUCTION_GSM8K,\n",
    "    critique_examples=GSM8K_FEWSHOT_EXAMPLES_CRITIC if use_tool else GSM8K_FEWSHOT_EXAMPLES_CRITIC_NO_TOOL,\n",
    "    critique_prompt=CRITIC_CRITIQUE_INSTRUCTION_GSM8K if use_tool else CRITIC_CRITIQUE_NO_TOOL_INSTRUCTION_GSM8K,\n",
    "    use_tool=use_tool,\n",
    "    max_interactions=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CriticAgent(\n",
    "    llm=llm, mode={\"math\": \"svamp\"}\n",
    ")\n",
    "\n",
    "use_tool = True\n",
    "\n",
    "# SVAMP\n",
    "question = \"There are 87 oranges and 290 bananas in Philip's collection. If the bananas are organized into 2 groups and oranges are organized into 93 groups. How big is each group of bananas?\"\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    examples=SVAMP_FEWSHOT_EXAMPLES_POT,\n",
    "    prompt=CRITIC_POT_INSTRUCTION_SVAMP,\n",
    "    critique_examples=SVAMP_FEWSHOT_EXAMPLES_CRITIC if use_tool else SVAMP_FEWSHOT_EXAMPLES_CRITIC_NO_TOOL,\n",
    "    critique_prompt=CRITIC_CRITIQUE_INSTRUCTION_SVAMP if use_tool else CRITIC_CRITIQUE_NO_TOOL_INSTRUCTION_SVAMP,\n",
    "    use_interpreter_tool=use_tool,\n",
    "    max_interactions=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CriticAgent(\n",
    "    llm=llm, mode={\"math\": \"tabmwp\"}\n",
    ")\n",
    "\n",
    "use_tool = True\n",
    "\n",
    "# TabMWP\n",
    "question = \"\"\"Read the following table regarding \"Bowling Scores\" and then write Python code to answer a question:\n",
    "\n",
    "Name | Score\n",
    "Amanda | 117\n",
    "Sam | 236\n",
    "Irma | 144\n",
    "Mike | 164\n",
    "\n",
    "Question: Some friends went bowling and kept track of their scores. How many more points did Mike score than Irma?\"\"\"\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    examples=TABMWP_FEWSHOT_EXAMPLES_POT,\n",
    "    prompt=CRITIC_POT_INSTRUCTION_TABMWP,\n",
    "    critique_examples=TABMWP_FEWSHOT_EXAMPLES_CRITIC if use_tool else TABMWP_FEWSHOT_EXAMPLES_CRITIC_NO_TOOL,\n",
    "    critique_prompt=CRITIC_CRITIQUE_INSTRUCTION_TABMWP if use_tool else CRITIC_CRITIQUE_NO_TOOL_INSTRUCTION_TABMWP,\n",
    "    use_interpreter_tool=use_tool,\n",
    "    max_interactions=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HumanEval\n",
    "agent = CriticAgent(\n",
    "    llm=llm, mode={\"code\": \"humaneval\"}\n",
    ")\n",
    "use_tool = True\n",
    "\n",
    "inst = {\"task_id\": \"HumanEval/0\", \"prompt\": \"from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \\\"\\\"\\\"\\n\", \"entry_point\": \"has_close_elements\", \"canonical_solution\": \"    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n\", \"test\": \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\\n\\n\"}\n",
    "\n",
    "question = inst['prompt']\n",
    "\n",
    "tests = f\"{inst['test']}\\ncheck({inst['entry_point']})\"\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    critique_additional_keys={\"tests\": tests},\n",
    "    examples=HUMANEVAL_FEWSHOT_EXAMPLES_POT,\n",
    "    prompt=CRITIC_POT_INSTRUCTION_HUMANEVAL,\n",
    "    critique_examples=HUMANEVAL_FEWSHOT_EXAMPLES_CRITIC if use_tool else HUMANEVAL_FEWSHOT_EXAMPLES_CRITIC_NO_TOOL,\n",
    "    critique_prompt=CRITIC_CRITIQUE_INSTRUCTION_HUMANEVAL if use_tool else CRITIC_CRITIQUE_NO_TOOL_INSTRUCTION_HUMANEVAL,\n",
    "    use_tool=use_tool,\n",
    "    max_interactions=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MBPP\n",
    "agent = CriticAgent(\n",
    "    llm=llm, mode={\"code\": \"mbpp\"}\n",
    ")\n",
    "use_tool = True\n",
    "\n",
    "question = \"Write a python function to find the first repeated character in a given string.\"\n",
    "tests = \"\"\"assert first_repeated_char(\"abcabc\") == \"a\"\n",
    "assert first_repeated_char(\"abc\") == None\n",
    "assert first_repeated_char(\"123123\") == \"1\\\"\"\"\"\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    additional_keys={\"tests\": tests},\n",
    "    critique_additional_keys={\"tests\": tests},\n",
    "    examples=MBPP_FEWSHOT_EXAMPLES_POT,\n",
    "    prompt=CRITIC_POT_INSTRUCTION_MBPP,\n",
    "    critique_examples=MBPP_FEWSHOT_EXAMPLES_CRITIC if use_tool else MBPP_FEWSHOT_EXAMPLES_CRITIC_NO_TOOL,\n",
    "    critique_prompt=CRITIC_CRITIQUE_INSTRUCTION_MBPP if use_tool else CRITIC_CRITIQUE_NO_TOOL_INSTRUCTION_MBPP,\n",
    "    use_tool=use_tool,\n",
    "    max_interactions=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
