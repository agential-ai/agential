{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agential.cog.lats.strategies.qa import LATSQAStrategy \n",
    "from agential.cog.lats.strategies.math import LATSMathStrategy \n",
    "from agential.cog.lats.strategies.code import LATSCodeStrategy \n",
    "from agential.llm.llm import LLM\n",
    "from agential.cog.fewshots.hotpotqa import (\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_REACT,\n",
    ")\n",
    "from agential.cog.fewshots.gsm8k import (\n",
    "    GSM8K_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.fewshots.humaneval import (\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.fewshots.mbpp import (\n",
    "    MBPP_FEWSHOT_EXAMPLES_REACT\n",
    ")\n",
    "from agential.cog.lats.prompts import (\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_HOTPOTQA,\n",
    "    LATS_REFLECT_INSTRUCTION_HOTPOTQA,\n",
    "    HOTPOTQA_FEWSHOT_EXAMPLES_LATS_VALUE, \n",
    "    LATS_VALUE_INSTRUCTION_HOTPOTQA,\n",
    "\n",
    "    GSM8K_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    GSM8K_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    LATS_INSTRUCTION_GSM8K,\n",
    "    LATS_REFLECT_INSTRUCTION_GSM8K,\n",
    "    LATS_VALUE_INSTRUCTION_GSM8K,\n",
    "\n",
    "    MBPP_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_MBPP,\n",
    "    LATS_REFLECT_INSTRUCTION_MBPP,\n",
    "    MBPP_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    LATS_VALUE_INSTRUCTION_MBPP,\n",
    "\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    LATS_INSTRUCTION_HUMANEVAL,\n",
    "    LATS_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    "    HUMANEVAL_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    LATS_VALUE_INSTRUCTION_HUMANEVAL,\n",
    ")\n",
    "\n",
    "from agential.cog.lats.functional import get_node_trajectory_qa, get_node_trajectory_math, get_node_trajectory_code\n",
    "\n",
    "\n",
    "llm = LLM(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4933815\n",
      "\n",
      "Thought 1: I need to calculate how much money Janet makes every day at the farmers' market.\n",
      "Action 1: Calculate[\n",
      "```python\n",
      "eggs_laid_per_day = 16\n",
      "eggs_consumed_for_breakfast = 3\n",
      "eggs_used_for_muffins = 4933828\n",
      "eggs_sold_at_market = eggs_laid_per_day - eggs_consumed_for_breakfast - eggs_used_for_muffins\n",
      "earnings_per_egg = 2\n",
      "total_earnings = eggs_sold_at_market * earnings_per_egg\n",
      "answer = total_earnings\n",
      "```\n",
      "]\n",
      "Observation 1: \n",
      "```python\n",
      "eggs_laid_per_day = 16\n",
      "eggs_consumed_for_breakfast = 3\n",
      "eggs_used_for_muffins = 4933828\n",
      "eggs_sold_at_market = eggs_laid_per_day - eggs_consumed_for_breakfast - eggs_used_for_muffins\n",
      "earnings_per_egg = 2\n",
      "total_earnings = eggs_sold_at_market * earnings_per_egg\n",
      "answer = total_earnings\n",
      "```\n",
      "Execution Status: Done\n",
      "Output: answer = -9867630\n",
      "Thought 2: The output is incorrect. I need to review the calculation for eggs sold at the market. The subtraction seems to be causing a negative value, which is not possible in this context.\n",
      "Action 2: Calculate[\n",
      "```python\n",
      "eggs_laid_per_day = 16\n",
      "eggs_consumed_for_breakfast = 3\n",
      "eggs_used_for_muffins = 4933828\n",
      "eggs_sold_at_market = eggs_laid_per_day - eggs_consumed_for_breakfast - eggs_used_for_muffins\n",
      "print(eggs_sold_at_market)\n",
      "```\n",
      "]\n",
      "Observation 2: \n",
      "```python\n",
      "eggs_laid_per_day = 16\n",
      "eggs_consumed_for_breakfast = 3\n",
      "eggs_used_for_muffins = 4933828\n",
      "eggs_sold_at_market = eggs_laid_per_day - eggs_consumed_for_breakfast - eggs_used_for_muffins\n",
      "print(eggs_sold_at_market)\n",
      "```\n",
      "Execution Status: Done\n",
      "Output: answer = None\n",
      "Thought 3: The code did not return a value because the quantity becomes a negative value, which is not practical. I need to reassess the approach to calculating the eggs sold at the market.\n",
      "Action 3: Finish[\n",
      "```python\n",
      "answer = \"Cannot calculate as eggs sold would be negative\"\n",
      "```\n",
      "]\n",
      "Observation 3: Answer is INCORRECT\n"
     ]
    }
   ],
   "source": [
    "question = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with 4933828. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\"\n",
    "key = -9867630\n",
    "\n",
    "strategy = LATSMathStrategy(\n",
    "    llm=llm, \n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    "    testing=True\n",
    ")\n",
    "out = strategy.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=GSM8K_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=GSM8K_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=GSM8K_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_GSM8K,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_GSM8K,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_GSM8K,\n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True,\n",
    ")\n",
    "\n",
    "print(get_node_trajectory_math(out.answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00567\n",
      "3780\n",
      "0.0223185\n",
      "44637\n",
      "48417\n",
      "0.0279885\n",
      "45.144935131073\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "for i in [\n",
    "    \"total_completion_cost\",\n",
    "    \"total_completion_tokens\",\n",
    "    \"total_prompt_cost\",\n",
    "    \"total_prompt_tokens\",\n",
    "    \"total_tokens\",\n",
    "    \"total_cost\",\n",
    "    \"total_prompt_time\",\n",
    "    \"total_time\"\n",
    "]:\n",
    "    print(getattr(out, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thought 1: To solve this problem, I need to iterate through the list of numbers and compare each pair of numbers to see if they are closer to each other than the given threshold.\n",
      "Action 1: Implement[\n",
      "```python\n",
      "from typing import List\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    for i in range(len(numbers)):\n",
      "        for j in range(i+1, len(numbers)):\n",
      "            if abs(numbers[i] - numbers[j]) < threshold:\n",
      "                return True\n",
      "    return False\n",
      "```\n",
      "]\n",
      "Observation 1: \n",
      "```python\n",
      "from typing import List\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    for i in range(len(numbers)):\n",
      "        for j in range(i+1, len(numbers)):\n",
      "            if abs(numbers[i] - numbers[j]) < threshold:\n",
      "                return True\n",
      "    return False\n",
      "```\n",
      "Execution Status: \n",
      "Thought 2: Now, let's test the implemented function with some test cases to verify its correctness.\n",
      "Action 2: Test[\n",
      "```python\n",
      "assert has_close_elements([1.0, 2.0, 3.0], 0.5) == False\n",
      "assert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True\n",
      "```\n",
      "]\n",
      "Observation 2: \n",
      "```python\n",
      "from typing import List\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    for i in range(len(numbers)):\n",
      "        for j in range(i+1, len(numbers)):\n",
      "            if abs(numbers[i] - numbers[j]) < threshold:\n",
      "                return True\n",
      "    return False\n",
      "\n",
      "assert has_close_elements([1.0, 2.0, 3.0], 0.5) == False\n",
      "assert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True\n",
      "```\n",
      "Execution Status: Done\n",
      "Thought 3: The function has passed the test cases, and it correctly identifies if there are any two numbers in the list closer to each other than the given threshold. I will finish this task now.\n",
      "Action 3: Finish[\n",
      "```python\n",
      "from typing import List\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    for i in range(len(numbers)):\n",
      "        for j in range(i+1, len(numbers)):\n",
      "            if abs(numbers[i] - numbers[j]) < threshold:\n",
      "                return True\n",
      "    return False\n",
      "```\n",
      "]\n",
      "Observation 3: Answer is CORRECT\n"
     ]
    }
   ],
   "source": [
    "inst = {\"task_id\": \"HumanEval/0\", \"prompt\": \"from typing import List\\n\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    \\\"\\\"\\\" Check if in given list of numbers, are any two numbers closer to each other than\\n    given threshold.\\n    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\\n    False\\n    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\\n    True\\n    \\\"\\\"\\\"\\n\", \"entry_point\": \"has_close_elements\", \"canonical_solution\": \"    for idx, elem in enumerate(numbers):\\n        for idx2, elem2 in enumerate(numbers):\\n            if idx != idx2:\\n                distance = abs(elem - elem2)\\n                if distance < threshold:\\n                    return True\\n\\n    return False\\n\", \"test\": \"\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'dataset': 'test'\\n}\\n\\n\\ndef check(candidate):\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\\n    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\\n    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\\n    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\\n    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\\n\\n\"}\n",
    "question = inst['prompt']\n",
    "key = f\"{inst['test']}\\ncheck({inst['entry_point']})\"\n",
    "\n",
    "agent = LATSCodeStrategy(\n",
    "    llm=llm, \n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=HUMANEVAL_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=HUMANEVAL_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=HUMANEVAL_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_HUMANEVAL,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_HUMANEVAL,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_HUMANEVAL,            \n",
    "    additional_keys={},\n",
    "    reflect_additional_keys={},\n",
    "    value_additional_keys={},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")\n",
    "\n",
    "print(get_node_trajectory_code(out.answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LATSOutput(answer=<agential.cog.lats.node.Node object at 0x0000024239BBA710>, total_prompt_tokens=17373, total_completion_tokens=2930, total_tokens=20303, total_prompt_cost=0.0086865, total_completion_cost=0.0043950000000000005, total_cost=0.013081500000000001, total_prompt_time=31.990691423416138, total_time=32.01023483276367, additional_info=[LATSStepOutput(iteration=0, current_node={'state': LATSReActStepOutput(thought='', action_type='', query='', observation='', answer='', external_tool_info={}), 'visits': 0, 'value': 0, 'depth': 0, 'is_terminal': False, 'reward': 0}, children_nodes=[{'state': LATSReActStepOutput(thought='To solve this problem, I need to iterate through the list of numbers and compare each pair of numbers to see if they are closer to each other than the given threshold.', action_type='Implement', query='from typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i+1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False', observation='\\n```python\\nfrom typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i+1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False\\n```\\nExecution Status: ', answer='', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0.0, 'depth': 1, 'is_terminal': False, 'reward': 0}, {'state': LATSReActStepOutput(thought='We need to iterate through the list of numbers and check if any two numbers are closer to each other than the given threshold. To do this, we can compare the absolute difference between each pair of numbers.', action_type='Implement', query='from typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i + 1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False', observation='\\n```python\\nfrom typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i + 1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False\\n```\\nExecution Status: ', answer='', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0.0, 'depth': 1, 'is_terminal': False, 'reward': 0}], generate_metrics=LATSGenerateMetrics(thoughts_metrics=[PromptMetrics(prompt_tokens=249, completion_tokens=380, total_tokens=629, prompt_cost=0.0001245, completion_cost=0.00057, total_cost=0.0006945, prompt_time=3.578505754470825), PromptMetrics(prompt_tokens=249, completion_tokens=377, total_tokens=626, prompt_cost=0.0001245, completion_cost=0.0005655, total_cost=0.0006900000000000001, prompt_time=3.4422123432159424)], actions_metrics=[PromptMetrics(prompt_tokens=287, completion_tokens=263, total_tokens=550, prompt_cost=0.0001435, completion_cost=0.0003945, total_cost=0.000538, prompt_time=2.4891202449798584), PromptMetrics(prompt_tokens=294, completion_tokens=69, total_tokens=363, prompt_cost=0.000147, completion_cost=0.00010350000000000001, total_cost=0.0002505, prompt_time=1.0115177631378174)], reflections_metrics=[]), values=[{'explanation': 'Explanation not found', 'value': 0.0}, {'explanation': 'Explanation not found', 'value': 0.0}], evaluate_metrics=LATSEvaluateMetrics(values_metrics=[PromptMetrics(prompt_tokens=2787, completion_tokens=97, total_tokens=2884, prompt_cost=0.0013935, completion_cost=0.0001455, total_cost=0.001539, prompt_time=1.408665418624878), PromptMetrics(prompt_tokens=2796, completion_tokens=65, total_tokens=2861, prompt_cost=0.001398, completion_cost=9.75e-05, total_cost=0.0014954999999999999, prompt_time=1.0734140872955322)]), simulation_results=LATSSimulationOutput(simulation_reward=1.0, simulation_terminal_node={'state': LATSReActStepOutput(thought='The function has passed the test cases, and it correctly identifies if there are any two numbers in the list closer to each other than the given threshold. I will finish this task now.', action_type='Finish', query='from typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i+1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False', observation='Answer is CORRECT', answer='from typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i+1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0, 'depth': 3, 'is_terminal': True, 'reward': 1}, simulation_current_nodes=[{'state': LATSReActStepOutput(thought='To solve this problem, I need to iterate through the list of numbers and compare each pair of numbers to see if they are closer to each other than the given threshold.', action_type='Implement', query='from typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i+1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False', observation='\\n```python\\nfrom typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i+1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False\\n```\\nExecution Status: ', answer='', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0.0, 'depth': 1, 'is_terminal': False, 'reward': 0}, {'state': LATSReActStepOutput(thought=\"Now, let's test the implemented function with some test cases to verify its correctness.\", action_type='Test', query='assert has_close_elements([1.0, 2.0, 3.0], 0.5) == False\\nassert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True', observation='\\n```python\\nfrom typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i+1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False\\n\\nassert has_close_elements([1.0, 2.0, 3.0], 0.5) == False\\nassert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True\\n```\\nExecution Status: Done', answer='', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0, 'depth': 2, 'is_terminal': False, 'reward': 0}], simulation_children_nodes=[[{'state': LATSReActStepOutput(thought=\"Now, let's test the implemented function with some test cases to verify its correctness.\", action_type='Test', query='assert has_close_elements([1.0, 2.0, 3.0], 0.5) == False\\nassert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True', observation='\\n```python\\nfrom typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i+1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False\\n\\nassert has_close_elements([1.0, 2.0, 3.0], 0.5) == False\\nassert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True\\n```\\nExecution Status: Done', answer='', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0, 'depth': 2, 'is_terminal': False, 'reward': 0}, {'state': LATSReActStepOutput(thought='Now, I need to test the implemented function with some assert statement test cases to ensure it works correctly.', action_type='Test', query='def test_has_close_elements():\\n    assert has_close_elements([1.0, 2.0, 3.0], 0.5) == False\\n    assert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True\\n\\ntest_has_close_elements()', observation='\\n```python\\nfrom typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i+1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False\\n\\ndef test_has_close_elements():\\n    assert has_close_elements([1.0, 2.0, 3.0], 0.5) == False\\n    assert has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3) == True\\n\\ntest_has_close_elements()\\n```\\nExecution Status: Done', answer='', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0, 'depth': 2, 'is_terminal': False, 'reward': 0}], [{'state': LATSReActStepOutput(thought='The function has passed the test cases, and it correctly identifies if there are any two numbers in the list closer to each other than the given threshold. I will finish this task now.', action_type='Finish', query='from typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i+1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False', observation='Answer is CORRECT', answer='from typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i+1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0, 'depth': 3, 'is_terminal': True, 'reward': 1}, {'state': LATSReActStepOutput(thought='The implementation is correct, and the tests have passed successfully. I will finish the task.', action_type='Finish', query='from typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i+1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False', observation='Answer is CORRECT', answer='from typing import List\\n\\ndef has_close_elements(numbers: List[float], threshold: float) -> bool:\\n    for i in range(len(numbers)):\\n        for j in range(i+1, len(numbers)):\\n            if abs(numbers[i] - numbers[j]) < threshold:\\n                return True\\n    return False', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0, 'depth': 3, 'is_terminal': True, 'reward': 1}]], simulation_values=[[{'explanation': 'Explanation not found', 'value': 0.0}, {'explanation': 'Explanation not found', 'value': 0.0}]]), simulation_metrics=LATSSimulationMetrics(simulation_step_metrics=[LATSSimulationStepMetrics(generate_metrics=LATSGenerateMetrics(thoughts_metrics=[PromptMetrics(prompt_tokens=438, completion_tokens=189, total_tokens=627, prompt_cost=0.00021899999999999998, completion_cost=0.0002835, total_cost=0.0005025, prompt_time=2.0563254356384277), PromptMetrics(prompt_tokens=438, completion_tokens=253, total_tokens=691, prompt_cost=0.00021899999999999998, completion_cost=0.0003795, total_cost=0.0005985, prompt_time=2.6207282543182373)], actions_metrics=[PromptMetrics(prompt_tokens=459, completion_tokens=252, total_tokens=711, prompt_cost=0.0002295, completion_cost=0.000378, total_cost=0.0006075, prompt_time=2.7249836921691895), PromptMetrics(prompt_tokens=463, completion_tokens=353, total_tokens=816, prompt_cost=0.0002315, completion_cost=0.0005295, total_cost=0.000761, prompt_time=3.3571689128875732)], reflections_metrics=[]), evaluate_metrics=LATSEvaluateMetrics(values_metrics=[PromptMetrics(prompt_tokens=3036, completion_tokens=60, total_tokens=3096, prompt_cost=0.001518, completion_cost=9e-05, total_cost=0.001608, prompt_time=0.9853651523590088), PromptMetrics(prompt_tokens=3066, completion_tokens=64, total_tokens=3130, prompt_cost=0.0015329999999999999, completion_cost=9.6e-05, total_cost=0.0016289999999999998, prompt_time=1.0504674911499023)])), LATSSimulationStepMetrics(generate_metrics=LATSGenerateMetrics(thoughts_metrics=[PromptMetrics(prompt_tokens=687, completion_tokens=187, total_tokens=874, prompt_cost=0.0003435, completion_cost=0.0002805, total_cost=0.000624, prompt_time=1.9371333122253418), PromptMetrics(prompt_tokens=687, completion_tokens=181, total_tokens=868, prompt_cost=0.0003435, completion_cost=0.0002715, total_cost=0.000615, prompt_time=2.186814308166504)], actions_metrics=[PromptMetrics(prompt_tokens=728, completion_tokens=70, total_tokens=798, prompt_cost=0.00036399999999999996, completion_cost=0.000105, total_cost=0.00046899999999999996, prompt_time=0.9830343723297119), PromptMetrics(prompt_tokens=709, completion_tokens=70, total_tokens=779, prompt_cost=0.0003545, completion_cost=0.000105, total_cost=0.0004595, prompt_time=1.0852348804473877)], reflections_metrics=[]), evaluate_metrics=LATSEvaluateMetrics(values_metrics=[]))]))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thought 1: I need to write a function that finds the first repeated character in a given string by checking each character against a set of seen characters.\n",
      "Action 1: Implement[\n",
      "```python\n",
      "def first_repeated_char(s):\n",
      "    seen = set()\n",
      "    for char in s:\n",
      "        if char in seen:\n",
      "            return char\n",
      "        seen.add(char)\n",
      "    return None\n",
      "```\n",
      "]\n",
      "Observation 1: \n",
      "```python\n",
      "def first_repeated_char(s):\n",
      "    seen = set()\n",
      "    for char in s:\n",
      "        if char in seen:\n",
      "            return char\n",
      "        seen.add(char)\n",
      "    return None\n",
      "```\n",
      "Execution Status: \n",
      "Thought 2: I need to test the function to ensure it works correctly with different test cases.\n",
      "Action 2: Test[\n",
      "```python\n",
      "assert first_repeated_char(\"abcabc\") == \"a\"\n",
      "assert first_repeated_char(\"abc\") == None\n",
      "assert first_repeated_char(\"123123\") == \"1\"\n",
      "```\n",
      "]\n",
      "Observation 2: \n",
      "```python\n",
      "def first_repeated_char(s):\n",
      "    seen = set()\n",
      "    for char in s:\n",
      "        if char in seen:\n",
      "            return char\n",
      "        seen.add(char)\n",
      "    return None\n",
      "\n",
      "assert first_repeated_char(\"abcabc\") == \"a\"\n",
      "assert first_repeated_char(\"abc\") == None\n",
      "assert first_repeated_char(\"123123\") == \"1\"\n",
      "```\n",
      "Execution Status: Done\n",
      "Thought 3: The function works correctly for the provided test cases. I can consider it completed.\n",
      "Action 3: Finish[\n",
      "```python\n",
      "def first_repeated_char(s):\n",
      "    seen = set()\n",
      "    for char in s:\n",
      "        if char in seen:\n",
      "            return char\n",
      "        seen.add(char)\n",
      "    return None\n",
      "```\n",
      "]\n",
      "Observation 3: Answer is CORRECT\n"
     ]
    }
   ],
   "source": [
    "question = \"Write a python function to find the first repeated character in a given string.\"\n",
    "key = \"\"\"assert first_repeated_char(\"abcabc\") == \"a\"\n",
    "assert first_repeated_char(\"abc\") == None\n",
    "assert first_repeated_char(\"123123\") == \"1\\\"\"\"\"\n",
    "\n",
    "agent = LATSCodeStrategy(\n",
    "    llm=llm, \n",
    "    n_samples=2, \n",
    "    max_reflections=4, \n",
    "    depth_limit=5,\n",
    "    max_unique=5,\n",
    "    cache_values=True,\n",
    ")\n",
    "\n",
    "out = agent.generate(\n",
    "    question=question,\n",
    "    key=key,\n",
    "    examples=MBPP_FEWSHOT_EXAMPLES_REACT,\n",
    "    reflect_examples=MBPP_FEWSHOT_EXAMPLES_LATS_REFLECT,\n",
    "    value_examples=MBPP_FEWSHOT_EXAMPLES_LATS_VALUE,\n",
    "    prompt=LATS_INSTRUCTION_MBPP,\n",
    "    reflect_prompt=LATS_REFLECT_INSTRUCTION_MBPP,\n",
    "    value_prompt=LATS_VALUE_INSTRUCTION_MBPP,            \n",
    "    additional_keys={\"tests\": key},\n",
    "    reflect_additional_keys={\"tests\": key},\n",
    "    value_additional_keys={\"tests\": key},\n",
    "    max_iterations=1,\n",
    "    reset=True\n",
    ")\n",
    "\n",
    "print(get_node_trajectory_code(out.answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LATSOutput(answer=<agential.cog.lats.node.Node object at 0x000002424F5D9550>, total_prompt_tokens=45134, total_completion_tokens=2099, total_tokens=47233, total_prompt_cost=0.022567, total_completion_cost=0.0031485000000000003, total_cost=0.025715499999999995, total_prompt_time=25.777687072753906, total_time=25.787718772888184, additional_info=[LATSStepOutput(iteration=0, current_node={'state': LATSReActStepOutput(thought='', action_type='', query='', observation='', answer='', external_tool_info={}), 'visits': 0, 'value': 0, 'depth': 0, 'is_terminal': False, 'reward': 0}, children_nodes=[{'state': LATSReActStepOutput(thought='I need to write a function that finds the first repeated character in a given string by checking each character against a set of seen characters.', action_type='Implement', query='def first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None', observation='\\n```python\\ndef first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None\\n```\\nExecution Status: ', answer='', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0.0, 'depth': 1, 'is_terminal': False, 'reward': 0}, {'state': LATSReActStepOutput(thought='I need to write a function that finds the first repeated character in a string by keeping track of characters that have been seen before.', action_type='Implement', query='def first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None', observation='\\n```python\\ndef first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None\\n```\\nExecution Status: ', answer='', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0.0, 'depth': 1, 'is_terminal': False, 'reward': 0}], generate_metrics=LATSGenerateMetrics(thoughts_metrics=[PromptMetrics(prompt_tokens=3106, completion_tokens=397, total_tokens=3503, prompt_cost=0.001553, completion_cost=0.0005955, total_cost=0.0021485, prompt_time=4.272340536117554), PromptMetrics(prompt_tokens=3106, completion_tokens=396, total_tokens=3502, prompt_cost=0.001553, completion_cost=0.000594, total_cost=0.002147, prompt_time=4.31091570854187)], actions_metrics=[PromptMetrics(prompt_tokens=3137, completion_tokens=45, total_tokens=3182, prompt_cost=0.0015685, completion_cost=6.75e-05, total_cost=0.001636, prompt_time=0.8239231109619141), PromptMetrics(prompt_tokens=3136, completion_tokens=45, total_tokens=3181, prompt_cost=0.001568, completion_cost=6.75e-05, total_cost=0.0016355, prompt_time=0.9458653926849365)], reflections_metrics=[]), values=[{'explanation': 'Explanation not found', 'value': 0.0}, {'explanation': 'Explanation not found', 'value': 0.0}], evaluate_metrics=LATSEvaluateMetrics(values_metrics=[PromptMetrics(prompt_tokens=3018, completion_tokens=50, total_tokens=3068, prompt_cost=0.001509, completion_cost=7.500000000000001e-05, total_cost=0.001584, prompt_time=1.0712969303131104), PromptMetrics(prompt_tokens=3017, completion_tokens=50, total_tokens=3067, prompt_cost=0.0015084999999999999, completion_cost=7.500000000000001e-05, total_cost=0.0015834999999999998, prompt_time=0.9237291812896729)]), simulation_results=LATSSimulationOutput(simulation_reward=1.0, simulation_terminal_node={'state': LATSReActStepOutput(thought='The function works correctly for the provided test cases. I can consider it completed.', action_type='Finish', query='def first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None', observation='Answer is CORRECT', answer='def first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0, 'depth': 3, 'is_terminal': True, 'reward': 1}, simulation_current_nodes=[{'state': LATSReActStepOutput(thought='I need to write a function that finds the first repeated character in a given string by checking each character against a set of seen characters.', action_type='Implement', query='def first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None', observation='\\n```python\\ndef first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None\\n```\\nExecution Status: ', answer='', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0.0, 'depth': 1, 'is_terminal': False, 'reward': 0}, {'state': LATSReActStepOutput(thought='I need to test the function to ensure it works correctly with different test cases.', action_type='Test', query='assert first_repeated_char(\"abcabc\") == \"a\"\\nassert first_repeated_char(\"abc\") == None\\nassert first_repeated_char(\"123123\") == \"1\"', observation='\\n```python\\ndef first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None\\n\\nassert first_repeated_char(\"abcabc\") == \"a\"\\nassert first_repeated_char(\"abc\") == None\\nassert first_repeated_char(\"123123\") == \"1\"\\n```\\nExecution Status: Done', answer='', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0, 'depth': 2, 'is_terminal': False, 'reward': 0}], simulation_children_nodes=[[{'state': LATSReActStepOutput(thought='I need to test the function to ensure it works correctly with different test cases.', action_type='Test', query='assert first_repeated_char(\"abcabc\") == \"a\"\\nassert first_repeated_char(\"abc\") == None\\nassert first_repeated_char(\"123123\") == \"1\"', observation='\\n```python\\ndef first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None\\n\\nassert first_repeated_char(\"abcabc\") == \"a\"\\nassert first_repeated_char(\"abc\") == None\\nassert first_repeated_char(\"123123\") == \"1\"\\n```\\nExecution Status: Done', answer='', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0, 'depth': 2, 'is_terminal': False, 'reward': 0}, {'state': LATSReActStepOutput(thought='I need to test the function to ensure it works correctly with different test cases.', action_type='Test', query='assert first_repeated_char(\"abcabc\") == \"a\"\\nassert first_repeated_char(\"abc\") == None\\nassert first_repeated_char(\"123123\") == \"1\"', observation='', answer='', external_tool_info={}), 'visits': 0, 'value': 0, 'depth': 0, 'is_terminal': False, 'reward': 0}], [{'state': LATSReActStepOutput(thought='The function works correctly for the provided test cases. I can consider it completed.', action_type='Finish', query='def first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None', observation='Answer is CORRECT', answer='def first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0, 'depth': 3, 'is_terminal': True, 'reward': 1}, {'state': LATSReActStepOutput(thought='The function works correctly for the provided test cases.', action_type='Finish', query='def first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None', observation='Answer is CORRECT', answer='def first_repeated_char(s):\\n    seen = set()\\n    for char in s:\\n        if char in seen:\\n            return char\\n        seen.add(char)\\n    return None', external_tool_info={'execution_status': 'Done'}), 'visits': 0, 'value': 0, 'depth': 3, 'is_terminal': True, 'reward': 1}]], simulation_values=[[{'explanation': '', 'value': -10000000000.0}, {'explanation': '', 'value': -10000000000.0}]]), simulation_metrics=LATSSimulationMetrics(simulation_step_metrics=[LATSSimulationStepMetrics(generate_metrics=LATSGenerateMetrics(thoughts_metrics=[PromptMetrics(prompt_tokens=3238, completion_tokens=16, total_tokens=3254, prompt_cost=0.001619, completion_cost=2.4e-05, total_cost=0.001643, prompt_time=0.5960044860839844), PromptMetrics(prompt_tokens=3238, completion_tokens=16, total_tokens=3254, prompt_cost=0.001619, completion_cost=2.4e-05, total_cost=0.001643, prompt_time=0.6334559917449951)], actions_metrics=[PromptMetrics(prompt_tokens=3258, completion_tokens=244, total_tokens=3502, prompt_cost=0.001629, completion_cost=0.000366, total_cost=0.0019950000000000002, prompt_time=2.7042131423950195), PromptMetrics(prompt_tokens=3258, completion_tokens=534, total_tokens=3792, prompt_cost=0.001629, completion_cost=0.0008010000000000001, total_cost=0.00243, prompt_time=5.054161787033081)], reflections_metrics=[]), evaluate_metrics=LATSEvaluateMetrics(values_metrics=[None, None])), LATSSimulationStepMetrics(generate_metrics=LATSGenerateMetrics(thoughts_metrics=[PromptMetrics(prompt_tokens=3397, completion_tokens=111, total_tokens=3508, prompt_cost=0.0016985, completion_cost=0.0001665, total_cost=0.001865, prompt_time=1.4739246368408203), PromptMetrics(prompt_tokens=3397, completion_tokens=105, total_tokens=3502, prompt_cost=0.0016985, completion_cost=0.0001575, total_cost=0.001856, prompt_time=1.3356571197509766)], actions_metrics=[PromptMetrics(prompt_tokens=3417, completion_tokens=45, total_tokens=3462, prompt_cost=0.0017085, completion_cost=6.75e-05, total_cost=0.001776, prompt_time=0.8122975826263428), PromptMetrics(prompt_tokens=3411, completion_tokens=45, total_tokens=3456, prompt_cost=0.0017055, completion_cost=6.75e-05, total_cost=0.001773, prompt_time=0.8199014663696289)], reflections_metrics=[]), evaluate_metrics=LATSEvaluateMetrics(values_metrics=[]))]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
