{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def halting_condition(\n",
    "        self,\n",
    "        idx: int,\n",
    "        key: str,\n",
    "        answer: str,\n",
    "    ) -> bool:\n",
    "\t\treturn EM(answer, key) or idx >= self.max_trials + 1\n",
    "\n",
    "\n",
    "def step_halting_condition(\n",
    "    finished: bool,\n",
    "    step_idx: int,\n",
    "    max_steps: int,\n",
    ") -> bool:\n",
    "\n",
    "    over_max_steps = step_idx > max_steps\n",
    "\n",
    "    return finished or over_max_steps\n",
    "\n",
    "\n",
    "def generate_action(\n",
    "        self,\n",
    "        idx: int,\n",
    "        scratchpad: str,\n",
    "        question: str,\n",
    "        examples: str,\n",
    "        reflections: str,\n",
    "        prompt: str,\n",
    "        additional_keys: Dict[str, str],\n",
    "    ) -> Tuple[str, str, str, Response]:\n",
    "        \"\"\"Generate an action for the current step in the reasoning process.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The current step index.\n",
    "            scratchpad (str): The scratchpad containing previous thoughts and actions.\n",
    "            question (str): The main question or task to be addressed.\n",
    "            examples (str): Relevant examples to provide context for action generation.\n",
    "            trajectory (str): The current trajectory or history of thoughts and actions.\n",
    "            reflections (str): Previous reflections to guide the action generation.\n",
    "            depth (int): The current depth in the search tree.\n",
    "            prompt (str): The prompt template for action generation.\n",
    "            additional_keys (Dict[str, str]): Additional keys for prompt formatting.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[str, str, str, Response]: A tuple containing the updated trajectory, action type, query, and the metrics.\n",
    "        \"\"\"\n",
    "        scratchpad += f\"\\nAction {idx}: \"\n",
    "        out = _prompt_clin_agent(\n",
    "            llm=self.llm,\n",
    "            question=question,\n",
    "            examples=examples,\n",
    "            reflections=reflections,\n",
    "            scratchpad=scratchpad,\n",
    "            max_steps=self.max_steps,\n",
    "            prompt=prompt,\n",
    "            additional_keys=additional_keys,\n",
    "        )\n",
    "        action = out.output_text\n",
    "        action = remove_newline(action).split(\"Observation\")[0]\n",
    "        scratchpad += action\n",
    "        action_type, query = parse_qa_action(action)\n",
    "\n",
    "        return scratchpad, action_type, query, out\n",
    "\n",
    "\n",
    "\n",
    "while not self.halting_condition():\n",
    "\n",
    "\twhile not self.step_halting_condition():\n",
    "\t\taction, action_response = self.generate_action()\n",
    "\t\tobs, reward = self.generate_observation(action)\n",
    "\n",
    "\n",
    "\n",
    "\tsummary = self.summarize()\n",
    "\n",
    "\n",
    "\n",
    "\t\n",
    "\t\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agential",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
